{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fd9a27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a055b3b9",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter'; color: rgb(0, 65, 75);\">\n",
    "    <h1>\n",
    "    GDP Revisions Datasets\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fd88a4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter'; color: rgb(0, 65, 75);\">\n",
    "    <h4>\n",
    "        Documentation\n",
    "        <br>\n",
    "        ____________________\n",
    "            </br>\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc72f519",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color: dark;\">\n",
    "    This \n",
    "    <span style=\"color: rgb(61, 48, 162);\">jupyter notebook</span>\n",
    "    provides a step-by-step guide to <b>data building</b> regarding the project <b>'Revisiones y sesgos en las estimaciones preliminares del PBI en el Per√∫'</b>. The guide covers downloading PDF files containing tables with information on annual, quarterly, and monthly Peru's GDP growth rates (including sectoral GDP) and extracting this information into SQL tables. These data sets will be used for data analysis.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d22837",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter'; color: rgb(0, 65, 75);\">\n",
    "    Jason Cruz\n",
    "    <br>\n",
    "    <a href=\"mailto:jj.cruza@up.edu.pe\" style=\"color: rgb(0, 153, 123)\">\n",
    "        jj.cruza@up.edu.pe\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28540df2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Times New Roman; text-align: left; color: rgb(61, 48, 162)\">The provided outline is functional. Use the buttons to enhance the experience of this script.<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fc04c9",
   "metadata": {},
   "source": [
    "<div id=\"outilne\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0fa13",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #141414; padding: 10px;\">\n",
    "<h2 style=\"text-align: left; font-family: 'charter'; color: #E0E0E0;\">\n",
    "    Outline\n",
    "    </h2>\n",
    "    <br>\n",
    "    <a href=\"#1\" style=\"color: #687EFF; font-size: 18px;\">\n",
    "        1. PDF Downloader</a>\n",
    "    <br>\n",
    "    <a href=\"#2\" style=\"color: #687EFF; font-size: 18px;\">\n",
    "        2. Extracting Tables (and data cleaning)</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        2.1. 'pdfplumber' demo.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1-1\" style=\"color: #E0E0E0; font-size: 12px;\">\n",
    "        2.1.1. What data would we get if we used the default settings?.</a>   \n",
    "    <br>\n",
    "    <a href=\"#2-1-2\" style=\"color: #E0E0E0; font-size: 12px;\">\n",
    "        2.1.2. Using custom '.extract_table' settings.</a>\n",
    "    <br> \n",
    "    <a href=\"#2-2\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        2.2. Extracting tables and generating dataframes (includes data cleanup).</a>\n",
    "    <br>\n",
    "    <a href=\"#3\" style=\"color: #687EFF; font-size: 18px;\">3. SQL Tables</a>\n",
    "    <br>\n",
    "    <a href=\"#3-1\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        3.1. Annual Concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-2\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        3.2. Quarterly Concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-3\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        3.3. Monthly Concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-4\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        3.4. Loading SQL.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90323106",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    Any questions or issues regarding the coding, please <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123)\">email Jason Cruz\n",
    "    </a>.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac40ed0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    If you don't have the libraries below, please use the following code (as example) to install the required libraries.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7c73193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907046a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    <h2>\n",
    "    Libraries\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "214f5982",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Downloader\n",
    "\n",
    "import os  # for file and directory manipulation\n",
    "import random  # to generate random numbers\n",
    "import time  # to manage time and take breaks in the script\n",
    "import requests  # to make HTTP requests to web servers\n",
    "from selenium import webdriver  # for automating web browsers\n",
    "from selenium.webdriver.common.by import By  # to locate elements on a webpage\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # to wait until certain conditions are met on a webpage.\n",
    "from selenium.webdriver.support import expected_conditions as EC  # to define expected conditions\n",
    "from selenium.common.exceptions import StaleElementReferenceException  # To handle exceptions related to elements on the webpage that are no longer available.\n",
    "\n",
    "\n",
    "# Extracting Tables (and data cleaning)\n",
    "\n",
    "import pdfplumber  # for extracting text and metadata from PDF files\n",
    "import pandas as pd  # for data manipulation and analysis\n",
    "import os  # for interacting with the operating system\n",
    "import unicodedata  # for manipulating Unicode data\n",
    "import re  # for regular expressions operations\n",
    "from datetime import datetime  # for working with dates and times\n",
    "import locale  # for locale-specific formatting of numbers, dates, and currencies\n",
    "\n",
    "\n",
    "# SQL tables\n",
    "\n",
    "import psycopg2  # for interacting with PostgreSQL databases\n",
    "from sqlalchemy import create_engine, text  # for creating and executing SQL queries using SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ef8f8",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    <h2>\n",
    "    Initial set-up\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc1c80",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\"> The next 3 code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8899a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to download PDF files\n",
    "\n",
    "raw_pdf = 'raw_pdf' # to save raw data (.pdf).\n",
    "if not os.path.exists(raw_pdf):\n",
    "    os.mkdir(raw_pdf) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26b4c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save text file with the names of already downloaded files\n",
    "\n",
    "download_record = 'download_record'\n",
    "if not os.path.exists(download_record):\n",
    "    os.mkdir(download_record) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "147227ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to download the trimmed PDF files (these are PDF inputs for the extraction and cleanup code)\n",
    "\n",
    "input_pdf = 'input_pdf'\n",
    "if not os.path.exists(input_pdf):\n",
    "    os.makedirs(input_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6dc316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to download the trimmed PDF files (these are PDF inputs for the extraction and cleanup code)\n",
    "\n",
    "trimmed_record = 'trimmed_record'\n",
    "if not os.path.exists(trimmed_record):\n",
    "    os.makedirs(trimmed_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0d69eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save dataframes generated record by year\n",
    "\n",
    "dataframes_record = 'dataframes_record'\n",
    "if not os.path.exists(dataframes_record):\n",
    "    os.makedirs(dataframes_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821d5382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to download the trimmed PDF files (these are PDF inputs for the extraction and cleanup code)\n",
    "\n",
    "pseudo_raw_pdf = 'pseudo_raw_pdf'\n",
    "if not os.path.exists(pseudo_raw_pdf):\n",
    "    os.makedirs(pseudo_raw_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f56ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d0038d2",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7cf410",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ba6e051c",
   "metadata": {},
   "source": [
    "<div id=\"1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f3192",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: charter;\">1.</span> <span style = \"color: dark; font-family: charter;\">PDF Downloader</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98250a64",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Our main source for data collection is the <a href=\"https://www.bcrp.gob.pe/\" style=\"color: rgb(0, 153, 123)\">BCRP's web page</a> (.../publicaciones/nota-semanal). The BCRP publishes \"Notas Semanales\", documents that contain, among other information, tables of GDP and sectoral GDP growth rate values for annual, quarterly and monthly frequencies.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b3a388",
   "metadata": {},
   "source": [
    "-- (pending) Selenium tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcc4e3",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    The provided code will download all the 'Notas Semanales' files in PDF format from this web page.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e812cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the BCRP URL\n",
    "bcrp_url = \"https://www.bcrp.gob.pe/publicaciones/nota-semanal.html\"  # Never replace this URL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e269c03d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    The provided code will download all the 'Notas Semanales' files in PDF format from this web page.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68363e06",
   "metadata": {},
   "source": [
    "# Con ventana input al usuario y alarma por cada lote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0199bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pygame\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import requests\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Inicializar pygame\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Carpeta donde se almacenar√°n los archivos de sonido\n",
    "sound_folder = \"sound\"\n",
    "\n",
    "# Lista de archivos de sonido disponibles\n",
    "available_sounds = os.listdir(sound_folder)\n",
    "\n",
    "# Seleccionar un sonido aleatorio\n",
    "random_sound = random.choice(available_sounds)\n",
    "\n",
    "# Ruta completa del sonido aleatorio\n",
    "sound_path = os.path.join(sound_folder, random_sound)\n",
    "\n",
    "# Cargar el sonido seleccionado\n",
    "pygame.mixer.music.load(sound_path)\n",
    "\n",
    "# Funci√≥n para reproducir el sonido\n",
    "def play_sound():\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "# List to keep track of successfully downloaded files\n",
    "downloaded_files = []\n",
    "\n",
    "# Folder where downloaded PDF files will be saved\n",
    "raw_pdf = \"raw_pdf\"  # Replace with the actual path\n",
    "\n",
    "# Folder where the download record file will be saved\n",
    "download_record = \"download_record\"  # Replace with the actual path\n",
    "\n",
    "# Load the list of previously downloaded files if it exists\n",
    "if os.path.exists(os.path.join(download_record, \"downloaded_files.txt\")):\n",
    "    with open(os.path.join(download_record, \"downloaded_files.txt\"), \"r\") as f:\n",
    "        downloaded_files = f.read().splitlines()\n",
    "\n",
    "# Web driver setup\n",
    "driver_path = os.environ.get('driver_path')\n",
    "driver = webdriver.Chrome(executable_path=driver_path)\n",
    "\n",
    "def random_wait(min_time, max_time):\n",
    "    wait_time = random.uniform(min_time, max_time)\n",
    "    print(f\"Waiting randomly for {wait_time:.2f} seconds\")\n",
    "    time.sleep(wait_time)\n",
    "\n",
    "def download_pdf(pdf_link):\n",
    "    # Click the link using JavaScript\n",
    "    driver.execute_script(\"arguments[0].click();\", pdf_link)\n",
    "\n",
    "    # Wait for the new page to fully open (adjust timing as necessary)\n",
    "    wait.until(EC.number_of_windows_to_be(2))\n",
    "\n",
    "    # Switch to the new window or tab\n",
    "    windows = driver.window_handles\n",
    "    driver.switch_to.window(windows[1])\n",
    "\n",
    "    # Get the current URL (may vary based on site-specific logic)\n",
    "    new_url = driver.current_url\n",
    "    print(f\"{download_counter}. New URL: {new_url}\")\n",
    "\n",
    "    # Get the file name from the URL\n",
    "    file_name = new_url.split(\"/\")[-1]\n",
    "\n",
    "    # Form the full destination path\n",
    "    destination_path = os.path.join(raw_pdf, file_name)\n",
    "\n",
    "    # Download the PDF\n",
    "    response = requests.get(new_url, stream=True)\n",
    "\n",
    "    # Check if the request was successful (status code 200)\n",
    "    if response.status_code == 200:\n",
    "        # Save the PDF content to the local file\n",
    "        with open(destination_path, 'wb') as pdf_file:\n",
    "            for chunk in response.iter_content(chunk_size=128):\n",
    "                pdf_file.write(chunk)\n",
    "\n",
    "        print(f\"PDF downloaded successfully at: {destination_path}\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Error downloading the PDF. Response code: {response.status_code}\")\n",
    "\n",
    "    # Close the new window or tab\n",
    "    driver.close()\n",
    "\n",
    "    # Switch back to the main window\n",
    "    driver.switch_to.window(windows[0])\n",
    "\n",
    "# Number of downloads per batch\n",
    "downloads_per_batch = 5\n",
    "# Total number of downloads\n",
    "total_downloads = 25\n",
    "\n",
    "try:\n",
    "    # Open the test page\n",
    "    driver.get(bcrp_url)\n",
    "    print(\"Site opened successfully\")\n",
    "\n",
    "    # Wait for the container area to be present\n",
    "    wait = WebDriverWait(driver, 60)\n",
    "    container_area = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"rightside\"]')))\n",
    "\n",
    "    # Get all the links within the container area\n",
    "    pdf_links = container_area.find_elements(By.XPATH, './/a')\n",
    "\n",
    "    # Reverse the order of links\n",
    "    pdf_links = list(reversed(pdf_links))\n",
    "\n",
    "    # Initialize download counter\n",
    "    download_counter = 0\n",
    "\n",
    "    # Iterate over reversed links and download PDFs in batches\n",
    "    for pdf_link in pdf_links:\n",
    "        download_counter += 1\n",
    "\n",
    "        # Get the file name from the URL\n",
    "        new_url = pdf_link.get_attribute(\"href\")\n",
    "        file_name = new_url.split(\"/\")[-1]\n",
    "\n",
    "        # Check if the file has already been downloaded\n",
    "        if file_name in downloaded_files:\n",
    "            print(f\"{download_counter}. The file {file_name} has already been downloaded previously. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Try to download the file\n",
    "        try:\n",
    "            download_pdf(pdf_link)\n",
    "\n",
    "            # Update the list of downloaded files\n",
    "            downloaded_files.append(file_name)\n",
    "\n",
    "            # Save the file name in the record\n",
    "            with open(os.path.join(download_record, \"downloaded_files.txt\"), \"a\") as f:\n",
    "                f.write(file_name + \"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading the file {file_name}: {str(e)}\")\n",
    "\n",
    "        # If the download count reaches a multiple of batch size, notify\n",
    "        if download_counter % downloads_per_batch == 0:\n",
    "            print(f\"Batch {download_counter // downloads_per_batch} of {downloads_per_batch} completed\")\n",
    "\n",
    "        # If the download count reaches a multiple of 25, ask the user if they want to continue\n",
    "        if download_counter % 25 == 0:\n",
    "            play_sound()\n",
    "            user_input = input(\"Do you want to continue downloading? (Enter 's' to continue, any other key to stop): \")\n",
    "            pygame.mixer.music.stop()\n",
    "            if user_input.lower() != 's':\n",
    "                break\n",
    "\n",
    "        # Random wait before the next iteration\n",
    "        random_wait(5, 10)\n",
    "\n",
    "        # If total downloads reached, break out of loop\n",
    "        if download_counter == total_downloads:\n",
    "            print(f\"All downloads completed ({total_downloads} in total)\")\n",
    "            break\n",
    "\n",
    "except StaleElementReferenceException:\n",
    "    print(\"StaleElementReferenceException occurred. Retrying...\")\n",
    "\n",
    "finally:\n",
    "    # Close the browser when finished\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0168995d",
   "metadata": {},
   "source": [
    "### Ordenando pdf por a√±os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee016a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Obtener la lista de archivos en el directorio\n",
    "archivos = os.listdir(raw_pdf)\n",
    "\n",
    "# Iterar sobre cada archivo\n",
    "for archivo in archivos:\n",
    "    # Obtener el a√±o del nombre del archivo\n",
    "    nombre, extension = os.path.splitext(archivo)\n",
    "    a√±o = None\n",
    "    partes_nombre = nombre.split('-')\n",
    "    for parte in partes_nombre:\n",
    "        if parte.isdigit() and len(parte) == 4:\n",
    "            a√±o = parte\n",
    "            break\n",
    "\n",
    "    # Si se encontr√≥ el a√±o, mover el archivo a la carpeta correspondiente\n",
    "    if a√±o:\n",
    "        carpeta_destino = os.path.join(raw_pdf, a√±o)\n",
    "        # Crear la carpeta si no existe\n",
    "        if not os.path.exists(carpeta_destino):\n",
    "            os.makedirs(carpeta_destino)\n",
    "        # Mover el archivo a la carpeta destino\n",
    "        shutil.move(os.path.join(raw_pdf, archivo), carpeta_destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d24d2",
   "metadata": {},
   "source": [
    "# Recortando PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4afd2370",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando carpeta: 2013\n",
      "1. Procesando: pseudo_raw_pdf\\2013\\ns-08-2017.pdf\n",
      "El PDF recortado 'input_pdf\\ns-08-2017.pdf' tiene 3 p√°ginas.\n",
      "Se conservaron todas las p√°ginas en el PDF recortado 'input_pdf\\ns-08-2017.pdf'.\n",
      "Proceso completado para todos los PDFs en el directorio: input_pdf\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import os\n",
    "import tkinter as tk\n",
    "\n",
    "# Rutas de directorios\n",
    "trimmed_record_dir = 'trimmed_record'\n",
    "trimmed_record_file = 'trimmed_files.txt'\n",
    "\n",
    "class PopupWindow(tk.Toplevel):\n",
    "    def __init__(self, root, message):\n",
    "        super().__init__(root)\n",
    "        self.root = root\n",
    "        self.title(\"Atenci√≥n!\")\n",
    "        self.message = message\n",
    "        self.result = None\n",
    "        self.configure_window()\n",
    "        self.create_widgets()\n",
    "\n",
    "    def configure_window(self):\n",
    "        self.resizable(False, False)  # Evita cambiar el tama√±o de la ventana\n",
    "\n",
    "    def create_widgets(self):\n",
    "        self.label = tk.Label(self, text=self.message, wraplength=250)  # Ajusta el texto si es demasiado largo\n",
    "        self.label.pack(pady=10, padx=10)\n",
    "        self.btn_frame = tk.Frame(self)\n",
    "        self.btn_frame.pack(pady=5)\n",
    "        self.btn_yes = tk.Button(self.btn_frame, text=\"S√≠\", command=self.yes)\n",
    "        self.btn_yes.pack(side=tk.LEFT, padx=5)\n",
    "        self.btn_no = tk.Button(self.btn_frame, text=\"No\", command=self.no)\n",
    "        self.btn_no.pack(side=tk.RIGHT, padx=5)\n",
    "\n",
    "        # Calcula el tama√±o de la ventana en funci√≥n del tama√±o del texto\n",
    "        width = self.label.winfo_reqwidth() + 20\n",
    "        height = self.label.winfo_reqheight() + 100\n",
    "        self.geometry(f\"{width}x{height}\")\n",
    "\n",
    "    def yes(self):\n",
    "        self.result = True\n",
    "        self.destroy()\n",
    "\n",
    "    def no(self):\n",
    "        self.result = False\n",
    "        self.destroy()\n",
    "\n",
    "def search_keywords(pdf_file, keywords):\n",
    "    pages_with_keywords = []\n",
    "    with fitz.open(pdf_file) as doc:\n",
    "        for page_num in range(doc.page_count):\n",
    "            page = doc.load_page(page_num)\n",
    "            text = page.get_text()\n",
    "            if any(keyword in text for keyword in keywords):\n",
    "                pages_with_keywords.append(page_num)\n",
    "    return pages_with_keywords\n",
    "\n",
    "def trim_pdf(pdf_file, pages):\n",
    "    if not pages:\n",
    "        print(f\"No se encontraron p√°ginas con palabras clave en {pdf_file}\")\n",
    "        return 0\n",
    "    \n",
    "    new_pdf_file = os.path.join(input_pdf, os.path.basename(pdf_file))\n",
    "    \n",
    "    with fitz.open(pdf_file) as doc:\n",
    "        new_doc = fitz.open()\n",
    "        new_doc.insert_pdf(doc, from_page=0, to_page=0)\n",
    "        for page_num in pages:\n",
    "            new_doc.insert_pdf(doc, from_page=page_num, to_page=page_num)\n",
    "        new_doc.save(new_pdf_file)\n",
    "    \n",
    "    num_pages_new_pdf = new_doc.page_count\n",
    "    print(f\"El PDF recortado '{new_pdf_file}' tiene {num_pages_new_pdf} p√°ginas.\")\n",
    "\n",
    "    if num_pages_new_pdf == 5:\n",
    "        final_doc = fitz.open()\n",
    "        final_doc.insert_pdf(new_doc, from_page=0, to_page=0)\n",
    "        final_doc.insert_pdf(new_doc, from_page=1, to_page=1)\n",
    "        final_doc.insert_pdf(new_doc, from_page=3, to_page=3)\n",
    "        final_doc.save(new_pdf_file)\n",
    "\n",
    "        num_pages_new_pdf = final_doc.page_count\n",
    "        print(f\"Solo se conservaron la portada y las p√°ginas con 2 tablas de inter√©s en el PDF recortado '{new_pdf_file}'.\")\n",
    "    else:\n",
    "        print(f\"Se conservaron todas las p√°ginas en el PDF recortado '{new_pdf_file}'.\")\n",
    "\n",
    "    return num_pages_new_pdf\n",
    "\n",
    "def read_trimmed_files():\n",
    "    trimmed_files_path = os.path.join(trimmed_record_dir, trimmed_record_file)\n",
    "    if not os.path.exists(trimmed_files_path):\n",
    "        return set()\n",
    "    \n",
    "    with open(trimmed_files_path, 'r') as file:\n",
    "        return set(file.read().splitlines())\n",
    "\n",
    "def write_trimmed_files(trimmed_files):\n",
    "    trimmed_files_path = os.path.join(trimmed_record_dir, trimmed_record_file)\n",
    "    sorted_filenames = sorted(trimmed_files)  # Sort the filenames\n",
    "    with open(trimmed_files_path, 'w') as file:\n",
    "        for filename in sorted_filenames:\n",
    "            file.write(filename + '\\n')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    keywords = [\"ECONOMIC SECTORS\"]\n",
    "    root = tk.Tk()\n",
    "    root.withdraw()  # Oculta la ventana principal de Tkinter\n",
    "\n",
    "    trimmed_files = read_trimmed_files()\n",
    "    processing_counter = 1\n",
    "\n",
    "    for folder in os.listdir(pseudo_raw_pdf):\n",
    "        folder_path = os.path.join(pseudo_raw_pdf, folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            print(\"Procesando carpeta:\", folder)\n",
    "            num_pdfs_trimmed = 0\n",
    "            for filename in os.listdir(folder_path):\n",
    "                if filename.endswith(\".pdf\"):\n",
    "                    pdf_file = os.path.join(folder_path, filename)\n",
    "                    if filename in trimmed_files:\n",
    "                        print(f\"{processing_counter}. El PDF '{filename}' ya ha sido recortado y guardado en '{input_folder}'...\")\n",
    "                        processing_counter += 1\n",
    "                        continue\n",
    "                    print(f\"{processing_counter}. Procesando:\", pdf_file)\n",
    "                    \n",
    "                    pages_with_keywords = search_keywords(pdf_file, keywords)\n",
    "                    num_pages_new_pdf = trim_pdf(pdf_file, pages_with_keywords)\n",
    "                    if num_pages_new_pdf > 0:\n",
    "                        num_pdfs_trimmed += 1\n",
    "                        trimmed_files.add(filename)\n",
    "                        processing_counter += 1\n",
    "            \n",
    "            write_trimmed_files(trimmed_files)\n",
    "\n",
    "            message = f\"{num_pdfs_trimmed} PDFs han sido recortados en la carpeta {folder}. ¬øDesea continuar?\"\n",
    "            popup = PopupWindow(root, message)\n",
    "            root.wait_window(popup)\n",
    "            if not popup.result:\n",
    "                break\n",
    "                \n",
    "    print(\"Proceso completado para todos los PDFs en el directorio:\", input_pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643079a",
   "metadata": {},
   "source": [
    "### Ordenando pdf por a√±os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ae87395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "# Obtener la lista de archivos en el directorio\n",
    "archivos = os.listdir(input_pdf)\n",
    "\n",
    "# Iterar sobre cada archivo\n",
    "for archivo in archivos:\n",
    "    # Obtener el a√±o del nombre del archivo\n",
    "    nombre, extension = os.path.splitext(archivo)\n",
    "    a√±o = None\n",
    "    partes_nombre = nombre.split('-')\n",
    "    for parte in partes_nombre:\n",
    "        if parte.isdigit() and len(parte) == 4:\n",
    "            a√±o = parte\n",
    "            break\n",
    "\n",
    "    # Si se encontr√≥ el a√±o, mover el archivo a la carpeta correspondiente\n",
    "    if a√±o:\n",
    "        carpeta_destino = os.path.join(input_pdf, a√±o)\n",
    "        # Crear la carpeta si no existe\n",
    "        if not os.path.exists(carpeta_destino):\n",
    "            os.makedirs(carpeta_destino)\n",
    "        # Mover el archivo a la carpeta destino\n",
    "        shutil.move(os.path.join(input_pdf, archivo), carpeta_destino)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045beb7b",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a384d2",
   "metadata": {},
   "source": [
    "<div id=\"2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e1e92",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.</span> <span style = \"color: dark; font-family: charter;\">Extracting Tables (and data cleaning)</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ed1db",
   "metadata": {},
   "source": [
    "<div id=\"2-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05af999f",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.1.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        pdfplumber\n",
    "    </span> \n",
    "    demo\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ebeb3a",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Import\n",
    "    <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        pdfplumber\n",
    "    </span>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e7dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "print(f'This library version is: {pdfplumber.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b481d4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Load the PDF\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb31c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfplumber.open(\".\\\\ns-10-2013.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad376ace",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Get the page 82\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc3638",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_82 = pdf.pages[81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33facebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the page to a higher resolution image (e.g., 300 DPI).\n",
    "image = p_82.to_image(resolution=300)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3629ee4d",
   "metadata": {},
   "source": [
    "<div id=\"2-1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d49929c",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.1.1.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    What data would we get if we used the default settings?\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ea8f5e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    We can check by using <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        PageImage.debug_tablefinder()\n",
    "    </span>:\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd775601",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.reset().debug_tablefinder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "919ae18d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    The default settings correctly identify the table's vertical demarcations, but don't capture the horizontal demarcations between each group of five states/territories. So:\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289b70f0",
   "metadata": {},
   "source": [
    "<div id=\"2-1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8947130a",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.1.2.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Using custom <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        <b>.extract_table\n",
    "            </b>\n",
    "    </span>'s settings\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c473c71b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    <ul>\n",
    "        <li>Because the columns are separated by lines, we use <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        vertical_strategy=\"lines\"\n",
    "    </span>.\n",
    "            </li>\n",
    "        <li>Because the rows are, primarily, separated by gutters between the text, we use <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        horizontal_strategy=\"text\"\n",
    "    </span>.\n",
    "            <li>To snap together a handful of the gutters at the top which aren't fully flush with one another, we use <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        snap_y_tolerance\n",
    "    </span>which snaps horizontal lines within a certain distance to the same vertical alignment.\n",
    "                </li>\n",
    "        <li>And because the left and right-hand extremities of the text aren't quite flush with the vertical lines, we use <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        \"intersection_tolerance\": 15\n",
    "    </span>.\n",
    "            </li>\n",
    "        </ul>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832b6806",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_settings = {\n",
    "    \"vertical_strategy\": \"lines\", \n",
    "    \"horizontal_strategy\": \"lines\",\n",
    "    \"explicit_vertical_lines\": [],\n",
    "    \"explicit_horizontal_lines\": [],\n",
    "    \"snap_tolerance\": 3,\n",
    "    \"snap_x_tolerance\": 3,\n",
    "    \"snap_y_tolerance\": 3,\n",
    "    \"join_tolerance\": 3,\n",
    "    \"join_x_tolerance\": 3,\n",
    "    \"join_y_tolerance\": 3,\n",
    "    \"edge_min_length\": 3,\n",
    "    \"min_words_vertical\": 3,\n",
    "    \"min_words_horizontal\": 1,\n",
    "    \"text_keep_blank_chars\": False,\n",
    "    \"text_tolerance\": 3,\n",
    "    \"text_x_tolerance\": 3,\n",
    "    \"text_y_tolerance\": 3,\n",
    "    \"intersection_tolerance\": 3,\n",
    "    \"intersection_x_tolerance\": 3,\n",
    "    \"intersection_y_tolerance\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c25c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.reset().debug_tablefinder(table_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2093bf",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5a767",
   "metadata": {},
   "source": [
    "<div id=\"2-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357318e8",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.2.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Extracting tables and generating dataframes (includes data cleanup)\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100857d4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    We would like to get specific tables: information on GDP growth rates with annual, quarterly and monthly frequency. We don't need other tables also related to GDP that don't meet these requirements. Extraction will be easier if we use keywords.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e77729e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords to search in the page text\n",
    "keywords = [\"PRODUCTO BRUTO INTERNO\", \"SECTORES ECON√ìMICOS\", \"PBI\", \"GDP\", \"Variaciones\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070fb47",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    The code iterates through each PDF and extracts the two required tables from each. The extracted information is then transformed into dataframes and the columns and values are cleaned up to conform to Python conventions (pythonic).\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5af4d90",
   "metadata": {},
   "source": [
    "# Funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df05629",
   "metadata": {},
   "source": [
    "### Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f4190e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_characters_first_row(texto):\n",
    "    texto = re.sub(r'\\s*-\\s*', '-', texto)  # Remueve espacios alrededor de guiones\n",
    "    texto = re.sub(r'[^a-zA-Z0-9\\s-]', '', texto)  # Remueve caracteres raros excepto letras, d√≠gitos y guiones\n",
    "    return texto\n",
    "\n",
    "def remove_rare_characters(texto):\n",
    "    return re.sub(r'[^a-zA-Z\\s]', '', texto)\n",
    "\n",
    "def remove_tildes(texto):\n",
    "    return ''.join((c for c in unicodedata.normalize('NFD', texto) if unicodedata.category(c) != 'Mn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb8eb2f",
   "metadata": {},
   "source": [
    "### Com√∫n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25bf119d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.\n",
    "def drop_nan_rows(df):\n",
    "    df = df.dropna(how='all')\n",
    "    return df\n",
    "\n",
    "# 1. \n",
    "def drop_nan_columns(df):\n",
    "    return df.dropna(axis=1, how='all')\n",
    "\n",
    "# 2.\n",
    "def swap_first_second_row(df):\n",
    "    temp = df.iloc[0, 0]\n",
    "    df.iloc[0, 0] = df.iloc[1, 0]\n",
    "    df.iloc[1, 0] = temp\n",
    "\n",
    "    temp = df.iloc[0, -1]\n",
    "    df.iloc[0, -1] = df.iloc[1, -1]\n",
    "    df.iloc[1, -1] = temp\n",
    "    return df\n",
    "\n",
    "# 8. \n",
    "def reset_index(df):\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df\n",
    "\n",
    "# 5.\n",
    "def remove_digit_slash(df):\n",
    "    # Aplica la funci√≥n de reemplazo a la primera columna y a las dos √∫ltimas columnas\n",
    "    df.iloc[:, [0, -2, -1]] = df.iloc[:, [0, -2, -1]].apply(lambda x: x.str.replace(r'\\d+/', '', regex=True))\n",
    "    return df\n",
    "\n",
    "# 9. AUX (ROBUSTO)\n",
    "\n",
    "def separate_text_digits(df):\n",
    "    for index, row in df.iterrows():\n",
    "        if any(char.isdigit() for char in str(row.iloc[-2])) and any(char.isalpha() for char in str(row.iloc[-2])):\n",
    "            if pd.isnull(row.iloc[-1]):\n",
    "                df.loc[index, df.columns[-1]] = ''.join(filter(lambda x: x.isalpha() or x == ' ', str(row.iloc[-2])))\n",
    "                df.loc[index, df.columns[-2]] = ''.join(filter(lambda x: not (x.isalpha() or x == ' '), str(row.iloc[-2])))\n",
    "            \n",
    "            # Check if comma or dot is used as decimal separator\n",
    "            if ',' in str(row.iloc[-2]):\n",
    "                split_values = str(row.iloc[-2]).split(',')\n",
    "            elif '.' in str(row.iloc[-2]):\n",
    "                split_values = str(row.iloc[-2]).split('.')\n",
    "            else:\n",
    "                # If neither comma nor dot found, assume no decimal part\n",
    "                split_values = [str(row.iloc[-2]), '']\n",
    "                \n",
    "            cleaned_integer = ''.join(filter(lambda x: x.isdigit() or x == '-', split_values[0]))\n",
    "            cleaned_decimal = ''.join(filter(lambda x: x.isdigit(), split_values[1]))\n",
    "            if cleaned_decimal:\n",
    "                # Use comma as decimal separator\n",
    "                cleaned_numeric = cleaned_integer + ',' + cleaned_decimal\n",
    "            else:\n",
    "                cleaned_numeric = cleaned_integer\n",
    "            df.loc[index, df.columns[-2]] = cleaned_numeric\n",
    "    return df\n",
    "\n",
    "\n",
    "# 4. \n",
    "def extract_years(df):\n",
    "    year_columns = [col for col in df.columns if re.match(r'\\b\\d{4}\\b', col)]\n",
    "    #print(\"A√±os (4 d√≠gitos) extra√≠dos:\")\n",
    "    #print(year_columns)\n",
    "    return year_columns\n",
    "\n",
    "# 6. \n",
    "def first_row_columns(df):\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.drop(df.index[0])\n",
    "    return df\n",
    "\n",
    "# 15.\n",
    "def clean_columns_values(df):\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Only normalize string column names\n",
    "    df.columns = [unicodedata.normalize('NFKD', col).encode('ASCII', 'ignore').decode('utf-8') if isinstance(col, str) else col for col in df.columns]\n",
    "    df.columns = df.columns.str.replace(' ', '_').str.replace('ano', 'year').str.replace('-', '_')\n",
    "    \n",
    "    text_columns = df.select_dtypes(include='object').columns\n",
    "    for col in df.columns:\n",
    "        df.loc[:, col] = df[col].apply(lambda x: remove_tildes(x) if isinstance(x, str) else x)\n",
    "        df.loc[:, col] = df[col].apply(lambda x: str(x).replace(',', '.') if isinstance(x, (int, float, str)) else x)\n",
    "    df.loc[:, 'sectores_economicos'] = df['sectores_economicos'].str.lower()\n",
    "    df.loc[:, 'economic_sectors'] = df['economic_sectors'].str.lower()\n",
    "    df.loc[:, 'sectores_economicos'] = df['sectores_economicos'].apply(remove_rare_characters)\n",
    "    df.loc[:, 'economic_sectors'] = df['economic_sectors'].apply(remove_rare_characters)\n",
    "    return df\n",
    "\n",
    "# 16.\n",
    "def convertir_float(df):\n",
    "    excluded_columns = ['sectores_economicos', 'economic_sectors']\n",
    "    columns_to_convert = [col for col in df.columns if col not in excluded_columns]\n",
    "    df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "    return df\n",
    "\n",
    "# 15.\n",
    "def relocate_last_column(df):\n",
    "    last_column = df.pop(df.columns[-1])\n",
    "    df.insert(1, last_column.name, last_column)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ed8745",
   "metadata": {},
   "source": [
    "### Exclusiva Tabla 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6981f802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATIPIC LAST COLUMNS\n",
    "def relocate_last_columns(df):\n",
    "    if not pd.isna(df.iloc[1, -1]):\n",
    "        # Create a new column with NaN\n",
    "        new_column = 'col_' + ''.join(map(str, np.random.randint(1, 5, size=1)))\n",
    "        df[new_column] = np.nan\n",
    "        \n",
    "        # Get 'ECONOMIC SECTORS' and relocate\n",
    "        insert_value_1 = df.iloc[0, -2]\n",
    "        # Convert the value to string before assignment\n",
    "        insert_value_1 = str(insert_value_1)\n",
    "        # Ensure the dtype of the last column is object (string) to accommodate string values\n",
    "        df.iloc[:, -1] = df.iloc[:, -1].astype('object')\n",
    "        df.iloc[0, -1] = insert_value_1\n",
    "        \n",
    "        # NaN first obs\n",
    "        df.iloc[0,-2] = np.nan\n",
    "    return df\n",
    "\n",
    "# Extraer meses\n",
    "\n",
    "def get_months_sublist_list(df, year_columns):\n",
    "    first_row = df.iloc[0]\n",
    "    # Initialize the list of sublists\n",
    "    months_sublist_list = []\n",
    "\n",
    "    # Initialize the current sublist\n",
    "    months_sublist = []\n",
    "\n",
    "    # Iterate over the elements of the first row\n",
    "    for item in first_row:\n",
    "        # Check if the item meets the requirements\n",
    "        if len(str(item)) == 3:\n",
    "            months_sublist.append(item)\n",
    "        elif '-' in item or str(item) == 'year':\n",
    "            months_sublist.append(item)\n",
    "            months_sublist_list.append(months_sublist)\n",
    "            months_sublist = []\n",
    "\n",
    "    # Add the last sublist if it's not empty\n",
    "    if months_sublist:\n",
    "        months_sublist_list.append(months_sublist)\n",
    "\n",
    "    new_elements = []\n",
    "\n",
    "    # Check if year_columns is not empty\n",
    "    if year_columns:\n",
    "        for i, year in enumerate(year_columns):\n",
    "            # Check if index i is valid for quarters_sublist_list\n",
    "            if i < len(months_sublist_list):\n",
    "                for element in months_sublist_list[i]:\n",
    "                    new_elements.append(f\"{year}_{element}\")\n",
    "                    \n",
    "    two_first_elements = df.iloc[0][:2].tolist()\n",
    "\n",
    "    # Ensure that the two_first_elements are added if they are not in new_elements\n",
    "    for index in range(len(two_first_elements) - 1, -1, -1):\n",
    "        if two_first_elements[index] not in new_elements:\n",
    "            new_elements.insert(0, two_first_elements[index])\n",
    "\n",
    "    # Ensure that the length of new_elements matches the number of columns in df\n",
    "    while len(new_elements) < len(df.columns):\n",
    "        new_elements.append(None)\n",
    "\n",
    "    temp_df = pd.DataFrame([new_elements], columns=df.columns)\n",
    "    df.iloc[0] = temp_df.iloc[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_year_column(df):\n",
    "    # List to store the found years\n",
    "    found_years = []\n",
    "\n",
    "    # Iterating over the column names of the DataFrame\n",
    "    for column in df.columns:\n",
    "        # Checking if the column name is a year (4 digits)\n",
    "        if column.isdigit() and len(column) == 4:\n",
    "            found_years.append(column)\n",
    "\n",
    "    # If more than one year is found, do nothing\n",
    "    if len(found_years) > 1:\n",
    "        pass\n",
    "    # If exactly one year is found, implement additional code\n",
    "    elif len(found_years) == 1:\n",
    "        # Getting the name of the found year\n",
    "        year_name = found_years[0]\n",
    "        print(\"The name of the column representing the year is:\", year_name)\n",
    "\n",
    "        # Getting the first row of the DataFrame\n",
    "        first_row = df.iloc[0]\n",
    "\n",
    "        # Searching for the first column containing the word \"year\" or some hyphen-separated expression\n",
    "        column_contains_year = first_row[first_row.astype(str).str.contains(r'\\byear\\b')]\n",
    "\n",
    "        if not column_contains_year.empty:\n",
    "            # Getting the name of the first column containing 'year' or some hyphen-separated expression in the first row\n",
    "            column_contains_year_name = column_contains_year.index[0]\n",
    "            print(\"The name of the first column containing 'year' or some hyphen-separated expression in the first row is:\", column_contains_year_name)\n",
    "\n",
    "            # Getting the indices of the columns\n",
    "            column_contains_year_index = df.columns.get_loc(column_contains_year_name)\n",
    "            year_name_index = df.columns.get_loc(year_name)\n",
    "            print(\"The index of the column containing 'year' is:\", column_contains_year_index)\n",
    "            print(\"The index of the column representing the year is:\", year_name_index)\n",
    "\n",
    "            # Checking if the column representing the year is to the right or to the left of column_contains_year\n",
    "            if column_contains_year_index < year_name_index:\n",
    "                print(\"The year column is to the right of the column containing 'year'.\")\n",
    "                # Adding one to the year\n",
    "                new_year = str(int(year_name) - 1)\n",
    "                # Renaming the column containing 'year' with the new year\n",
    "                df.rename(columns={column_contains_year_name: new_year}, inplace=True)\n",
    "                print(f\"The column containing 'year' is now named '{new_year}'.\")\n",
    "            elif column_contains_year_index > year_name_index:\n",
    "                print(\"The year column is to the left of the column containing 'year'.\")\n",
    "                # Subtracting one from the year\n",
    "                new_year = str(int(year_name) + 1)\n",
    "                # Renaming the year column with the new year\n",
    "                df.rename(columns={column_contains_year_name: new_year}, inplace=True)\n",
    "                print(f\"The column containing 'year' is now named '{new_year}'.\")\n",
    "            else:\n",
    "                print(\"The year column is in the same position as the column containing 'year'.\")\n",
    "        else:\n",
    "            print(\"No columns containing 'year' were found in the first row.\")\n",
    "    # If no year is found, print a message\n",
    "    else:\n",
    "        print(\"No years were found in the column names.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "#\n",
    "\n",
    "def clean_first_row(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            if isinstance(df.at[0, col], str):\n",
    "                df.at[0, col] = df.at[0, col].lower()  # Convertir a min√∫sculas solo si es un objeto\n",
    "                df.at[0, col] = remove_tildes(df.at[0, col])\n",
    "                df.at[0, col] = remove_rare_characters_first_row(df.at[0, col])\n",
    "                # Reemplazar 'ano' por 'year'\n",
    "                df.at[0, col] = df.at[0, col].replace('ano', 'year')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def intercambiar_valores(df):\n",
    "    # Verificar si hay al menos dos columnas en el DataFrame\n",
    "    if len(df.columns) < 2:\n",
    "        print(\"El DataFrame tiene menos de dos columnas. No se pueden intercambiar valores.\")\n",
    "        return df\n",
    "\n",
    "    # Verificar si hay valores NaN en la √∫ltima columna\n",
    "    if df.iloc[:, -1].isnull().any():\n",
    "        # Obtener √≠ndice de filas con NaN en la √∫ltima columna\n",
    "        last_column_rows_nan = df[df.iloc[:, -1].isnull()].index\n",
    "\n",
    "        # Iterar sobre las filas con NaN en la √∫ltima columna\n",
    "        for idx in last_column_rows_nan:\n",
    "            # Verificar si el √≠ndice est√° dentro del rango de las columnas\n",
    "            if -2 >= -len(df.columns):\n",
    "                # Intercambiar los valores de la √∫ltima columna y la pen√∫ltima columna\n",
    "                df.iloc[idx, -1], df.iloc[idx, -2] = df.iloc[idx, -2], df.iloc[idx, -1]\n",
    "            else:\n",
    "                print(f\"√çndice fuera de rango para la fila {idx}. No se pueden intercambiar valores.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "def replace_var_perc_first_column(df):\n",
    "    # Regular expression to search for \"Var. %\" or \"Var.%\"\n",
    "    regex = re.compile(r'Var\\. ?%')\n",
    "\n",
    "    # Iterate over the rows of the dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Convert the value in the first column to a string\n",
    "        value = str(row.iloc[0])\n",
    "\n",
    "        # Check if the value matches the regular expression\n",
    "        if regex.search(value):\n",
    "            # Replace only the characters that match the regular expression\n",
    "            df.at[index, df.columns[0]] = regex.sub(\"variacion porcentual\", value)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# 8.\n",
    "number_moving_average = 'three ' # Keep a space at the end\n",
    "\n",
    "def replace_number_moving_average(df):\n",
    "    for index, row in df.iterrows():\n",
    "        # Buscar la expresi√≥n regular en la pen√∫ltima o √∫ltima columna\n",
    "        if pd.notnull(row.iloc[-1]) and re.search(r'(\\d\\s*-)', str(row.iloc[-1])):\n",
    "            df.at[index, df.columns[-1]] = re.sub(r'(\\d\\s*-)', f'{number_moving_average}-', str(row.iloc[-1]))\n",
    "        elif pd.notnull(row.iloc[-2]) and re.search(r'(\\d\\s*-)', str(row.iloc[-2])):\n",
    "            df.at[index, df.columns[-2]] = re.sub(r'(\\d\\s*-)', f'{number_moving_average}-', str(row.iloc[-2]))\n",
    "    return df\n",
    "\n",
    "\n",
    "# 7.\n",
    "def replace_var_perc_last_columns(df):\n",
    "    # Expresi√≥n regular para buscar \"Var. %\" o \"Var.%\"\n",
    "    regex = re.compile(r'(Var\\. ?%)(.*)')\n",
    "\n",
    "    # Iterar sobre las filas del dataframe\n",
    "    for index, row in df.iterrows():\n",
    "        # Verificar si el valor en la pen√∫ltima columna es una cadena no nula\n",
    "        if isinstance(row.iloc[-2], str) and regex.search(row.iloc[-2]):\n",
    "            # Realizar el reemplazo al final del valor de la pen√∫ltima columna\n",
    "            replaced_text = regex.sub(r'\\2 percent change', row.iloc[-2])\n",
    "            df.at[index, df.columns[-2]] = replaced_text.strip()\n",
    "        \n",
    "        # Verificar si el valor en la √∫ltima columna es una cadena no nula\n",
    "        if isinstance(row.iloc[-1], str) and regex.search(row.iloc[-1]):\n",
    "            # Realizar el reemplazo al final del valor de la √∫ltima columna\n",
    "            replaced_text = regex.sub(r'\\2 percent change', row.iloc[-1])\n",
    "            df.at[index, df.columns[-1]] = replaced_text.strip()\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Funci√≥n para buscar y reemplazar en la segunda fila del DataFrame\n",
    "def replace_first_dot(df):\n",
    "    second_row = df.iloc[1]  # Segunda fila del DataFrame\n",
    "    \n",
    "    # Verificar si al menos una observaci√≥n cumple con el patr√≥n\n",
    "    if any(isinstance(cell, str) and re.match(r'^\\w+\\.\\s?\\w+', cell) for cell in second_row):\n",
    "        for col in df.columns:\n",
    "            if isinstance(second_row[col], str):  # Verificar si el valor es una cadena\n",
    "                if re.match(r'^\\w+\\.\\s?\\w+', second_row[col]):  # Verificar si cumple con el patr√≥n Xxx.Xxx o Xxx. Xxx.\n",
    "                    df.at[1, col] = re.sub(r'(\\w+)\\.(\\s?\\w+)', r'\\1-\\2', second_row[col], count=1)  # Reemplazar solo el primer punto\n",
    "    return df\n",
    "\n",
    "def drop_rare_caracter_row(df):\n",
    "    # Buscar el caracter solitario \"}\" en cada fila y obtener un booleano para cada fila\n",
    "    rare_caracter_row = df.apply(lambda row: '}' in row.values, axis=1)\n",
    "    \n",
    "    # Filtrar el DataFrame para eliminar las filas con el caracter solitario \"}\"\n",
    "    df = df[~rare_caracter_row]\n",
    "    \n",
    "    return df\n",
    "\n",
    "def split_column_by_pattern(df):\n",
    "    # Iteramos sobre las columnas del dataframe\n",
    "    for col in df.columns:\n",
    "        # Verificamos si la segunda fila de la columna contiene el patr√≥n\n",
    "        if re.match(r'^[A-Z][a-z]+\\.\\s[A-Z][a-z]+\\.$', str(df.iloc[1][col])):\n",
    "            # Realizamos el split de la columna usando como criterio el espacio\n",
    "            split_values = df[col].str.split(expand=True)\n",
    "            # Guardamos los primeros valores en la columna original\n",
    "            df[col] = split_values[0]\n",
    "            # Guardamos los segundos valores en una nueva columna con el sufijo \"_split\"\n",
    "            new_col_name = col + '_split'\n",
    "            df.insert(df.columns.get_loc(col) + 1, new_col_name, split_values[1])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b3bf9",
   "metadata": {},
   "source": [
    "### Exclusiva Tabla 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8911f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_first_row(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            if isinstance(df.at[0, col], str):\n",
    "                df.at[0, col] = df.at[0, col].lower()  # Convertir a min√∫sculas solo si es un objeto\n",
    "                df.at[0, col] = remove_tildes(df.at[0, col])\n",
    "                df.at[0, col] = remove_rare_characters_first_row(df.at[0, col])\n",
    "                # Reemplazar 'ano' por 'year'\n",
    "                df.at[0, col] = df.at[0, col].replace('ano', 'year')\n",
    "\n",
    "    return df\n",
    "\n",
    "# 2.\n",
    "def separate_years(df):\n",
    "    df = df.copy()  # Se crea una copia del DataFrame para evitar SettingWithCopyWarning\n",
    "    if isinstance(df.iloc[0, -2], str) and len(df.iloc[0, -2].split()) == 2:\n",
    "        years = df.iloc[0, -2].split()\n",
    "        if all(len(year) == 4 for year in years):\n",
    "            segundo_anio = years[1]\n",
    "            df.iloc[0, -2] = years[0]\n",
    "            df.insert(len(df.columns) - 1, 'new_column', [segundo_anio] + [None] * (len(df) - 1))\n",
    "    return df\n",
    "\n",
    "# 3.\n",
    "def find_roman_numerals(text):\n",
    "    pattern = r'\\b(?:I{1,3}|IV|V|VI{0,3}|IX|X)\\b'\n",
    "    matches = re.findall(pattern, text)\n",
    "    return matches\n",
    "\n",
    "def relocate_roman_numerals(df):\n",
    "    numeros_romanos = find_roman_numerals(df.iloc[2, -1])\n",
    "    if numeros_romanos:\n",
    "        original_text = df.iloc[2, -1]\n",
    "        for roman_numeral in numeros_romanos:\n",
    "            original_text = original_text.replace(roman_numeral, '').strip()\n",
    "        df.iloc[2, -1] = original_text\n",
    "        df.at[2, 'new_column'] = ', '.join(numeros_romanos)\n",
    "        df.iloc[2, -1] = np.nan\n",
    "    return df\n",
    "\n",
    "# 4.\n",
    "def extract_mixed_values(df):\n",
    "    df = df.copy()  # Se crea una copia del DataFrame para evitar SettingWithCopyWarning\n",
    "    regex_pattern = r'(-?\\d+,\\d [a-zA-Z\\s]+)'\n",
    "    for index, row in df.iterrows():\n",
    "        antepenultima_obs = row.iloc[-3]\n",
    "        penultima_obs = row.iloc[-2]\n",
    "\n",
    "        if isinstance(antepenultima_obs, str) and pd.notnull(antepenultima_obs):\n",
    "            match = re.search(regex_pattern, antepenultima_obs)\n",
    "            if match:\n",
    "                parte_extraida = match.group(0)\n",
    "                if pd.isna(penultima_obs) or pd.isnull(penultima_obs):\n",
    "                    df.iloc[index, -2] = parte_extraida\n",
    "                    antepenultima_obs = re.sub(regex_pattern, '', antepenultima_obs).strip()\n",
    "                    df.iloc[index, -3] = antepenultima_obs\n",
    "    return df\n",
    "\n",
    "# 5.\n",
    "def replace_first_row_nan(df):\n",
    "    for col in df.columns:\n",
    "        if pd.isna(df.iloc[0][col]):\n",
    "            df.iloc[0, df.columns.get_loc(col)] = col\n",
    "    return df\n",
    "\n",
    "# 11. \n",
    "def split_values(df):\n",
    "    columna_a_expandir = df.columns[-3]\n",
    "    nuevas_columnas = df[columna_a_expandir].str.split(expand=True)\n",
    "    nuevas_columnas.columns = [f'{columna_a_expandir}_{i+1}' for i in range(nuevas_columnas.shape[1])]\n",
    "    posicion_insercion = len(df.columns) - 2\n",
    "    for col in reversed(nuevas_columnas.columns):\n",
    "        df.insert(posicion_insercion, col, nuevas_columnas[col])\n",
    "    df.drop(columns=[columna_a_expandir], inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 13.\n",
    "def roman_arabic(df):\n",
    "    primera_fila = df.iloc[0]\n",
    "    def convert_roman_number(numero):\n",
    "        try:\n",
    "            return str(roman.fromRoman(numero))\n",
    "        except roman.InvalidRomanNumeralError:\n",
    "            return numero\n",
    "\n",
    "    primera_fila_convertida = []\n",
    "    for valor in primera_fila:\n",
    "        if isinstance(valor, str) and not pd.isna(valor):\n",
    "            primera_fila_convertida.append(convert_roman_number(valor))\n",
    "        else:\n",
    "            primera_fila_convertida.append(valor)\n",
    "\n",
    "    df.iloc[0] = primera_fila_convertida\n",
    "    return df\n",
    "\n",
    "# 14.\n",
    "def fix_duplicates(df):\n",
    "    fila_segunda = df.iloc[0].copy()\n",
    "    prev_num = None\n",
    "    first_one_index = None\n",
    "\n",
    "    for i, num in enumerate(fila_segunda):\n",
    "        try:\n",
    "            num = int(num)\n",
    "            prev_num = int(prev_num) if prev_num is not None else None\n",
    "\n",
    "            if num == prev_num:\n",
    "                if num == 1:\n",
    "                    if first_one_index is None:\n",
    "                        first_one_index = i - 1\n",
    "                    next_num = int(fila_segunda[i - 1]) + 1\n",
    "                    for j in range(i, len(fila_segunda)):\n",
    "                        if fila_segunda.iloc[j].isdigit():\n",
    "                            fila_segunda.iloc[j] = str(next_num)\n",
    "                            next_num += 1\n",
    "                elif i - 1 >= 0:\n",
    "                    fila_segunda.iloc[i] = str(int(fila_segunda.iloc[i - 1]) + 1)\n",
    "\n",
    "            prev_num = num\n",
    "        except ValueError:\n",
    "            pass\n",
    "\n",
    "    df.iloc[0] = fila_segunda\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# 16. \n",
    "def get_quarters_sublist_list(df):\n",
    "    first_row = df.iloc[0]\n",
    "    # Initialize the list of sublists\n",
    "    quarters_sublist_list = []\n",
    "\n",
    "    # Initialize the current sublist\n",
    "    quarters_sublist = []\n",
    "\n",
    "    # Iterate over the elements of the first row\n",
    "    for item in first_row:\n",
    "        # Check if the item meets the requirements\n",
    "        if len(item) == 1:\n",
    "            quarters_sublist.append(item)\n",
    "        elif item == 'year':\n",
    "            quarters_sublist.append(item)\n",
    "            quarters_sublist_list.append(quarters_sublist)\n",
    "            quarters_sublist = []\n",
    "\n",
    "    # Add the last sublist if it's not empty\n",
    "    if quarters_sublist:\n",
    "        quarters_sublist_list.append(quarters_sublist)\n",
    "\n",
    "    new_elements = []\n",
    "\n",
    "    for i, year in enumerate(year_columns):\n",
    "        for element in quarters_sublist_list[i]:\n",
    "            new_elements.append(f\"{year}_{element}\")\n",
    "\n",
    "    two_first_elements = df.iloc[0][:2].tolist()\n",
    "\n",
    "    # Ensure that the two_first_elements are added if they are not in new_elements\n",
    "    for index in range(len(two_first_elements) - 1, -1, -1):\n",
    "        if two_first_elements[index] not in new_elements:\n",
    "            new_elements.insert(0, two_first_elements[index])\n",
    "\n",
    "    # Ensure that the length of new_elements matches the number of columns in df\n",
    "    while len(new_elements) < len(df.columns):\n",
    "        new_elements.append(None)\n",
    "        \n",
    "    temp_df = pd.DataFrame([new_elements], columns=df.columns)\n",
    "    df.iloc[0] = temp_df.iloc[0]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba6224f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_quarters_sublist_list(df, year_columns):\n",
    "    first_row = df.iloc[0]\n",
    "    # Initialize the list of sublists\n",
    "    quarters_sublist_list = []\n",
    "\n",
    "    # Initialize the current sublist\n",
    "    quarters_sublist = []\n",
    "\n",
    "    # Iterate over the elements of the first row\n",
    "    for item in first_row:\n",
    "        # Check if the item meets the requirements\n",
    "        if len(str(item)) == 1:\n",
    "            quarters_sublist.append(item)\n",
    "        elif str(item) == 'year':\n",
    "            quarters_sublist.append(item)\n",
    "            quarters_sublist_list.append(quarters_sublist)\n",
    "            quarters_sublist = []\n",
    "\n",
    "    # Add the last sublist if it's not empty\n",
    "    if quarters_sublist:\n",
    "        quarters_sublist_list.append(quarters_sublist)\n",
    "\n",
    "    new_elements = []\n",
    "\n",
    "    # Check if year_columns is not empty\n",
    "    if year_columns:\n",
    "        for i, year in enumerate(year_columns):\n",
    "            # Check if index i is valid for quarters_sublist_list\n",
    "            if i < len(quarters_sublist_list):\n",
    "                for element in quarters_sublist_list[i]:\n",
    "                    new_elements.append(f\"{year}_{element}\")\n",
    "\n",
    "    two_first_elements = df.iloc[0][:2].tolist()\n",
    "\n",
    "    # Ensure that the two_first_elements are added if they are not in new_elements\n",
    "    for index in range(len(two_first_elements) - 1, -1, -1):\n",
    "        if two_first_elements[index] not in new_elements:\n",
    "            new_elements.insert(0, two_first_elements[index])\n",
    "\n",
    "    # Ensure that the length of new_elements matches the number of columns in df\n",
    "    while len(new_elements) < len(df.columns):\n",
    "        new_elements.append(None)\n",
    "\n",
    "    temp_df = pd.DataFrame([new_elements], columns=df.columns)\n",
    "    df.iloc[0] = temp_df.iloc[0]\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88524d6",
   "metadata": {},
   "source": [
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tabula\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import locale\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO\n",
    "import os\n",
    "\n",
    "# Establecer la localizaci√≥n en espa√±ol\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Palabras clave para buscar en el texto de la p√°gina\n",
    "keywords = [\"ECONOMIC SECTORS\"]\n",
    "\n",
    "# Diccionario para almacenar los DataFrames generados\n",
    "dataframes_dict = {}\n",
    "\n",
    "# Funci√≥n para corregir los nombres de los meses\n",
    "def corregir_nombre_mes(mes):\n",
    "    meses_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Agrega m√°s mapeos si es necesario para otros nombres de meses\n",
    "    }\n",
    "    return meses_mapping.get(mes, mes)\n",
    "\n",
    "def procesar_pdf(pdf_path):\n",
    "    tables_dict = {}  # Diccionario local para cada PDF\n",
    "    table_counter = 1\n",
    "    keyword_count = 0 \n",
    "\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No se encontraron coincidencias para id_ns y year en el nombre del archivo:\", filename)\n",
    "        return None, None, None, None, None  # Return None for tables_dict as well\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(pdf_path))[0].replace('-', '_')\n",
    "    date = None\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, 1):\n",
    "            text = page.extract_text()\n",
    "            if i == 1:\n",
    "                match = re.search(r'(\\d{1,2}\\s+de\\s+\\w+\\s+de\\s+\\d{4})', text, re.IGNORECASE)\n",
    "                if match:\n",
    "                    fecha_str = match.group(0)\n",
    "                    # Corregir el nombre del mes\n",
    "                    partes_fecha = fecha_str.split()\n",
    "                    partes_fecha[2] = corregir_nombre_mes(partes_fecha[2].lower())\n",
    "                    fecha_str_corregida = ' '.join(partes_fecha)\n",
    "                    date = datetime.strptime(fecha_str_corregida, '%d de %B de %Y')\n",
    "\n",
    "            if all(keyword in text for keyword in keywords):\n",
    "                keyword_count += 1\n",
    "                if keyword_count == 1:  # Solo procesar la primera ocurrencia\n",
    "                    tables = tabula.read_pdf(pdf_path, pages=i, multiple_tables=False, stream=True) # change stream to another option if desired\n",
    "                    for j, table_df in enumerate(tables, start=1):\n",
    "                        nombre_dataframe = f\"{new_filename}_{keyword_count}\"\n",
    "                        tables_dict[nombre_dataframe] = table_df\n",
    "                        table_counter += 1\n",
    "\n",
    "                    break  # Salir del bucle despu√©s de encontrar la primera ocurrencia\n",
    "\n",
    "    return id_ns, year, date, tables_dict, keyword_count  # Return tables_dict here\n",
    "\n",
    "\n",
    "def procesar_carpeta(carpeta):\n",
    "    print(f\"Procesando la carpeta {os.path.basename(carpeta)}\")\n",
    "    pdf_files = [os.path.join(carpeta, f) for f in os.listdir(carpeta) if f.endswith('.pdf')]\n",
    "\n",
    "    num_pdfs_procesados = 0\n",
    "    num_dataframes_generados = 0\n",
    "\n",
    "    table_counter = 1  # Inicializar el contador de tabla aqu√≠\n",
    "    tables_dict = {}  # Declarar tables_dict fuera del bucle principal\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        id_ns, year, date, tables_dict_temp, keyword_count = procesar_pdf(pdf_file)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for nombre_df, df in tables_dict_temp.items():\n",
    "                nombre_archivo = os.path.splitext(os.path.basename(pdf_file))[0].replace('-', '_')\n",
    "                nombre_df = f\"{nombre_archivo}_{keyword_count}\"\n",
    "                \n",
    "                # Almacenar DataFrame sin procesar en tables_dict\n",
    "                tables_dict[nombre_df] = df.copy()\n",
    "                \n",
    "                # Aplicar las 20 l√≠neas de funciones de limpieza a una copia del DataFrame\n",
    "                df_clean = df.copy()\n",
    "                df_clean = split_column_by_pattern(df_clean)\n",
    "                df_clean = drop_rare_caracter_row(df_clean)\n",
    "                df_clean = drop_nan_rows(df_clean)\n",
    "                df_clean = drop_nan_columns(df_clean)\n",
    "                df_clean = relocate_last_columns(df_clean)\n",
    "                df_clean = replace_first_dot(df_clean)\n",
    "                df_clean = swap_first_second_row(df_clean)\n",
    "                df_clean = drop_nan_rows(df_clean)\n",
    "                df_clean = reset_index(df_clean)\n",
    "                df_clean = remove_digit_slash(df_clean)\n",
    "                df_clean = replace_var_perc_first_column(df_clean)\n",
    "                df_clean = replace_var_perc_last_columns(df_clean)\n",
    "                df_clean = replace_number_moving_average(df_clean)\n",
    "                df_clean = separate_text_digits(df_clean)\n",
    "                df_clean = intercambiar_valores(df_clean)\n",
    "                df_clean = relocate_last_column(df_clean)\n",
    "                df_clean = clean_first_row(df_clean)\n",
    "                df_clean = find_year_column(df_clean)\n",
    "                year_columns = extract_years(df_clean)\n",
    "                df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "                df_clean = first_row_columns(df_clean)\n",
    "                df_clean = clean_columns_values(df_clean)\n",
    "                df_clean = convertir_float(df_clean)\n",
    "                \n",
    "                # A√±adir las columnas 'year', 'id_ns', 'date' al DataFrame limpio\n",
    "                df_clean.insert(0, 'date', date)\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "                df_clean.insert(2, 'year', year)\n",
    "                \n",
    "                # Almacenar DataFrame limpio en dataframes_dict\n",
    "                dataframes_dict[nombre_df] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. El dataframe generado para el archivo {pdf_file} es: {nombre_df}')\n",
    "                num_dataframes_generados += 1\n",
    "                table_counter += 1  # Incrementar el contador de tabla aqu√≠\n",
    "        \n",
    "        num_pdfs_procesados += len(pdf_files)\n",
    "\n",
    "    return num_pdfs_procesados, num_dataframes_generados, tables_dict\n",
    "\n",
    "def procesar_carpetas():\n",
    "    pdf_folder = 'pseudo_raw_pdf'\n",
    "    carpetas = [os.path.join(pdf_folder, d) for d in os.listdir(pdf_folder) if os.path.isdir(os.path.join(pdf_folder, d))]\n",
    "    \n",
    "    tables_dict = {}  # Inicializar tables_dict aqu√≠\n",
    "    \n",
    "    for carpeta in carpetas:\n",
    "        num_pdfs_procesados, num_dataframes_generados, tables_dict_temp = procesar_carpeta(carpeta)\n",
    "        \n",
    "        # Actualizar tables_dict con los valores devueltos de procesar_carpeta()\n",
    "        tables_dict.update(tables_dict_temp)\n",
    "\n",
    "        # Preguntar al usuario si desea continuar con la siguiente carpeta\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Para asegurar que la ventana est√© en primer plano\n",
    "        \n",
    "        mensaje = f\"Se han generado {num_dataframes_generados} dataframes en la carpeta {carpeta}. ¬øDeseas continuar con la siguiente carpeta?\"\n",
    "        continuar = messagebox.askyesno(\"Continuar\", mensaje)\n",
    "        root.destroy()\n",
    "\n",
    "        if not continuar:\n",
    "            print(\"Procesamiento detenido por el usuario.\")\n",
    "            return  # Ensure to return if the user decides to stop processing\n",
    "\n",
    "    print(\"Procesamiento completado para todas las carpetas.\")  # Add a message to indicate completion\n",
    "\n",
    "    return tables_dict  # Devolver tables_dict al final de la funci√≥n\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tables_dict = procesar_carpetas()  # Capturar el valor devuelto de procesar_carpetas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3ce026",
   "metadata": {},
   "source": [
    "# Con registro de carpetas procesdas 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2928fa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando la carpeta 2013\n",
      "  1. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2013.pdf es: ns_01_2013_1\n",
      "  2. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2014.pdf es: ns_01_2014_1\n",
      "  3. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2015.pdf es: ns_01_2015_1\n",
      "  4. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2016.pdf es: ns_01_2016_1\n",
      "  5. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2017.pdf es: ns_01_2017_1\n",
      "  6. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2018.pdf es: ns_01_2018_1\n",
      "  7. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2019.pdf es: ns_01_2019_1\n",
      "  8. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2020.pdf es: ns_01_2020_1\n",
      "  9. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2021.pdf es: ns_01_2021_1\n",
      "  10. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-02-2013.pdf es: ns_02_2013_1\n",
      "  11. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-03-2013.pdf es: ns_03_2013_1\n",
      "  12. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-04-2013.pdf es: ns_04_2013_1\n",
      "  13. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-05-2013.pdf es: ns_05_2013_1\n",
      "  14. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-06-2013.pdf es: ns_06_2013_1\n",
      "  15. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-07-2013.pdf es: ns_07_2013_1\n",
      "The name of the column representing the year is: 2012\n",
      "The name of the first column containing 'year' or some hyphen-separated expression in the first row is: Unnamed: 2\n",
      "The index of the column containing 'year' is: 3\n",
      "The index of the column representing the year is: 10\n",
      "The year column is to the right of the column containing 'year'.\n",
      "The column containing 'year' is now named '2011'.\n",
      "  16. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-09-2013.pdf es: ns_09_2013_1\n",
      "The name of the column representing the year is: 2012\n",
      "The name of the first column containing 'year' or some hyphen-separated expression in the first row is: Unnamed: 2\n",
      "The index of the column containing 'year' is: 3\n",
      "The index of the column representing the year is: 10\n",
      "The year column is to the right of the column containing 'year'.\n",
      "The column containing 'year' is now named '2011'.\n",
      "  17. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-10-2013.pdf es: ns_10_2013_1\n",
      "Procesando la carpeta 2014\n",
      "  1. El dataframe generado para el archivo pseudo_raw_pdf\\2014\\ns-46-2018.pdf es: ns_46_2018_1\n",
      "  2. El dataframe generado para el archivo pseudo_raw_pdf\\2014\\ns-47-2018.pdf es: ns_47_2018_1\n",
      "Procesamiento detenido por el usuario.\n",
      "Procesamiento completado para todas las carpetas.\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import locale\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO\n",
    "import os\n",
    "\n",
    "# Establecer la localizaci√≥n en espa√±ol\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Palabras clave para buscar en el texto de la p√°gina\n",
    "keywords = [\"ECONOMIC SECTORS\"]\n",
    "\n",
    "# Diccionario para almacenar los DataFrames generados\n",
    "dataframes_dict = {}\n",
    "\n",
    "# Ruta del archivo de registro de carpetas procesadas\n",
    "registro_path = 'dataframes_record/carpetas_procesadas_1.txt'\n",
    "\n",
    "# Funci√≥n para corregir los nombres de los meses\n",
    "def corregir_nombre_mes(mes):\n",
    "    meses_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Agrega m√°s mapeos si es necesario para otros nombres de meses\n",
    "    }\n",
    "    return meses_mapping.get(mes, mes)\n",
    "\n",
    "def registrar_carpeta_procesada(carpeta, num_archivos_procesados):\n",
    "    with open(registro_path, 'a') as file:\n",
    "        file.write(f\"{carpeta}:{num_archivos_procesados}\\n\")\n",
    "\n",
    "def carpeta_procesada(carpeta):\n",
    "    if not os.path.exists(registro_path):\n",
    "        return False\n",
    "    with open(registro_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(carpeta):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def procesar_pdf(pdf_path):\n",
    "    tables_dict = {}  # Diccionario local para cada PDF\n",
    "    table_counter = 1\n",
    "    keyword_count = 0 \n",
    "\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No se encontraron coincidencias para id_ns y year en el nombre del archivo:\", filename)\n",
    "        return None, None, None, None, None  # Return None for tables_dict as well\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(pdf_path))[0].replace('-', '_')\n",
    "    date = None\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, 1):\n",
    "            text = page.extract_text()\n",
    "            if i == 1:\n",
    "                match = re.search(r'(\\d{1,2}\\s+de\\s+\\w+\\s+de\\s+\\d{4})', text, re.IGNORECASE)\n",
    "                if match:\n",
    "                    fecha_str = match.group(0)\n",
    "                    # Corregir el nombre del mes\n",
    "                    partes_fecha = fecha_str.split()\n",
    "                    partes_fecha[2] = corregir_nombre_mes(partes_fecha[2].lower())\n",
    "                    fecha_str_corregida = ' '.join(partes_fecha)\n",
    "                    date = datetime.strptime(fecha_str_corregida, '%d de %B de %Y')\n",
    "\n",
    "            if all(keyword in text for keyword in keywords):\n",
    "                keyword_count += 1\n",
    "                if keyword_count == 1:  # Solo procesar la primera ocurrencia\n",
    "                    tables = tabula.read_pdf(pdf_path, pages=i, multiple_tables=False, stream=True) # change stream to another option if desired\n",
    "                    for j, table_df in enumerate(tables, start=1):\n",
    "                        nombre_dataframe = f\"{new_filename}_{keyword_count}\"\n",
    "                        tables_dict[nombre_dataframe] = table_df\n",
    "                        table_counter += 1\n",
    "\n",
    "                    break  # Salir del bucle despu√©s de encontrar la primera ocurrencia\n",
    "\n",
    "    return id_ns, year, date, tables_dict, keyword_count  # Return tables_dict here\n",
    "\n",
    "\n",
    "def procesar_carpeta(carpeta):\n",
    "    print(f\"Procesando la carpeta {os.path.basename(carpeta)}\")\n",
    "    pdf_files = [os.path.join(carpeta, f) for f in os.listdir(carpeta) if f.endswith('.pdf')]\n",
    "\n",
    "    num_pdfs_procesados = 0\n",
    "    num_dataframes_generados = 0\n",
    "\n",
    "    table_counter = 1  # Inicializar el contador de tabla aqu√≠\n",
    "    tables_dict = {}  # Declarar tables_dict fuera del bucle principal\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        id_ns, year, date, tables_dict_temp, keyword_count = procesar_pdf(pdf_file)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for nombre_df, df in tables_dict_temp.items():\n",
    "                nombre_archivo = os.path.splitext(os.path.basename(pdf_file))[0].replace('-', '_')\n",
    "                nombre_df = f\"{nombre_archivo}_{keyword_count}\"\n",
    "                \n",
    "                # Almacenar DataFrame sin procesar en tables_dict\n",
    "                tables_dict[nombre_df] = df.copy()\n",
    "                \n",
    "                # Aplicar las 20 l√≠neas de funciones de limpieza a una copia del DataFrame\n",
    "                df_clean = df.copy()\n",
    "                df_clean = split_column_by_pattern(df_clean)\n",
    "                df_clean = drop_rare_caracter_row(df_clean)\n",
    "                df_clean = drop_nan_rows(df_clean)\n",
    "                df_clean = drop_nan_columns(df_clean)\n",
    "                df_clean = relocate_last_columns(df_clean)\n",
    "                df_clean = replace_first_dot(df_clean)\n",
    "                df_clean = swap_first_second_row(df_clean)\n",
    "                df_clean = drop_nan_rows(df_clean)\n",
    "                df_clean = reset_index(df_clean)\n",
    "                df_clean = remove_digit_slash(df_clean)\n",
    "                df_clean = replace_var_perc_first_column(df_clean)\n",
    "                df_clean = replace_var_perc_last_columns(df_clean)\n",
    "                df_clean = replace_number_moving_average(df_clean)\n",
    "                df_clean = separate_text_digits(df_clean)\n",
    "                df_clean = intercambiar_valores(df_clean)\n",
    "                df_clean = relocate_last_column(df_clean)\n",
    "                df_clean = clean_first_row(df_clean)\n",
    "                df_clean = find_year_column(df_clean)\n",
    "                year_columns = extract_years(df_clean)\n",
    "                df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "                df_clean = first_row_columns(df_clean)\n",
    "                df_clean = clean_columns_values(df_clean)\n",
    "                df_clean = convertir_float(df_clean)\n",
    "                \n",
    "                # A√±adir las columnas 'year', 'id_ns', 'date' al DataFrame limpio\n",
    "                df_clean.insert(0, 'date', date)\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "                df_clean.insert(2, 'year', year)\n",
    "                \n",
    "                # Almacenar DataFrame limpio en dataframes_dict\n",
    "                dataframes_dict[nombre_df] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. El dataframe generado para el archivo {pdf_file} es: {nombre_df}')\n",
    "                num_dataframes_generados += 1\n",
    "                table_counter += 1  # Incrementar el contador de tabla aqu√≠\n",
    "        \n",
    "        num_pdfs_procesados += len(pdf_files)\n",
    "\n",
    "    return num_pdfs_procesados, num_dataframes_generados, tables_dict\n",
    "\n",
    "def procesar_carpetas():\n",
    "    pdf_folder = 'pseudo_raw_pdf'\n",
    "    carpetas = [os.path.join(pdf_folder, d) for d in os.listdir(pdf_folder) if os.path.isdir(os.path.join(pdf_folder, d))]\n",
    "    \n",
    "    tables_dict = {}  # Inicializar tables_dict aqu√≠\n",
    "    \n",
    "    for carpeta in carpetas:\n",
    "        if carpeta_procesada(carpeta):\n",
    "            print(f\"La carpeta {carpeta} ya ha sido procesada.\")\n",
    "            continue\n",
    "        \n",
    "        num_pdfs_procesados, num_dataframes_generados, tables_dict_temp = procesar_carpeta(carpeta)\n",
    "        \n",
    "        # Actualizar tables_dict con los valores devueltos de procesar_carpeta()\n",
    "        tables_dict.update(tables_dict_temp)\n",
    "        \n",
    "        registrar_carpeta_procesada(carpeta, num_pdfs_procesados)\n",
    "\n",
    "        # Preguntar al usuario si desea continuar con la siguiente carpeta\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Para asegurar que la ventana est√© en primer plano\n",
    "        \n",
    "        mensaje = f\"Se han generado {num_dataframes_generados} dataframes en la carpeta {carpeta}. ¬øDeseas continuar con la siguiente carpeta?\"\n",
    "        continuar = messagebox.askyesno(\"Continuar\", mensaje)\n",
    "        root.destroy()\n",
    "\n",
    "        if not continuar:\n",
    "            print(\"Procesamiento detenido por el usuario.\")\n",
    "            break  # Romper el bucle for si el usuario decide no continuar\n",
    "\n",
    "    print(\"Procesamiento completado para todas las carpetas.\")  # Add a message to indicate completion\n",
    "\n",
    "    return tables_dict  # Devolver tables_dict al final de la funci√≥n\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tables_dict = procesar_carpetas()  # Capturar el valor devuelto de procesar_carpetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15f0a6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ns_01_2013_1', 'ns_01_2014_1', 'ns_01_2015_1', 'ns_01_2016_1', 'ns_01_2017_1', 'ns_01_2018_1', 'ns_01_2019_1', 'ns_01_2020_1', 'ns_01_2021_1', 'ns_02_2013_1', 'ns_03_2013_1', 'ns_04_2013_1', 'ns_05_2013_1', 'ns_06_2013_1', 'ns_07_2013_1', 'ns_09_2013_1', 'ns_10_2013_1', 'ns_46_2018_1', 'ns_47_2018_1'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8329629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ns_01_2013_1', 'ns_01_2014_1', 'ns_01_2015_1', 'ns_01_2016_1', 'ns_01_2017_1', 'ns_01_2018_1', 'ns_01_2019_1', 'ns_01_2020_1', 'ns_01_2021_1', 'ns_02_2013_1', 'ns_03_2013_1', 'ns_04_2013_1', 'ns_05_2013_1', 'ns_06_2013_1', 'ns_07_2013_1', 'ns_09_2013_1', 'ns_10_2013_1', 'ns_46_2018_1', 'ns_47_2018_1'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a6cc13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>2011</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>2012</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SECTORES ECON√ìMICOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECONOMIC SECTORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Set.</td>\n",
       "      <td>Oct.</td>\n",
       "      <td>Nov.</td>\n",
       "      <td>Dic.</td>\n",
       "      <td>A√±o</td>\n",
       "      <td>Ene.</td>\n",
       "      <td>Feb.</td>\n",
       "      <td>Mar.</td>\n",
       "      <td>Abr.</td>\n",
       "      <td>May.</td>\n",
       "      <td>Jun.</td>\n",
       "      <td>Jul.</td>\n",
       "      <td>Ago.</td>\n",
       "      <td>Set.</td>\n",
       "      <td>Ene.-Set.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agropecuario</td>\n",
       "      <td>3,4</td>\n",
       "      <td>4,4</td>\n",
       "      <td>4,1</td>\n",
       "      <td>-1,3</td>\n",
       "      <td>3,8</td>\n",
       "      <td>2,9</td>\n",
       "      <td>2,9</td>\n",
       "      <td>2,2</td>\n",
       "      <td>0,9</td>\n",
       "      <td>10,1</td>\n",
       "      <td>10,1</td>\n",
       "      <td>2,0</td>\n",
       "      <td>3,6</td>\n",
       "      <td>4,1</td>\n",
       "      <td>4,6 Agriculture and Livestock</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agr√≠cola</td>\n",
       "      <td>4,2</td>\n",
       "      <td>4,0</td>\n",
       "      <td>3,3</td>\n",
       "      <td>-4,2</td>\n",
       "      <td>3,1</td>\n",
       "      <td>2,2</td>\n",
       "      <td>1,2</td>\n",
       "      <td>0,0</td>\n",
       "      <td>-2,0</td>\n",
       "      <td>13,2</td>\n",
       "      <td>13,7</td>\n",
       "      <td>-0,9</td>\n",
       "      <td>0,8</td>\n",
       "      <td>2,2</td>\n",
       "      <td>4,2</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pecuario</td>\n",
       "      <td>2,6</td>\n",
       "      <td>4,9</td>\n",
       "      <td>5,1</td>\n",
       "      <td>2,1</td>\n",
       "      <td>5,2</td>\n",
       "      <td>3,6</td>\n",
       "      <td>4,7</td>\n",
       "      <td>5,2</td>\n",
       "      <td>7,2</td>\n",
       "      <td>3,3</td>\n",
       "      <td>3,4</td>\n",
       "      <td>6,6</td>\n",
       "      <td>6,9</td>\n",
       "      <td>5,9</td>\n",
       "      <td>5,2</td>\n",
       "      <td>Livestock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0 Unnamed: 1 Unnamed: 2  2011 Unnamed: 4 Unnamed: 5  \\\n",
       "0  SECTORES ECON√ìMICOS        NaN        NaN   NaN        NaN        NaN   \n",
       "1                  NaN       Set.       Oct.  Nov.       Dic.        A√±o   \n",
       "2         Agropecuario        3,4        4,4   4,1       -1,3        3,8   \n",
       "3             Agr√≠cola        4,2        4,0   3,3       -4,2        3,1   \n",
       "4             Pecuario        2,6        4,9   5,1        2,1        5,2   \n",
       "\n",
       "  Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10  2012 Unnamed: 12  \\\n",
       "0        NaN        NaN        NaN        NaN         NaN   NaN         NaN   \n",
       "1       Ene.       Feb.       Mar.       Abr.        May.  Jun.        Jul.   \n",
       "2        2,9        2,9        2,2        0,9        10,1  10,1         2,0   \n",
       "3        2,2        1,2        0,0       -2,0        13,2  13,7        -0,9   \n",
       "4        3,6        4,7        5,2        7,2         3,3   3,4         6,6   \n",
       "\n",
       "  Unnamed: 13 Unnamed: 14                    Unnamed: 15       Unnamed: 16  \n",
       "0         NaN         NaN                            NaN  ECONOMIC SECTORS  \n",
       "1        Ago.        Set.                      Ene.-Set.               NaN  \n",
       "2         3,6         4,1  4,6 Agriculture and Livestock               NaN  \n",
       "3         0,8         2,2                            4,2       Agriculture  \n",
       "4         6,9         5,9                            5,2         Livestock  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_dict['ns_01_2013_1'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "084ecc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_ns</th>\n",
       "      <th>year</th>\n",
       "      <th>sectores_economicos</th>\n",
       "      <th>economic_sectors</th>\n",
       "      <th>2011_set</th>\n",
       "      <th>2011_oct</th>\n",
       "      <th>2011_nov</th>\n",
       "      <th>2011_dic</th>\n",
       "      <th>2011_year</th>\n",
       "      <th>2012_ene</th>\n",
       "      <th>2012_feb</th>\n",
       "      <th>2012_mar</th>\n",
       "      <th>2012_abr</th>\n",
       "      <th>2012_may</th>\n",
       "      <th>2012_jun</th>\n",
       "      <th>2012_jul</th>\n",
       "      <th>2012_ago</th>\n",
       "      <th>2012_set</th>\n",
       "      <th>2012_ene_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>agropecuario</td>\n",
       "      <td>agriculture and livestock</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>agricola</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-4.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>2.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>13.7</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pecuario</td>\n",
       "      <td>livestock</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>5.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pesca</td>\n",
       "      <td>fishing</td>\n",
       "      <td>30.1</td>\n",
       "      <td>35.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>74.5</td>\n",
       "      <td>29.7</td>\n",
       "      <td>-15.5</td>\n",
       "      <td>-10.9</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-44.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-11.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>-7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>mineria e hidrocarburos</td>\n",
       "      <td>mining and fuel</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>mineria metalica</td>\n",
       "      <td>metals</td>\n",
       "      <td>-0.9</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>hidrocarburos</td>\n",
       "      <td>fuel</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.2</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>18.1</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>manufactura</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>3.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>de recursos primarios</td>\n",
       "      <td>based on raw materials</td>\n",
       "      <td>10.7</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>34.9</td>\n",
       "      <td>12.3</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-8.9</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>-9.1</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-5.1</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>no primaria</td>\n",
       "      <td>nonprimary</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.1</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>electricidad y agua</td>\n",
       "      <td>electricity and water</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>construccion</td>\n",
       "      <td>construction</td>\n",
       "      <td>1.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>10.1</td>\n",
       "      <td>14.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>17.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>16.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>comercio</td>\n",
       "      <td>commerce</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>8.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.3</td>\n",
       "      <td>6.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>otros servicios</td>\n",
       "      <td>other services</td>\n",
       "      <td>7.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pbi</td>\n",
       "      <td>gdp</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>sectores primarios</td>\n",
       "      <td>primary sectors</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>sectores no primarios</td>\n",
       "      <td>non primary sectors</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pbi desestacionalizado</td>\n",
       "      <td>seasonally adjusted gdp</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>indicador de demanda interna</td>\n",
       "      <td>domestic demand indicator</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.8</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>7.5</td>\n",
       "      <td>12.6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>indicador de demanda interna desestacionalizada</td>\n",
       "      <td>seasonally adjusted domestic demand indicator</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id_ns  year                               sectores_economicos  \\\n",
       "1  2013-01-04    01  2013                                      agropecuario   \n",
       "2  2013-01-04    01  2013                                          agricola   \n",
       "3  2013-01-04    01  2013                                          pecuario   \n",
       "4  2013-01-04    01  2013                                             pesca   \n",
       "5  2013-01-04    01  2013                           mineria e hidrocarburos   \n",
       "6  2013-01-04    01  2013                                  mineria metalica   \n",
       "7  2013-01-04    01  2013                                     hidrocarburos   \n",
       "8  2013-01-04    01  2013                                       manufactura   \n",
       "9  2013-01-04    01  2013                             de recursos primarios   \n",
       "10 2013-01-04    01  2013                                       no primaria   \n",
       "11 2013-01-04    01  2013                               electricidad y agua   \n",
       "12 2013-01-04    01  2013                                      construccion   \n",
       "13 2013-01-04    01  2013                                          comercio   \n",
       "14 2013-01-04    01  2013                                  otros servicios    \n",
       "15 2013-01-04    01  2013                                               pbi   \n",
       "16 2013-01-04    01  2013                                sectores primarios   \n",
       "17 2013-01-04    01  2013                             sectores no primarios   \n",
       "18 2013-01-04    01  2013                           pbi desestacionalizado    \n",
       "19 2013-01-04    01  2013                      indicador de demanda interna   \n",
       "20 2013-01-04    01  2013  indicador de demanda interna desestacionalizada    \n",
       "\n",
       "                                  economic_sectors  2011_set  2011_oct  \\\n",
       "1                        agriculture and livestock       3.4       4.4   \n",
       "2                                      agriculture       4.2       4.0   \n",
       "3                                        livestock       2.6       4.9   \n",
       "4                                          fishing      30.1      35.1   \n",
       "5                                  mining and fuel       0.7      -0.5   \n",
       "6                                           metals      -0.9      -2.2   \n",
       "7                                             fuel       8.3       6.2   \n",
       "8                                    manufacturing       1.8      -0.4   \n",
       "9                           based on raw materials      10.7      -0.1   \n",
       "10                                      nonprimary       0.5      -0.5   \n",
       "11                           electricity and water       7.6       7.3   \n",
       "12                                    construction       1.6       4.4   \n",
       "13                                        commerce       8.8       8.7   \n",
       "14                                 other services        7.7       6.8   \n",
       "15                                             gdp       5.9       5.3   \n",
       "16                                 primary sectors       4.0       2.3   \n",
       "17                             non primary sectors       6.2       5.8   \n",
       "18                        seasonally adjusted gdp        0.2       0.0   \n",
       "19                       domestic demand indicator       5.9       3.9   \n",
       "20  seasonally adjusted domestic demand indicator        1.0       0.2   \n",
       "\n",
       "    2011_nov  2011_dic  2011_year  2012_ene  2012_feb  2012_mar  2012_abr  \\\n",
       "1        4.1      -1.3        3.8       2.9       2.9       2.2       0.9   \n",
       "2        3.3      -4.2        3.1       2.2       1.2       0.0      -2.0   \n",
       "3        5.1       2.1        5.2       3.6       4.7       5.2       7.2   \n",
       "4        0.3      74.5       29.7     -15.5     -10.9      -4.5     -44.7   \n",
       "5       -1.1       4.2       -0.2      -0.3       3.7       7.2       6.7   \n",
       "6       -1.7       4.4       -3.6       1.4       3.4       5.6       8.7   \n",
       "7        1.9       3.1       18.1      -8.0       5.0      15.3      -1.9   \n",
       "8       -0.2       3.7        5.6      -1.0       1.8      -2.7      -4.1   \n",
       "9       -0.6      34.9       12.3       1.1      -1.4      -8.9     -21.1   \n",
       "10      -0.2      -1.3        4.4      -1.3       2.3      -1.6      -0.3   \n",
       "11       6.9       7.3        7.4       5.7       7.4       5.8       5.1   \n",
       "12       3.2       3.8        3.4      12.5      10.1      14.7      14.6   \n",
       "13       7.0       7.0        8.8       7.7       8.9       7.2       6.1   \n",
       "14       7.4       7.2        8.3       7.1       8.6       7.1       6.6   \n",
       "15       5.1       6.0        6.9       5.5       6.9       5.7       4.5   \n",
       "16       1.4       8.1        4.4       1.0       2.1       1.6      -3.4   \n",
       "17       5.8       5.6        7.4       6.3       7.8       6.4       6.2   \n",
       "18       0.6       0.8        NaN       0.5       0.4       0.6       0.1   \n",
       "19       6.2       5.4        7.2       3.2       5.9       5.8       5.0   \n",
       "20       0.8       0.3        NaN       0.2       0.6       1.0       1.0   \n",
       "\n",
       "    2012_may  2012_jun  2012_jul  2012_ago  2012_set  2012_ene_set  \n",
       "1       10.1      10.1       2.0       3.6       4.1           4.6  \n",
       "2       13.2      13.7      -0.9       0.8       2.2           4.2  \n",
       "3        3.3       3.4       6.6       6.9       5.9           5.2  \n",
       "4        5.4      20.6       0.8     -11.9      19.1          -7.5  \n",
       "5        1.2       4.8       4.3       0.6       5.0           3.6  \n",
       "6        1.6       4.5       4.5       0.1       4.5           3.7  \n",
       "7       -0.6       6.1       3.6       2.7       7.1           3.1  \n",
       "8        2.9       1.6       5.0       4.3       1.3           1.0  \n",
       "9       -9.1      -2.1      -0.4      -5.1      -4.5          -6.2  \n",
       "10       5.4       2.4       6.1       5.9       2.2           2.3  \n",
       "11       5.3       4.7       5.7       5.3       4.2           5.5  \n",
       "12      15.8      19.7      21.4      17.4      19.2          16.2  \n",
       "13       6.5       6.7       6.9       6.5       5.3           6.8  \n",
       "14       7.4       7.5       7.8       6.5       5.9           7.2  \n",
       "15       7.0       7.3       7.4       6.3       5.9           6.3  \n",
       "16       4.4       6.8       2.3       0.7       3.2           2.1  \n",
       "17       7.6       7.4       8.3       7.3       6.4           7.1  \n",
       "18       1.4       0.5       0.6       0.3       0.3           NaN  \n",
       "19       9.6       7.5      12.6      10.0       7.0           7.4  \n",
       "20       1.5       1.0       1.3       0.4       0.3           NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_dict['ns_01_2013_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5108832",
   "metadata": {},
   "source": [
    "# Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4acaf593",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando la carpeta 2013\n",
      "  1. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-09-2013.pdf es: ns_09_2013_2\n",
      "  2. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-10-2013.pdf es: ns_10_2013_2\n",
      "Procesando la carpeta 2018\n",
      "  1. El dataframe generado para el archivo pseudo_raw_pdf\\2018\\ns-48-2018.pdf es: ns_48_2018_2\n",
      "  2. El dataframe generado para el archivo pseudo_raw_pdf\\2018\\ns-49-2018.pdf es: ns_49_2018_2\n",
      "Procesamiento completado para todas las carpetas.\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import roman\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import locale\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO\n",
    "import os\n",
    "\n",
    "\n",
    "# Establecer la localizaci√≥n en espa√±ol\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Palabras clave para buscar en el texto de la p√°gina\n",
    "keywords = [\"ECONOMIC SECTORS\"]\n",
    "\n",
    "# Diccionario para almacenar los DataFrames generados\n",
    "dataframes_dict = {}\n",
    "\n",
    "# Funci√≥n para corregir los nombres de los meses\n",
    "def corregir_nombre_mes(mes):\n",
    "    meses_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Agrega m√°s mapeos si es necesario para otros nombres de meses\n",
    "    }\n",
    "    return meses_mapping.get(mes, mes)\n",
    "\n",
    "def procesar_pdf(pdf_path):\n",
    "    tables_dict = {}  # Diccionario local para cada PDF\n",
    "    table_counter = 1\n",
    "    keyword_count = 0 \n",
    "\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No se encontraron coincidencias para id_ns y year en el nombre del archivo:\", filename)\n",
    "        return None, None, None, None\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(pdf_path))[0].replace('-', '_')\n",
    "    date = None\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, 1):\n",
    "            text = page.extract_text()\n",
    "            if i == 1:\n",
    "                match = re.search(r'(\\d{1,2}\\s+de\\s+\\w+\\s+de\\s+\\d{4})', text, re.IGNORECASE)\n",
    "                if match:\n",
    "                    fecha_str = match.group(0)\n",
    "                    # Corregir el nombre del mes\n",
    "                    partes_fecha = fecha_str.split()\n",
    "                    partes_fecha[2] = corregir_nombre_mes(partes_fecha[2].lower())\n",
    "                    fecha_str_corregida = ' '.join(partes_fecha)\n",
    "                    date = datetime.strptime(fecha_str_corregida, '%d de %B de %Y')\n",
    "\n",
    "            if all(keyword in text for keyword in keywords):\n",
    "                keyword_count += 1\n",
    "                if keyword_count == 2:\n",
    "                    tables = tabula.read_pdf(pdf_path, pages=i, multiple_tables=False)\n",
    "                    for j, table_df in enumerate(tables, start=1):\n",
    "                        nombre_dataframe = f\"{new_filename}_{keyword_count}\"\n",
    "                        tables_dict[nombre_dataframe] = table_df\n",
    "                        table_counter += 1\n",
    "\n",
    "    return id_ns, year, date, tables_dict, keyword_count\n",
    "\n",
    "\n",
    "def procesar_carpeta(carpeta):\n",
    "    print(f\"Procesando la carpeta {os.path.basename(carpeta)}\")\n",
    "    pdf_files = [os.path.join(carpeta, f) for f in os.listdir(carpeta) if f.endswith('.pdf')]\n",
    "\n",
    "    num_pdfs_procesados = 0\n",
    "    num_dataframes_generados = 0\n",
    "\n",
    "    table_counter = 1  # Inicializar el contador de tabla aqu√≠\n",
    "    tables_dict = {}  # Declarar tables_dict fuera del bucle principal\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        id_ns, year, date, tables_dict_temp, keyword_count = procesar_pdf(pdf_file)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for nombre_df, df in tables_dict_temp.items():\n",
    "                nombre_archivo = os.path.splitext(os.path.basename(pdf_file))[0].replace('-', '_')\n",
    "                nombre_df = f\"{nombre_archivo}_{keyword_count}\"\n",
    "\n",
    "                # Almacenar DataFrame sin procesar en tables_dict\n",
    "                tables_dict[nombre_df] = df.copy()\n",
    "\n",
    "                # Aplicar las 20 l√≠neas de funciones de limpieza a una copia del DataFrame\n",
    "                df_clean = df.copy()\n",
    "                if df_clean.iloc[0, 0] is np.nan:\n",
    "                    # Aplicar las 20 l√≠neas de limpieza\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = separate_years(df_clean)\n",
    "                    df_clean = relocate_roman_numerals(df_clean)\n",
    "                    df_clean = extract_mixed_values(df_clean)\n",
    "                    df_clean = replace_first_row_nan(df_clean)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = swap_first_second_row(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = drop_nan_row(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = split_values(df_clean)\n",
    "                    df_clean = separate_text_digits(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convertir_float(df_clean)\n",
    "                else:\n",
    "                    # Aplicar las 15 l√≠neas de limpieza\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = remove_digit_slash(df_clean)\n",
    "                    df_clean = swap_first_second_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = separate_text_digits(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convertir_float(df_clean)\n",
    "\n",
    "                # A√±adir las columnas 'year', 'id_ns', 'date' al DataFrame limpio\n",
    "                df_clean.insert(0, 'date', date)\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "                df_clean.insert(2, 'year', year)\n",
    "\n",
    "                # Almacenar DataFrame limpio en dataframes_dict\n",
    "                dataframes_dict[nombre_df] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. El dataframe generado para el archivo {pdf_file} es: {nombre_df}')\n",
    "                num_dataframes_generados += 1\n",
    "                table_counter += 1  # Incrementar el contador de tabla aqu√≠\n",
    "                    \n",
    "        num_pdfs_procesados += len(pdf_files)\n",
    "\n",
    "    return num_pdfs_procesados, num_dataframes_generados, tables_dict\n",
    "\n",
    "\n",
    "def procesar_carpetas():\n",
    "    pdf_folder = 'pseudo_raw_pdf'\n",
    "    carpetas = [os.path.join(pdf_folder, d) for d in os.listdir(pdf_folder) if os.path.isdir(os.path.join(pdf_folder, d))]\n",
    "\n",
    "    tables_dict = {}  # Inicializar tables_dict aqu√≠\n",
    "    \n",
    "    for carpeta in carpetas:\n",
    "        num_pdfs_procesados, num_dataframes_generados, tables_dict_temp = procesar_carpeta(carpeta)\n",
    "        \n",
    "        # Actualizar tables_dict con los valores devueltos de procesar_carpeta()\n",
    "        tables_dict.update(tables_dict_temp)\n",
    "        \n",
    "        # Preguntar al usuario si desea continuar con la siguiente carpeta\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Para asegurar que la ventana est√© en primer plano\n",
    "        \n",
    "        mensaje = f\"Se han generado {num_dataframes_generados} dataframes en la carpeta {carpeta}. ¬øDeseas continuar con la siguiente carpeta?\"\n",
    "        continuar = messagebox.askyesno(\"Continuar\", mensaje)\n",
    "        root.destroy()\n",
    "                    \n",
    "        if not continuar:\n",
    "            print(\"Procesamiento detenido por el usuario.\")\n",
    "            break\n",
    "    \n",
    "    print(\"Procesamiento completado para todas las carpetas.\")  # Add a message to indicate completion\n",
    "\n",
    "    return tables_dict  # Devolver tables_dict al final de la funci√≥n\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tables_dict = procesar_carpetas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28075a94",
   "metadata": {},
   "source": [
    "# Con registro de carpetas procesdas 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19908f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando la carpeta 2013\n",
      "  1. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2013.pdf es: ns_01_2013_2\n",
      "  2. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2014.pdf es: ns_01_2014_2\n",
      "  3. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2015.pdf es: ns_01_2015_2\n",
      "  4. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2016.pdf es: ns_01_2016_2\n",
      "  5. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2017.pdf es: ns_01_2017_2\n",
      "  6. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2018.pdf es: ns_01_2018_2\n",
      "  7. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2019.pdf es: ns_01_2019_2\n",
      "  8. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2020.pdf es: ns_01_2020_2\n",
      "  9. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-01-2021.pdf es: ns_01_2021_2\n",
      "  10. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-02-2013.pdf es: ns_02_2013_2\n",
      "  11. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-03-2013.pdf es: ns_03_2013_2\n",
      "  12. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-04-2013.pdf es: ns_04_2013_2\n",
      "  13. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-05-2013.pdf es: ns_05_2013_2\n",
      "  14. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-06-2013.pdf es: ns_06_2013_2\n",
      "  15. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-07-2013.pdf es: ns_07_2013_2\n",
      "  16. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-09-2013.pdf es: ns_09_2013_2\n",
      "  17. El dataframe generado para el archivo pseudo_raw_pdf\\2013\\ns-10-2013.pdf es: ns_10_2013_2\n",
      "Procesamiento detenido por el usuario.\n",
      "Procesamiento completado para todas las carpetas.\n"
     ]
    }
   ],
   "source": [
    "import tabula\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import roman\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import locale\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO\n",
    "import os\n",
    "\n",
    "\n",
    "# Establecer la localizaci√≥n en espa√±ol\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Palabras clave para buscar en el texto de la p√°gina\n",
    "keywords = [\"ECONOMIC SECTORS\"]\n",
    "\n",
    "# Diccionario para almacenar los DataFrames generados\n",
    "dataframes_dict = {}\n",
    "\n",
    "# Ruta del archivo de registro de carpetas procesadas\n",
    "registro_path = 'dataframes_record/carpetas_procesadas_2.txt'\n",
    "\n",
    "# Funci√≥n para corregir los nombres de los meses\n",
    "def corregir_nombre_mes(mes):\n",
    "    meses_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Agrega m√°s mapeos si es necesario para otros nombres de meses\n",
    "    }\n",
    "    return meses_mapping.get(mes, mes)\n",
    "\n",
    "def registrar_carpeta_procesada(carpeta, num_archivos_procesados):\n",
    "    with open(registro_path, 'a') as file:\n",
    "        file.write(f\"{carpeta}:{num_archivos_procesados}\\n\")\n",
    "\n",
    "def carpeta_procesada(carpeta):\n",
    "    if not os.path.exists(registro_path):\n",
    "        return False\n",
    "    with open(registro_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(carpeta):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def procesar_pdf(pdf_path):\n",
    "    tables_dict = {}  # Diccionario local para cada PDF\n",
    "    table_counter = 1\n",
    "    keyword_count = 0 \n",
    "\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No se encontraron coincidencias para id_ns y year en el nombre del archivo:\", filename)\n",
    "        return None, None, None, None\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(pdf_path))[0].replace('-', '_')\n",
    "    date = None\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for i, page in enumerate(pdf.pages, 1):\n",
    "            text = page.extract_text()\n",
    "            if i == 1:\n",
    "                match = re.search(r'(\\d{1,2}\\s+de\\s+\\w+\\s+de\\s+\\d{4})', text, re.IGNORECASE)\n",
    "                if match:\n",
    "                    fecha_str = match.group(0)\n",
    "                    # Corregir el nombre del mes\n",
    "                    partes_fecha = fecha_str.split()\n",
    "                    partes_fecha[2] = corregir_nombre_mes(partes_fecha[2].lower())\n",
    "                    fecha_str_corregida = ' '.join(partes_fecha)\n",
    "                    date = datetime.strptime(fecha_str_corregida, '%d de %B de %Y')\n",
    "\n",
    "            if all(keyword in text for keyword in keywords):\n",
    "                keyword_count += 1\n",
    "                if keyword_count == 2:\n",
    "                    tables = tabula.read_pdf(pdf_path, pages=i, multiple_tables=False)\n",
    "                    for j, table_df in enumerate(tables, start=1):\n",
    "                        nombre_dataframe = f\"{new_filename}_{keyword_count}\"\n",
    "                        tables_dict[nombre_dataframe] = table_df\n",
    "                        table_counter += 1\n",
    "\n",
    "    return id_ns, year, date, tables_dict, keyword_count\n",
    "\n",
    "\n",
    "def procesar_carpeta(carpeta):\n",
    "    print(f\"Procesando la carpeta {os.path.basename(carpeta)}\")\n",
    "    pdf_files = [os.path.join(carpeta, f) for f in os.listdir(carpeta) if f.endswith('.pdf')]\n",
    "\n",
    "    num_pdfs_procesados = 0\n",
    "    num_dataframes_generados = 0\n",
    "\n",
    "    table_counter = 1  # Inicializar el contador de tabla aqu√≠\n",
    "    tables_dict = {}  # Declarar tables_dict fuera del bucle principal\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        id_ns, year, date, tables_dict_temp, keyword_count = procesar_pdf(pdf_file)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for nombre_df, df in tables_dict_temp.items():\n",
    "                nombre_archivo = os.path.splitext(os.path.basename(pdf_file))[0].replace('-', '_')\n",
    "                nombre_df = f\"{nombre_archivo}_{keyword_count}\"\n",
    "\n",
    "                # Almacenar DataFrame sin procesar en tables_dict\n",
    "                tables_dict[nombre_df] = df.copy()\n",
    "\n",
    "                # Aplicar las 20 l√≠neas de funciones de limpieza a una copia del DataFrame\n",
    "                df_clean = df.copy()\n",
    "                if df_clean.iloc[0, 0] is np.nan:\n",
    "                    # Aplicar las 20 l√≠neas de limpieza\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = separate_years(df_clean)\n",
    "                    df_clean = relocate_roman_numerals(df_clean)\n",
    "                    df_clean = extract_mixed_values(df_clean)\n",
    "                    df_clean = replace_first_row_nan(df_clean)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = swap_first_second_row(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = drop_nan_row(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = split_values(df_clean)\n",
    "                    df_clean = separate_text_digits(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convertir_float(df_clean)\n",
    "                else:\n",
    "                    # Aplicar las 15 l√≠neas de limpieza\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = remove_digit_slash(df_clean)\n",
    "                    df_clean = swap_first_second_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = separate_text_digits(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convertir_float(df_clean)\n",
    "\n",
    "                # A√±adir las columnas 'year', 'id_ns', 'date' al DataFrame limpio\n",
    "                df_clean.insert(0, 'date', date)\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "                df_clean.insert(2, 'year', year)\n",
    "\n",
    "                # Almacenar DataFrame limpio en dataframes_dict\n",
    "                dataframes_dict[nombre_df] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. El dataframe generado para el archivo {pdf_file} es: {nombre_df}')\n",
    "                num_dataframes_generados += 1\n",
    "                table_counter += 1  # Incrementar el contador de tabla aqu√≠\n",
    "                    \n",
    "        num_pdfs_procesados += len(pdf_files)\n",
    "\n",
    "    return num_pdfs_procesados, num_dataframes_generados, tables_dict\n",
    "\n",
    "\n",
    "def procesar_carpetas():\n",
    "    pdf_folder = 'pseudo_raw_pdf'\n",
    "    carpetas = [os.path.join(pdf_folder, d) for d in os.listdir(pdf_folder) if os.path.isdir(os.path.join(pdf_folder, d))]\n",
    "\n",
    "    tables_dict = {}  # Inicializar tables_dict aqu√≠\n",
    "    \n",
    "    for carpeta in carpetas:\n",
    "        if carpeta_procesada(carpeta):\n",
    "            print(f\"La carpeta {carpeta} ya ha sido procesada.\")\n",
    "            continue\n",
    "        \n",
    "        num_pdfs_procesados, num_dataframes_generados, tables_dict_temp = procesar_carpeta(carpeta)\n",
    "        \n",
    "        # Actualizar tables_dict con los valores devueltos de procesar_carpeta()\n",
    "        tables_dict.update(tables_dict_temp)\n",
    "        \n",
    "        registrar_carpeta_procesada(carpeta, num_pdfs_procesados)\n",
    "\n",
    "        # Preguntar al usuario si desea continuar con la siguiente carpeta\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Para asegurar que la ventana est√© en primer plano\n",
    "        \n",
    "        mensaje = f\"Se han generado {num_dataframes_generados} dataframes en la carpeta {carpeta}. ¬øDeseas continuar con la siguiente carpeta?\"\n",
    "        continuar = messagebox.askyesno(\"Continuar\", mensaje)\n",
    "        root.destroy()\n",
    "\n",
    "        if not continuar:\n",
    "            print(\"Procesamiento detenido por el usuario.\")\n",
    "            break  # Romper el bucle for si el usuario decide no continuar\n",
    "\n",
    "    print(\"Procesamiento completado para todas las carpetas.\")  # Add a message to indicate completion\n",
    "\n",
    "    return tables_dict  # Devolver tables_dict al final de la funci√≥n\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tables_dict = procesar_carpetas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7acb746",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f272f429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ns_01_2013_2', 'ns_01_2014_2', 'ns_01_2015_2', 'ns_01_2016_2', 'ns_01_2017_2', 'ns_01_2018_2', 'ns_01_2019_2', 'ns_01_2020_2', 'ns_01_2021_2', 'ns_02_2013_2', 'ns_03_2013_2', 'ns_04_2013_2', 'ns_05_2013_2', 'ns_06_2013_2', 'ns_07_2013_2', 'ns_09_2013_2', 'ns_10_2013_2'])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "62a46bbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ns_01_2013_2', 'ns_01_2014_2', 'ns_01_2015_2', 'ns_01_2016_2', 'ns_01_2017_2', 'ns_01_2018_2', 'ns_01_2019_2', 'ns_01_2020_2', 'ns_01_2021_2', 'ns_02_2013_2', 'ns_03_2013_2', 'ns_04_2013_2', 'ns_05_2013_2', 'ns_06_2013_2', 'ns_07_2013_2', 'ns_09_2013_2', 'ns_10_2013_2'])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cbcfed7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>2010</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>2011</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "      <th>2012</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SECTORES ECON√ìMICOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECONOMIC SECTORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>II</td>\n",
       "      <td>III</td>\n",
       "      <td>IV</td>\n",
       "      <td>A√ëO</td>\n",
       "      <td>I</td>\n",
       "      <td>II</td>\n",
       "      <td>III</td>\n",
       "      <td>IV</td>\n",
       "      <td>A√ëO</td>\n",
       "      <td>I</td>\n",
       "      <td>II</td>\n",
       "      <td>NaN</td>\n",
       "      <td>II</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agropecuario</td>\n",
       "      <td>3,8</td>\n",
       "      <td>4,4</td>\n",
       "      <td>2,4</td>\n",
       "      <td>6,6</td>\n",
       "      <td>4,3</td>\n",
       "      <td>3,0</td>\n",
       "      <td>2,9</td>\n",
       "      <td>7,2</td>\n",
       "      <td>2,3</td>\n",
       "      <td>3,8</td>\n",
       "      <td>2,6</td>\n",
       "      <td>7,0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,1 Agriculture and Livestock</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agr√≠cola</td>\n",
       "      <td>3,9</td>\n",
       "      <td>4,2</td>\n",
       "      <td>2,1</td>\n",
       "      <td>6,6</td>\n",
       "      <td>4,1</td>\n",
       "      <td>0,3</td>\n",
       "      <td>1,9</td>\n",
       "      <td>10,1</td>\n",
       "      <td>0,9</td>\n",
       "      <td>3,1</td>\n",
       "      <td>1,1</td>\n",
       "      <td>8,2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0,4</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pecuario</td>\n",
       "      <td>3,7</td>\n",
       "      <td>4,9</td>\n",
       "      <td>2,8</td>\n",
       "      <td>6,4</td>\n",
       "      <td>4,4</td>\n",
       "      <td>6,6</td>\n",
       "      <td>6,8</td>\n",
       "      <td>3,6</td>\n",
       "      <td>4,0</td>\n",
       "      <td>5,2</td>\n",
       "      <td>4,5</td>\n",
       "      <td>4,6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6,5</td>\n",
       "      <td>Livestock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0 Unnamed: 1 Unnamed: 2 2010 Unnamed: 4 Unnamed: 5  \\\n",
       "0  SECTORES ECON√ìMICOS        NaN        NaN  NaN        NaN        NaN   \n",
       "1                  NaN          I         II  III         IV        A√ëO   \n",
       "2         Agropecuario        3,8        4,4  2,4        6,6        4,3   \n",
       "3             Agr√≠cola        3,9        4,2  2,1        6,6        4,1   \n",
       "4             Pecuario        3,7        4,9  2,8        6,4        4,4   \n",
       "\n",
       "  Unnamed: 6 Unnamed: 7  2011 Unnamed: 9 Unnamed: 10 Unnamed: 11 2012  \\\n",
       "0        NaN        NaN   NaN        NaN         NaN         NaN  NaN   \n",
       "1          I         II   III         IV         A√ëO           I   II   \n",
       "2        3,0        2,9   7,2        2,3         3,8         2,6  7,0   \n",
       "3        0,3        1,9  10,1        0,9         3,1         1,1  8,2   \n",
       "4        6,6        6,8   3,6        4,0         5,2         4,5  4,6   \n",
       "\n",
       "   Unnamed: 13                    Unnamed: 14       Unnamed: 15  \n",
       "0          NaN                            NaN  ECONOMIC SECTORS  \n",
       "1          NaN                             II               NaN  \n",
       "2          NaN  3,1 Agriculture and Livestock               NaN  \n",
       "3          NaN                            0,4       Agriculture  \n",
       "4          NaN                            6,5         Livestock  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables_dict['ns_01_2013_2'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ab5fa18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>id_ns</th>\n",
       "      <th>year</th>\n",
       "      <th>sectores_economicos</th>\n",
       "      <th>economic_sectors</th>\n",
       "      <th>2010_1</th>\n",
       "      <th>2010_2</th>\n",
       "      <th>2010_3</th>\n",
       "      <th>2010_4</th>\n",
       "      <th>2010_year</th>\n",
       "      <th>2011_1</th>\n",
       "      <th>2011_2</th>\n",
       "      <th>2011_3</th>\n",
       "      <th>2011_4</th>\n",
       "      <th>2011_year</th>\n",
       "      <th>2012_1</th>\n",
       "      <th>2012_2</th>\n",
       "      <th>2012_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>agropecuario</td>\n",
       "      <td>agriculture and livestock</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>agricola</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>2.1</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>10.1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pecuario</td>\n",
       "      <td>livestock</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.8</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.6</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pesca</td>\n",
       "      <td>fishing</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>-25.3</td>\n",
       "      <td>-16.4</td>\n",
       "      <td>12.3</td>\n",
       "      <td>20.8</td>\n",
       "      <td>65.9</td>\n",
       "      <td>36.6</td>\n",
       "      <td>29.7</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>-11.7</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>mineria e hidrocarburos</td>\n",
       "      <td>mining and fuel</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.9</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>mineria metalica</td>\n",
       "      <td>metals</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>-3.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>hidrocarburos</td>\n",
       "      <td>fuel</td>\n",
       "      <td>11.0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>37.4</td>\n",
       "      <td>44.8</td>\n",
       "      <td>29.5</td>\n",
       "      <td>34.6</td>\n",
       "      <td>31.5</td>\n",
       "      <td>10.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>18.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>manufactura</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>7.5</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.4</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>12.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>de procesamiento de recursos primarios</td>\n",
       "      <td>based on raw materials</td>\n",
       "      <td>-5.6</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>11.6</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-11.2</td>\n",
       "      <td>-3.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>no primaria</td>\n",
       "      <td>nonprimary</td>\n",
       "      <td>10.1</td>\n",
       "      <td>21.4</td>\n",
       "      <td>20.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>16.9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>electricidad y agua</td>\n",
       "      <td>electricity and water</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.6</td>\n",
       "      <td>8.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>construccion</td>\n",
       "      <td>construction</td>\n",
       "      <td>16.8</td>\n",
       "      <td>21.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>15.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>8.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>12.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>comercio</td>\n",
       "      <td>commerce</td>\n",
       "      <td>8.1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>10.3</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>otros servicios</td>\n",
       "      <td>other services</td>\n",
       "      <td>4.9</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pbi</td>\n",
       "      <td>gdp</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pbi de los sectores primarios</td>\n",
       "      <td>primary sectors gross domestic product</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>7.1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>pbi de los sectores no primarios</td>\n",
       "      <td>non primary sectors gross domestic product</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11.9</td>\n",
       "      <td>11.4</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.3</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date id_ns  year                     sectores_economicos  \\\n",
       "0  2013-01-04    01  2013                            agropecuario   \n",
       "1  2013-01-04    01  2013                                agricola   \n",
       "2  2013-01-04    01  2013                                pecuario   \n",
       "3  2013-01-04    01  2013                                   pesca   \n",
       "4  2013-01-04    01  2013                 mineria e hidrocarburos   \n",
       "5  2013-01-04    01  2013                        mineria metalica   \n",
       "6  2013-01-04    01  2013                           hidrocarburos   \n",
       "7  2013-01-04    01  2013                             manufactura   \n",
       "8  2013-01-04    01  2013  de procesamiento de recursos primarios   \n",
       "9  2013-01-04    01  2013                             no primaria   \n",
       "10 2013-01-04    01  2013                     electricidad y agua   \n",
       "11 2013-01-04    01  2013                            construccion   \n",
       "12 2013-01-04    01  2013                                comercio   \n",
       "13 2013-01-04    01  2013                        otros servicios    \n",
       "14 2013-01-04    01  2013                                     pbi   \n",
       "15 2013-01-04    01  2013           pbi de los sectores primarios   \n",
       "16 2013-01-04    01  2013        pbi de los sectores no primarios   \n",
       "\n",
       "                               economic_sectors  2010_1  2010_2  2010_3  \\\n",
       "0                     agriculture and livestock     3.8     4.4     2.4   \n",
       "1                                   agriculture     3.9     4.2     2.1   \n",
       "2                                     livestock     3.7     4.9     2.8   \n",
       "3                                       fishing    -8.2    -9.7   -27.0   \n",
       "4                               mining and fuel     1.1     1.7    -2.3   \n",
       "5                                        metals    -1.0    -2.3    -8.2   \n",
       "6                                          fuel    11.0    22.3    37.4   \n",
       "7                                 manufacturing     7.5    16.8    17.4   \n",
       "8                       based on raw materials     -5.6    -1.9     2.4   \n",
       "9                                    nonprimary    10.1    21.4    20.1   \n",
       "10                        electricity and water     6.5     8.6     8.4   \n",
       "11                                 construction    16.8    21.5    16.6   \n",
       "12                                     commerce     8.1    11.0     9.6   \n",
       "13                              other services      4.9     8.8     9.3   \n",
       "14                                          gdp     6.2    10.0     9.6   \n",
       "15       primary sectors gross domestic product     0.9     2.2     0.0   \n",
       "16   non primary sectors gross domestic product     7.2    11.9    11.4   \n",
       "\n",
       "    2010_4  2010_year  2011_1  2011_2  2011_3  2011_4  2011_year  2012_1  \\\n",
       "0      6.6        4.3     3.0     2.9     7.2     2.3        3.8     2.6   \n",
       "1      6.6        4.1     0.3     1.9    10.1     0.9        3.1     1.1   \n",
       "2      6.4        4.4     6.6     6.8     3.6     4.0        5.2     4.5   \n",
       "3    -25.3      -16.4    12.3    20.8    65.9    36.6       29.7    -9.7   \n",
       "4     -1.0       -0.1    -0.3    -2.3     0.9     0.9       -0.2     3.5   \n",
       "5     -7.4       -4.8    -5.6    -7.7    -1.1     0.2       -3.6     3.4   \n",
       "6     44.8       29.5    34.6    31.5    10.4     3.7       18.1     3.7   \n",
       "7     13.0       13.6    12.3     6.0     3.8     1.0        5.6    -0.7   \n",
       "8     -3.7       -2.3    11.6    12.0    14.7    11.3       12.3    -3.2   \n",
       "9     16.2       16.9    12.4     4.8     2.1    -0.7        4.4    -0.3   \n",
       "10     7.3        7.7     7.3     7.4     7.7     7.2        7.4     6.3   \n",
       "11    15.5       17.4     8.1     0.4     1.8     3.8        3.4    12.5   \n",
       "12     9.9        9.7    10.3     8.8     8.6     7.6        8.8     7.9   \n",
       "13     8.9        8.0     9.3     9.0     8.0     7.1        8.3     7.6   \n",
       "14     9.2        8.8     8.8     6.9     6.7     5.5        6.9     6.0   \n",
       "15     1.1        1.1     3.5     3.3     7.1     4.0        4.4     1.6   \n",
       "16    10.6       10.3     9.8     7.6     6.6     5.7        7.4     6.8   \n",
       "\n",
       "    2012_2  2012_3  \n",
       "0      7.0     3.1  \n",
       "1      8.2     0.4  \n",
       "2      4.6     6.5  \n",
       "3    -11.7     0.7  \n",
       "4      4.1     3.3  \n",
       "5      4.8     3.0  \n",
       "6      1.2     4.4  \n",
       "7      0.2     3.5  \n",
       "8    -11.2    -3.2  \n",
       "9      2.5     4.7  \n",
       "10     5.0     5.1  \n",
       "11    16.6    19.2  \n",
       "12     6.4     6.2  \n",
       "13     7.2     6.7  \n",
       "14     6.3     6.5  \n",
       "15     2.6     2.0  \n",
       "16     7.1     7.3  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframes_dict['ns_01_2013_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d654ba",
   "metadata": {},
   "source": [
    "# Se recomienda procesar por carpetas. Aseg√∫rese de que cuando una carpeta ya ha sido procesada con todos los dataframes generados correctamente, se corra el siguiente c√≥digo que concatena por sectores las revisiones de todas las NS de un mismo a√±o (para todas las frecuencias). Los datasets de growth rates deben ser cargados a SQL por a√±os. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e1939c",
   "metadata": {},
   "source": [
    "**Nota sobre $\\color{blue}{NS-08-2017}$: La NS-08-2017 no tiene la tabla 1, pero resulta que la tabla 1 no cambia desde la NS 07 a la NS 09 del mismo a√±o. Adem√°s la tabla 2 s√≠ existe en la NS 08 y es la misma que en la NS 09. Por ello se puede reconstruir la NS (con las 3 pa¬¥ginas de inter√©s) a partir de la NS 09, se duplicar√≠an las dos √∫ltimas p√°ginas de la NS 09 y estas reemplazar√≠an las dos √∫ltimas de la NS 08 actual, la primera no porque la primera es la portada y nos da informaci√≥n sobre la fecha en que ocurri√≥ la NS.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187e0f27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709d3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c726d387",
   "metadata": {},
   "source": [
    "# To sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e53ca68a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cur' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Iterar sobre los DataFrames generados y guardarlos en PostgreSQL\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m nombre_df, df \u001b[38;5;129;01min\u001b[39;00m dataframes_dict\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# Crear una nueva tabla en PostgreSQL con el nombre del DataFrame\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     \u001b[43mcur\u001b[49m\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCREATE TABLE IF NOT EXISTS \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnombre_df\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (index serial PRIMARY KEY);\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Iterar sobre las columnas del DataFrame y agregarlas a la tabla en PostgreSQL\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m columna \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cur' is not defined"
     ]
    }
   ],
   "source": [
    "# Iterar sobre los DataFrames generados y guardarlos en PostgreSQL\n",
    "for nombre_df, df in dataframes_dict.items():\n",
    "    # Crear una nueva tabla en PostgreSQL con el nombre del DataFrame\n",
    "    cur.execute(f\"CREATE TABLE IF NOT EXISTS {nombre_df} (index serial PRIMARY KEY);\")\n",
    "\n",
    "    # Iterar sobre las columnas del DataFrame y agregarlas a la tabla en PostgreSQL\n",
    "    for columna in df.columns:\n",
    "        cur.execute(f\"ALTER TABLE {nombre_df} ADD COLUMN IF NOT EXISTS {columna} TEXT;\")\n",
    "\n",
    "    # Insertar los datos del DataFrame en la tabla en PostgreSQL\n",
    "    for fila in df.itertuples(index=False):\n",
    "        cur.execute(f\"INSERT INTO {nombre_df} VALUES ({', '.join(['%s'] * len(fila))});\", fila)\n",
    "\n",
    "# Confirmar los cambios y cerrar la conexi√≥n a PostgreSQL\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f44ed1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "667d97b8",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217183e7",
   "metadata": {},
   "source": [
    "<div id=\"3\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8989d65",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.</span> <span style = \"color: dark; font-family: charter;\">SQL Tables</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a04abd",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Finally, after obtaining and cleaning all the necessary data, we can create the three most important datasets to store realeses, vintages, and revisions. These datasets will be stored as tables in SQL and can be loaded into any software or programming language.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6ca98",
   "metadata": {},
   "source": [
    "<div id=\"3-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b142e",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.1.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Annual Concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3c25f13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_and_filter_dataframes(dataframes_dict):\n",
    "    # List to store the names of dataframes that meet the criterion of ending in '_2'\n",
    "    dataframes_ending_with_2 = []\n",
    "\n",
    "    # List to store the names of dataframes to be concatenated\n",
    "    dataframes_to_concatenate = []\n",
    "\n",
    "    # Iterate over the dataframe names in the all_dataframes dictionary\n",
    "    for df_name in dataframes_dict.keys():\n",
    "        # Check if the dataframe name ends with '_2' and add it to the corresponding list\n",
    "        if df_name.endswith('_2'):\n",
    "            dataframes_ending_with_2.append(df_name)\n",
    "            dataframes_to_concatenate.append(dataframes_dict[df_name])\n",
    "\n",
    "    # Print the names of dataframes that meet the criterion of ending in '_2'\n",
    "    print(\"DataFrames ending with '_2' that will be concatenated:\")\n",
    "    for df_name in dataframes_ending_with_2:\n",
    "        print(df_name)\n",
    "\n",
    "    # Concatenate all dataframes in the 'dataframes_to_concatenate' list\n",
    "    if dataframes_to_concatenate:\n",
    "        # Concatenate only rows that meet the specified conditions\n",
    "        gdp_annual_growth_rates = pd.concat([df[(df['sectores_economicos'] == 'pbi') | (df['economic_sectors'] == 'gdp')] \n",
    "                                    for df in dataframes_to_concatenate \n",
    "                                    if 'sectores_economicos' in df.columns and 'economic_sectors' in df.columns], \n",
    "                                    ignore_index=True)\n",
    "\n",
    "        # Keep only columns that start with 'year' and the 'id_ns', 'year', and 'date' columns\n",
    "        columns_to_keep = ['id_ns', 'year', 'date'] + [col for col in gdp_annual_growth_rates.columns if col.endswith('_year')]\n",
    "\n",
    "        # Drop unwanted columns\n",
    "        gdp_annual_growth_rates = gdp_annual_growth_rates[columns_to_keep]\n",
    "        \n",
    "        # Remove duplicate columns if any\n",
    "        gdp_annual_growth_rates = gdp_annual_growth_rates.loc[:,~gdp_annual_growth_rates.columns.duplicated()]\n",
    "\n",
    "        # Print the number of rows in the concatenated dataframe\n",
    "        print(\"Number of rows in the concatenated dataframe:\", len(gdp_annual_growth_rates))\n",
    "        \n",
    "        return gdp_annual_growth_rates\n",
    "    else:\n",
    "        print(\"No dataframes were found to concatenate.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4891f2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames ending with '_2' that will be concatenated:\n",
      "ns_01_2013_2\n",
      "ns_01_2014_2\n",
      "ns_01_2015_2\n",
      "ns_01_2016_2\n",
      "ns_01_2017_2\n",
      "ns_01_2018_2\n",
      "ns_01_2019_2\n",
      "ns_01_2020_2\n",
      "ns_01_2021_2\n",
      "ns_02_2013_2\n",
      "ns_03_2013_2\n",
      "ns_04_2013_2\n",
      "ns_05_2013_2\n",
      "ns_06_2013_2\n",
      "ns_07_2013_2\n",
      "ns_09_2013_2\n",
      "ns_10_2013_2\n",
      "Number of rows in the concatenated dataframe: 10\n"
     ]
    }
   ],
   "source": [
    "gdp_annual_growth_rates = concatenate_and_filter_dataframes(dataframes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ea4b7182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ns</th>\n",
       "      <th>year</th>\n",
       "      <th>date</th>\n",
       "      <th>2010_year</th>\n",
       "      <th>2011_year</th>\n",
       "      <th>2012_year</th>\n",
       "      <th>2013_year</th>\n",
       "      <th>2014_year</th>\n",
       "      <th>2015_year</th>\n",
       "      <th>2016_year</th>\n",
       "      <th>2017_year</th>\n",
       "      <th>2018_year</th>\n",
       "      <th>2019_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>2014</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>05</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>06</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>07</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2013</td>\n",
       "      <td>2013-03-08</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_ns  year       date  2010_year  2011_year  2012_year  2013_year  \\\n",
       "0    01  2013 2013-01-04        8.8        6.9        NaN        NaN   \n",
       "1    01  2014 2014-01-10        NaN        6.9        6.3        NaN   \n",
       "2    02  2013 2013-01-11        8.8        6.9        NaN        NaN   \n",
       "3    03  2013 2013-01-18        8.8        6.9        NaN        NaN   \n",
       "4    04  2013 2013-01-25        8.8        6.9        NaN        NaN   \n",
       "5    05  2013 2013-02-01        8.8        6.9        NaN        NaN   \n",
       "6    06  2013 2013-02-08        8.8        6.9        NaN        NaN   \n",
       "7    07  2013 2013-02-15        8.8        6.9        NaN        NaN   \n",
       "8    09  2013 2013-03-01        8.8        6.9        6.3        NaN   \n",
       "9    10  2013 2013-03-08        8.8        6.9        6.3        NaN   \n",
       "\n",
       "   2014_year  2015_year  2016_year  2017_year  2018_year  2019_year  \n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "2        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "3        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "4        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "5        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "6        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "7        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "8        NaN        NaN        NaN        NaN        NaN        NaN  \n",
       "9        NaN        NaN        NaN        NaN        NaN        NaN  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_annual_growth_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270f8d73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61bbaac2",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "461d9bac",
   "metadata": {},
   "source": [
    "<div id=\"3-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50087e95",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.2.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Quarterly Concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6467ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concatenate_and_filter_dataframes(dataframes_dict):\n",
    "    # List to store the names of dataframes that meet the criterion of ending in '_2'\n",
    "    dataframes_ending_with_2 = []\n",
    "\n",
    "    # List to store the names of dataframes to be concatenated\n",
    "    dataframes_to_concatenate = []\n",
    "\n",
    "    # Iterate over the dataframe names in the all_dataframes dictionary\n",
    "    for df_name in dataframes_dict.keys():\n",
    "        # Check if the dataframe name ends with '_2' and add it to the corresponding list\n",
    "        if df_name.endswith('_2'):\n",
    "            dataframes_ending_with_2.append(df_name)\n",
    "            dataframes_to_concatenate.append(dataframes_dict[df_name])\n",
    "\n",
    "    # Print the names of dataframes that meet the criterion of ending in '_2'\n",
    "    print(\"DataFrames ending with '_2' that will be concatenated:\")\n",
    "    for df_name in dataframes_ending_with_2:\n",
    "        print(df_name)\n",
    "\n",
    "    # Concatenate all dataframes in the 'dataframes_to_concatenate' list\n",
    "    if dataframes_to_concatenate:\n",
    "        # Concatenate only rows that meet the specified conditions\n",
    "        gdp_quarterly_growth_rates = pd.concat([df[(df['sectores_economicos'] == 'pbi') | (df['economic_sectors'] == 'gdp')] \n",
    "                                    for df in dataframes_to_concatenate \n",
    "                                    if 'sectores_economicos' in df.columns and 'economic_sectors' in df.columns], \n",
    "                                    ignore_index=True)\n",
    "\n",
    "        # Keep all columns except those starting with 'year_', in addition to the 'id_ns', 'year', and 'date' columns\n",
    "        columns_to_keep = ['year', 'id_ns', 'date'] + [col for col in gdp_quarterly_growth_rates.columns if not col.endswith('_year')]\n",
    "\n",
    "        # Select unwanted columns\n",
    "        gdp_quarterly_growth_rates = gdp_quarterly_growth_rates[columns_to_keep]\n",
    "\n",
    "        # Drop the 'sectores_economicos' and 'economic_sectors' columns\n",
    "        gdp_quarterly_growth_rates.drop(columns=['sectores_economicos', 'economic_sectors'], inplace=True)\n",
    "\n",
    "        # Remove duplicate columns if any\n",
    "        gdp_quarterly_growth_rates = gdp_quarterly_growth_rates.loc[:,~gdp_quarterly_growth_rates.columns.duplicated()]\n",
    "\n",
    "        # Print the number of rows in the concatenated dataframe\n",
    "        print(\"Number of rows in the concatenated dataframe:\", len(gdp_quarterly_growth_rates))\n",
    "        \n",
    "        return gdp_quarterly_growth_rates\n",
    "    else:\n",
    "        print(\"No dataframes were found to concatenate.\")\n",
    "        return None\n",
    "\n",
    "# Uso de la funci√≥n con el diccionario como argumento\n",
    "# gdp_quarterly_growth_rates = concatenate_and_filter_dataframes(dataframes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b4fc5844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id_ns</th>\n",
       "      <th>date</th>\n",
       "      <th>2010_1</th>\n",
       "      <th>2010_2</th>\n",
       "      <th>2010_3</th>\n",
       "      <th>2010_4</th>\n",
       "      <th>2011_1</th>\n",
       "      <th>2011_2</th>\n",
       "      <th>2011_3</th>\n",
       "      <th>2011_4</th>\n",
       "      <th>2012_1</th>\n",
       "      <th>2012_2</th>\n",
       "      <th>2012_3</th>\n",
       "      <th>2012_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>02</td>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>03</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>04</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>05</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013</td>\n",
       "      <td>06</td>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013</td>\n",
       "      <td>07</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013</td>\n",
       "      <td>08</td>\n",
       "      <td>2013-02-22</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013</td>\n",
       "      <td>09</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-03-08</td>\n",
       "      <td>6.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year id_ns       date  2010_1  2010_2  2010_3  2010_4  2011_1  2011_2  \\\n",
       "0  2013    01 2013-01-04     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "1  2013    02 2013-01-11     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "2  2013    03 2013-01-18     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "3  2013    04 2013-01-25     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "4  2013    05 2013-02-01     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "5  2013    06 2013-02-08     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "6  2013    07 2013-02-15     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "7  2013    08 2013-02-22     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "8  2013    09 2013-03-01     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "9  2013    10 2013-03-08     6.2    10.0     9.6     9.2     8.8     6.9   \n",
       "\n",
       "   2011_3  2011_4  2012_1  2012_2  2012_3  2012_4  \n",
       "0     6.7     5.5     6.0     6.3     6.5     NaN  \n",
       "1     6.7     5.5     6.0     6.3     6.5     NaN  \n",
       "2     6.7     5.5     6.0     6.3     6.5     NaN  \n",
       "3     6.7     5.5     6.0     6.3     6.5     NaN  \n",
       "4     6.7     5.5     6.0     6.3     6.5     NaN  \n",
       "5     6.7     5.5     6.0     6.3     6.5     NaN  \n",
       "6     6.7     5.5     6.0     6.3     6.5     NaN  \n",
       "7     6.7     5.5     6.0     6.4     6.8     5.9  \n",
       "8     6.7     5.5     6.0     6.4     6.8     5.9  \n",
       "9     6.7     5.5     6.0     6.4     6.8     5.9  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_quarterly_growth_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d99fd6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24dd0fc0",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca271f",
   "metadata": {},
   "source": [
    "<div id=\"3-3\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453bb965",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.3.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Monthly Concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33a86c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def concatenate_and_filter_dataframes(dataframes_dict):\n",
    "    # List to store the names of dataframes that meet the criterion of ending in '_1'\n",
    "    dataframes_ending_with_1 = []\n",
    "\n",
    "    # List to store the names of dataframes to be concatenated\n",
    "    dataframes_to_concatenate = []\n",
    "\n",
    "    # Iterate over the dataframe names in the all_dataframes dictionary\n",
    "    for df_name in dataframes_dict.keys():\n",
    "        # Check if the dataframe name ends with '_1' and add it to the corresponding list\n",
    "        if df_name.endswith('_1'):\n",
    "            dataframes_ending_with_1.append(df_name)\n",
    "            dataframes_to_concatenate.append(dataframes_dict[df_name])\n",
    "\n",
    "    # Print the names of dataframes that meet the criterion of ending with '_1'\n",
    "    print(\"DataFrames ending with '_1' that will be concatenated:\")\n",
    "    for df_name in dataframes_ending_with_1:\n",
    "        print(df_name)\n",
    "\n",
    "    # Concatenate all dataframes in the 'dataframes_to_concatenate' list\n",
    "    if dataframes_to_concatenate:\n",
    "        # Concatenate only rows that meet the specified conditions\n",
    "        gdp_monthly_growth_rates = pd.concat([df[(df['sectores_economicos'] == 'pbi') | (df['economic_sectors'] == 'gdp')] \n",
    "                                    for df in dataframes_to_concatenate \n",
    "                                    if 'sectores_economicos' in df.columns and 'economic_sectors' in df.columns], \n",
    "                                    ignore_index=True)\n",
    "\n",
    "        # Keep all columns except those starting with 'year_', in addition to the 'id_ns', 'year', and 'date' columns\n",
    "        columns_to_keep = ['year', 'id_ns', 'date'] + [col for col in gdp_monthly_growth_rates.columns if not col.endswith('_year')]\n",
    "\n",
    "        # Select unwanted columns\n",
    "        gdp_monthly_growth_rates = gdp_monthly_growth_rates[columns_to_keep]\n",
    "\n",
    "        # Drop the 'sectores_economicos' and 'economic_sectors' columns\n",
    "        gdp_monthly_growth_rates.drop(columns=['sectores_economicos', 'economic_sectors'], inplace=True)\n",
    "\n",
    "        # Remove duplicate columns if any\n",
    "        gdp_monthly_growth_rates = gdp_monthly_growth_rates.loc[:,~gdp_monthly_growth_rates.columns.duplicated()]\n",
    "        \n",
    "        # Drop columns with at least two underscores in their names\n",
    "        columns_to_drop = [col for col in gdp_monthly_growth_rates.columns if col.count('_') >= 2]\n",
    "        gdp_monthly_growth_rates.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "        # Print the number of rows in the concatenated dataframe\n",
    "        print(\"Number of rows in the concatenated dataframe:\", len(gdp_monthly_growth_rates))\n",
    "        \n",
    "        return gdp_monthly_growth_rates\n",
    "    else:\n",
    "        print(\"No dataframes were found to concatenate.\")\n",
    "        return None\n",
    "\n",
    "# Uso de la funci√≥n con el diccionario como argumento\n",
    "# gdp_monthly_growth_rates = concatenate_and_filter_dataframes(dataframes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "671223c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames ending with '_1' that will be concatenated:\n",
      "ns_01_2013_1\n",
      "ns_01_2014_1\n",
      "ns_01_2015_1\n",
      "ns_01_2016_1\n",
      "ns_01_2017_1\n",
      "ns_01_2018_1\n",
      "ns_01_2019_1\n",
      "ns_01_2020_1\n",
      "ns_01_2021_1\n",
      "ns_02_2013_1\n",
      "ns_03_2013_1\n",
      "ns_04_2013_1\n",
      "ns_05_2013_1\n",
      "ns_06_2013_1\n",
      "ns_07_2013_1\n",
      "ns_09_2013_1\n",
      "ns_10_2013_1\n",
      "ns_46_2018_1\n",
      "ns_47_2018_1\n",
      "Number of rows in the concatenated dataframe: 19\n"
     ]
    }
   ],
   "source": [
    "gdp_monthly_growth_rates = concatenate_and_filter_dataframes(dataframes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e805081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id_ns</th>\n",
       "      <th>date</th>\n",
       "      <th>2011_set</th>\n",
       "      <th>2011_oct</th>\n",
       "      <th>2011_nov</th>\n",
       "      <th>2011_dic</th>\n",
       "      <th>2012_ene</th>\n",
       "      <th>2012_feb</th>\n",
       "      <th>2012_mar</th>\n",
       "      <th>...</th>\n",
       "      <th>2020_ene</th>\n",
       "      <th>2020_feb</th>\n",
       "      <th>2020_mar</th>\n",
       "      <th>2020_abr</th>\n",
       "      <th>2020_may</th>\n",
       "      <th>2020_jun</th>\n",
       "      <th>2020_jul</th>\n",
       "      <th>2020_ago</th>\n",
       "      <th>2020_sep</th>\n",
       "      <th>2020_oct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>01</td>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014</td>\n",
       "      <td>01</td>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>01</td>\n",
       "      <td>2015-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>01</td>\n",
       "      <td>2016-01-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>01</td>\n",
       "      <td>2017-01-05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>01</td>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>01</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020</td>\n",
       "      <td>01</td>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021</td>\n",
       "      <td>01</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-16.3</td>\n",
       "      <td>-39.2</td>\n",
       "      <td>-32.3</td>\n",
       "      <td>-17.9</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013</td>\n",
       "      <td>02</td>\n",
       "      <td>2013-01-11</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013</td>\n",
       "      <td>03</td>\n",
       "      <td>2013-01-18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013</td>\n",
       "      <td>04</td>\n",
       "      <td>2013-01-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013</td>\n",
       "      <td>05</td>\n",
       "      <td>2013-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013</td>\n",
       "      <td>06</td>\n",
       "      <td>2013-02-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013</td>\n",
       "      <td>07</td>\n",
       "      <td>2013-02-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013</td>\n",
       "      <td>09</td>\n",
       "      <td>2013-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013</td>\n",
       "      <td>10</td>\n",
       "      <td>2013-03-08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>46</td>\n",
       "      <td>2018-11-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>47</td>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19 rows √ó 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    year id_ns       date  2011_set  2011_oct  2011_nov  2011_dic  2012_ene  \\\n",
       "0   2013    01 2013-01-04       5.9       5.3       5.1       6.0       5.5   \n",
       "1   2014    01 2014-01-10       NaN       NaN       NaN       NaN       NaN   \n",
       "2   2015    01 2015-01-09       NaN       NaN       NaN       NaN       NaN   \n",
       "3   2016    01 2016-01-08       NaN       NaN       NaN       NaN       NaN   \n",
       "4   2017    01 2017-01-05       NaN       NaN       NaN       NaN       NaN   \n",
       "5   2018    01 2018-01-11       NaN       NaN       NaN       NaN       NaN   \n",
       "6   2019    01 2019-01-10       NaN       NaN       NaN       NaN       NaN   \n",
       "7   2020    01 2020-01-09       NaN       NaN       NaN       NaN       NaN   \n",
       "8   2021    01 2021-01-07       NaN       NaN       NaN       NaN       NaN   \n",
       "9   2013    02 2013-01-11       5.9       5.3       5.1       6.0       5.5   \n",
       "10  2013    03 2013-01-18       NaN       NaN       5.1       6.0       5.5   \n",
       "11  2013    04 2013-01-25       NaN       NaN       5.1       6.0       5.5   \n",
       "12  2013    05 2013-02-01       NaN       NaN       5.1       6.0       5.5   \n",
       "13  2013    06 2013-02-08       NaN       NaN       5.1       6.0       5.5   \n",
       "14  2013    07 2013-02-15       NaN       NaN       5.1       6.0       5.5   \n",
       "15  2013    09 2013-03-01       NaN       NaN       NaN       6.0       5.5   \n",
       "16  2013    10 2013-03-08       NaN       NaN       NaN       6.0       5.5   \n",
       "17  2018    46 2018-11-29       NaN       NaN       NaN       NaN       NaN   \n",
       "18  2018    47 2018-12-06       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "    2012_feb  2012_mar  ...  2020_ene  2020_feb  2020_mar  2020_abr  2020_may  \\\n",
       "0        6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "1        NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "2        NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "3        NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "4        NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "5        NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "6        NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "7        NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "8        NaN       NaN  ...       3.0       3.7     -16.3     -39.2     -32.3   \n",
       "9        6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "10       6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "11       6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "12       6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "13       6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "14       6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "15       6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "16       6.9       5.7  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "17       NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "18       NaN       NaN  ...       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "    2020_jun  2020_jul  2020_ago  2020_sep  2020_oct  \n",
       "0        NaN       NaN       NaN       NaN       NaN  \n",
       "1        NaN       NaN       NaN       NaN       NaN  \n",
       "2        NaN       NaN       NaN       NaN       NaN  \n",
       "3        NaN       NaN       NaN       NaN       NaN  \n",
       "4        NaN       NaN       NaN       NaN       NaN  \n",
       "5        NaN       NaN       NaN       NaN       NaN  \n",
       "6        NaN       NaN       NaN       NaN       NaN  \n",
       "7        NaN       NaN       NaN       NaN       NaN  \n",
       "8      -17.9     -11.6      -9.7      -6.9      -3.8  \n",
       "9        NaN       NaN       NaN       NaN       NaN  \n",
       "10       NaN       NaN       NaN       NaN       NaN  \n",
       "11       NaN       NaN       NaN       NaN       NaN  \n",
       "12       NaN       NaN       NaN       NaN       NaN  \n",
       "13       NaN       NaN       NaN       NaN       NaN  \n",
       "14       NaN       NaN       NaN       NaN       NaN  \n",
       "15       NaN       NaN       NaN       NaN       NaN  \n",
       "16       NaN       NaN       NaN       NaN       NaN  \n",
       "17       NaN       NaN       NaN       NaN       NaN  \n",
       "18       NaN       NaN       NaN       NaN       NaN  \n",
       "\n",
       "[19 rows x 113 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdp_monthly_growth_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912d83a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_monthly_growth_rates['date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb99df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8dcb07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79df4c62",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda85bba",
   "metadata": {},
   "source": [
    "<div id=\"3-4\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66d3554",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.4.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Loading SQL\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "df33a919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Get environment variables\n",
    "user = os.environ.get('CIUP_SQL_USER')\n",
    "password = os.environ.get('CIUP_SQL_PASS')\n",
    "host = os.environ.get('CIUP_SQL_HOST')\n",
    "port = 5432\n",
    "database = 'gdp_revisions_datasets'\n",
    "\n",
    "# Check if all environment variables are defined\n",
    "if not all([host, user, password]):\n",
    "    raise ValueError(\"Some environment variables are missing (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "# Create connection string\n",
    "connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# gdp_monthly_growth_rates is the DataFrame you want to save to the database\n",
    "gdp_annual_growth_rates.to_sql('gdp_annual_growth_rates_2013', engine, index=False, if_exists='replace')\n",
    "#gdp_quarterly_growth_rates.to_sql('gdp_quarterly_growth_rates', engine, index=False, if_exists='replace')\n",
    "#gdp_monthly_growth_rates.to_sql('gdp_monthly_growth_rates', engine, index=False, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132cb43c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c651835",
   "metadata": {},
   "source": [
    "### PENDINGS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b4c405",
   "metadata": {},
   "source": [
    "1. Fix TYPOS (ns_05_2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd18b4",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc920fd",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eae11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf105ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
