\documentclass[a4paper, fleqn, 11pt]{article}

\input{CWT_Format}  

\newcommand{\sigone}[0]{***}
\newcommand{\sigfive}[0]{**\phantom{*}}
\newcommand{\sigten}[0]{*\phantom{**}}
\newcommand{\signada}[0]{\phantom{***}}
\newcommand{\sigse}[0]{\phantom{**}}

\begin{document}

\begin{center}
\emph{Online Supplement \red{(Not intended for publication)}} \\[2mm]
\Large{
\textbf{Rationality and Nowcasting in Emerging Economies:\\ Evidence from GDP Revisions in Peru}} \\[5mm]

\normalsize
\iffalse
%\iftrue
\begin{tabular}{c c c  }
\textbf{ Jason Cruz} & \textbf{ Diego Winkelried}
&   \textbf{ Javier Torres} \\
\href{jj.cruza@up.edu.pe }{jj.cruza@up.edu.pe }  &\href{winkelried\_dm@up.edu.pe}{winkelried\_dm@up.edu.pe} &
\href{J.Torresgomez@up.edu.pe }{j.torresgomez@up.edu.pe }  \\[1mm]
\multicolumn{3}{c}{\emph{School of Economics and Finance, Universidad del Pac\'{i}fico (Lima, Per\'{u})}}
\end{tabular}\\[4mm]
\else
\vspace{1.5cm}
\fi
\today
\end{center}

This supplemental document provides detailed information on the data sources, collection procedures, processing steps, and terminology used to construct the first real-time dataset (RTD) of Peruvian GDP growth. It focuses on the methodological workflow, quality-control standards, and replication resources that underpin the empirical analysis.

In Peru, the National Institute of Statistics and Informatics (\href{https://www.inei.gob.pe/estadisticas/indice-tematico/economia/}{INEI}) produces and disseminates GDP statistics, while the Central Reserve Bank of Peru (\href{https://www.bcrp.gob.pe/publications/weekly-reports/weekly-report.html}{BCRP}) republishes these figures in its \href{https://www.bcrp.gob.pe/statistics/weekly-report-tables.html}{Weekly Report} (WR). Although INEI is the primary source, the BCRP provides a clearer and more consistent record of releases, reflecting legal obligations under article 84 of the Peruvian Constitution and articles 2 and 74 of the BCRP’s Organic Law, which require the periodic publication of key national macroeconomic statistics. Our data collection strategy draws on both sources to construct the RTD of Peruvian GDP growth.

%-----------------------------------------------------------------------
% 1. Revision Calendar
%-----------------------------------------------------------------------

\section{Revision Calendar}
\label{section:calendar}

A formal publication calendar governs the initial release of GDP growth figures, which are published with a two-month lag relative to the reference period across all frequencies. While this delay aligns with international practice, it underscores the need to account for data revisions when using GDP for real-time policy analysis. In contrast, no official revision calendar is maintained. This distinction is important to highlight: the timing of first releases is regulated and predictable, whereas subsequent revisions follow no explicit or public schedule.

For the construction of a RTD, however, a revision calendar is indispensable. Without a consistent schedule of updates, it becomes impossible to define vintages and track revisions systematically. A regular calendar ensures comparability across time, while irregular release dates complicate measurement, since the horizon between releases varies.

To address this limitation, we reconstructed an implicit revision calendar using the BCRP’s WR. Each WR reproduces INEI’s figures and specifies the date of the update. We then harmonized this information to a monthly frequency—consistent with the ``horizon'' definition in the main paper—based on two criteria: 

\begin{enumerate}
    \item \href{https://www.gob.pe/institucion/inei/normas-legales/2294897-316-2003-inei}{Chief Resolution No. 316-2003-INEI} mandates that sectoral offices update their data at least quarterly (e.g., March, June, September, December). These offices also produce monthly statistical information for the Monthly Index of National Production (IMPN), suggeting that revisions are made monthly.

    \item In the WR, revisions are effectively made on a month-to-month basis rather than week-to-week. Our reconstructed calendar confirms that the WR report updated GDP figures at least once per month.
\end{enumerate} 

%-----------------------------------------------------------------------
% 2. Raw Data Sources
%-----------------------------------------------------------------------

\section{Raw Data Sources}
\label{section:raw_data}

Once the monthly revision calendar was established, we compiled the last WR of each month. Each monthly WR defines a \emph{vintage} of GDP growth rates, which together form the basis of the RTD.

The WR republishes GDP growth rates by sector as released by INEI. These sectoral growth rates are reported year-on-year and presented in a well-organized table whose structure has changed little over the past three decades, although the table numbering has varied across issues. Two key tables were systematically extracted: one reporting monthly growth rates, and another reporting quarterly and annual growth rates

Historically, until the early 2000s, the WR was titled the ``Weekly Bulletin'', and no digital versions of either the Bulletin or the Report exist prior to 2013. Consequently, for the period spanning 2000–2012, the macroeconomic tables are only accessible in hardcover volumes available at the BCRP’s \href{https://biblioteca.bcrp.gob.pe/discovery/search?vid=51BCDRDP_INST:51BCDRDP2}{Renzo
 Rossini Library}, requiring in-person consultation. These volumes cannot be removed from the library, but they may be photocopied or photographed. This process is not always straightforward, as the historical WRs are often bound in large, heavy volumes.

From 2013 to the present, however, WRs have been freely accessible on the BCRP’s website in PDF format, which has greatly facilitated data collection. The data are also presented in spreadsheets and in the BCRP data database, although only in their revised form.

\subsection{Scanned Data (pre–2013)}

For the pre-2013 period, the WRs  were scanned into PDF format, producing non-structured hardcopies. Consequently, the extraction process was far from trivial and followed three main steps: (i) Computer-based extraction, (ii) manual correction and verification, and (iii) construction of parsed structured tables feeding into automated vintage-building codes. %\footnote{OCR was especially critical for the years prior to 2002. For subsequent years up to 2010, we were provided with confidential files containing GDP growth rates by BCRP specialists.}

The scanned sources posed significant challenges:  
%
\begin{itemize}
    \item Warped or distorted text and misaligned table lines, often caused by hardcover bindings during scanning.  
    \item Shadowing, opacity, or blur reducing legibility.  
    \item Fragmented or incomplete tables.  
    \item Highlighted entries interfering with optical recognition accuracy.  
    \item Inconsistent font sizes across tables within the same report.  
    \item Residual marks obscuring decimal points or digits.  
    \item Ink and other physical spots disrupting recognition.  
\end{itemize}

Figures~\ref{fig:wr_2_2007_table_1} and \ref{fig:wr_2_2007_table_2} show examples of scanned tables exhibiting some of these difficulties.  

\begin{figure}[!t]
\caption{Table 70, WR 2 (January 2007): monthly growth rates}
\includegraphics[width=1\textwidth]{pictures/wr_2_2007_table_1.pdf}
\label{fig:wr_2_2007_table_1}\\ 
\footnotesize \textbf{Notes:} The low resolution, uneven lighting, and shadowing from the page fold in this figure illustrate common difficulties for OCR processing. Distortions in the horizontal and vertical alignment of cells, faint characters, and overlapping text reduce recognition accuracy. Highlighted values and residual marks (e.g., spots or smudges) can obscure digits or decimal points, leading to frequent misclassifications. In this specific case, blurred numbers in the central columns and shading near the binding make it particularly challenging to extract reliable machine-readable data without extensive manual correction.
\end{figure}



Given these limitations, data extraction was particularly demanding and did not provide definite results. We employed Optical Character Recognition (OCR) using the open-source \href{https://github.com/tesseract-ocr/tesseract}{\texttt{Tesseract}} engine in \texttt{Python}. Originally developed by Hewlett-Packard and now maintained by Google, \texttt{Tesseract} is widely used for digitizing printed material, including statistical reports.

\newpage
The OCR workflow consisted of:  
%
\begin{enumerate}
    \item Converting pages into PNG format.  
    \item Transforming visual text into machine-readable formats, with extensive pre-processing to improve accuracy:  
        \begin{itemize}
            \item Grayscale conversion and binarization to separate text from background.  
            \item Noise removal (e.g., speckles, smudges) using median filtering or adaptive thresholding.  
            \item Skew correction (deskewing) to align rotated text.  
            \item Image scaling to ensure at least 300 DPI resolution.  
            \item Contrast enhancement (e.g., via CLAHE) to make characters more prominent.  
            \item Thinning and skeletonization to separate thick or touching characters.  
            \item Border removal to avoid false detections.  
        \end{itemize}
    \item Extracting tabular text into editable formats.  
\end{enumerate}

Although OCR provided an initial transcription, frequent misclassifications occurred (e.g., reading \texttt{9.4} as \texttt{5.4}), making manual verification indispensable.

\begin{figure}[!t]
\caption{Table 88, WR 2 (January 2007): quarterly and annual growth rates}  \label{fig:wr_2_2007_table_2}
\includegraphics[width=1\textwidth]{pictures/wr_2_2007_table_2.pdf}\\      
\footnotesize \textbf{Notes:} Another example of a problematic scanned WR table. OCR processing is hindered by uneven contrast, faint print, shading near the binding, and inconsistent alignment. Highlighted values, small font sizes, and residual marks further obscure digits and decimal points, making reliable digitization difficult without extensive pre-processing and manual checks.
\end{figure}

Once raw tables were extracted and put in  readable csv format, we parsed and processed the data using functions documented in \texttt{old\_gdp\_dataset\_functions.py} and implemented in \texttt{old\_gdp\_dataset.ipynb}. The pipeline involved: 
%
\begin{enumerate}  
    \item Further data cleaning and validation.  
    \item Concatenation of target-event datasets across vintages.  
    \item Merging of sector-level datasets across vintages.  
    \item Storage of structured vintages in SQL for the pre-2013 sample.  
\end{enumerate}

The combination of automated routines and manual oversight was essential for ensuring the reliability of the early vintages.



\subsection{Digital Data (post-2013)}

Since 2013, WRs have been published online as digital PDFs (semi-structured data), greatly facilitating automated extraction. We developed \texttt{Python} routines to handle heterogeneous table structures across reports. Although digital sources were more consistent than scanned volumes, irregular formatting still required flexible parsing scripts. The primary extraction library was \texttt{tabula}, selected for its robustness in dealing with complex table layouts.

\newpage
Despite their advantages, digital sources also presented several recurring issues:  
%
\begin{itemize}
    \item Encoded characters replacing numerical values (e.g., \texttt{(cid:101)(cid:115)}).  
    \item Incomplete vertical lines separating columns, creating ambiguous parsing.  
    \item Duplicate documents (e.g., \texttt{ns-21-2015} and \texttt{ns-45-2015}), disrupting scraping routines.  
    \item Empty table cells misinterpreted as headers (e.g., \texttt{ns-25-2014}, \texttt{ns-14-2020}).  
    \item Missing target-period labels, complicating the assignment of growth rates (e.g., \texttt{ns-28-2013}).  
    \item Missing year labels, complicating the chronological alignment of data (e.g., \texttt{ns-28-2013}).  
    \item Duplicated or misaligned headers generating spurious columns.  
    \item Double or fragmented border lines, complicating table parsing.  
\end{itemize}

Figure~\ref{fig:wr_28_2013_table_1} shows an example of a monthly table in digital format, where the fifth issue above is apparent: missing year labels (from May to December). While it is obvious to a human reader that the missing label corresponds to year \texttt{2012}, automated scripts must explicitly account for such cases. On the other hand, Figure~\ref{fig:wr_48_2016_table_2} illustrates additional issues such as incomplete borders and duplicated headers.


\begin{figure}[t!]
\caption{Table 62, WR 28 (July 2013): monthly growth rates}\label{fig:wr_28_2013_table_1}
\includegraphics[width=1\textwidth]{pictures/wr_28_2013_table_1.pdf}\\       
\footnotesize \textbf{Notes:} Although OCR accuracy is much higher than for scanned sources, gaps remain in the archive. For instance, the year 2012 is missing. Such discontinuities complicate the construction of a complete real-time dataset and require cross-checking against alternative sources.
\end{figure}

\begin{figure}[t!]
\caption{Table 82, WR 48 (December 2016): quarterly and annual growth rates}\label{fig:wr_48_2016_table_2}
\includegraphics[width=1\textwidth]{pictures/wr_48_2016_table_2.pdf}\\        
\footnotesize \textbf{Notes:} While free of resolution problems, this table illustrates other challenges for automated extraction, such as irregular table borders, as the border to the right of ``I'' in year 2016. These features can disrupt parsing routines and require additional cleaning before integration into the RTD.
\end{figure}

\newpage
The replication codes were designed to systematically address these problems without resorting to \textit{hardcoding}. This ensured adaptability to changes in table formats and preserved consistency across vintages. 
%
All functions are modular and documented in \texttt{new\_gdp\_dataset\_functions.py}. The routines were specifically designed to handle formatting inconsistencies, providing flexibility for future WR formats. In particular, the workflow generates two logs: one storing the raw tables (as extracted by \texttt{tabula}), and another containing the fully cleaned versions. This structure allows researchers to compare original data with processed results, offering a transparent view of both challenges and solutions.  

The extraction workflow, implemented in \texttt{new\_gdp\_dataset.ipynb}, followed these steps:  
%
\begin{enumerate}
    \item Automated downloading of WR PDFs from the BCRP website via a scraper.  
    \item Identification of relevant tables (monthly, quarterly, and annual) using keyword searches.  
    \item Extraction of tables with \texttt{tabula}.  
    \item Cleaning and restructuring into standardized \texttt{Python} dictionaries.  
    \item Concatenation of target-event datasets across vintages.  

   % \item Merging of sector-level datasets across vintages.  
    \item Export of structured vintages in SQL for the post-2013 sample.  
\end{enumerate}

\newpage
Once both scanned and digital vintages were processed, they were integrated into a continuous RTD spanning 2000–2024. The integration, implemented in \texttt{gdp\_revisions\_datasets.ipynb}, involved:  
%
\begin{enumerate}
    \item Concatenating vintages from pre- and post-2013 samples.  
    \item Generating datasets excluding observations affected by base-year changes.  
    \item Producing benchmarking dummies to flag revisions from rebasing.  
    %\item Merging vintages into release-based datasets.  
    %\item Computing revisions ($r$)
    \item Storage of structured vintages in SQL for the whole sample.   
\end{enumerate}




 


%-----------------------------------------------------------------------
% 3. The Real-Time Dataset (RTD)
%-----------------------------------------------------------------------

\section{The Real-Time Dataset (RTD)}
\label{section:rtd}
We emphasize the distinction between two key products:  

\begin{itemize}
    \item \textbf{Vintages dataset:} contains all successive records as originally extracted. This constitutes the real-time dataset (RTD). 
    \item \textbf{Releases dataset:} derived from vintages, reorganized for revision analysis, and serving as the main input for our empirical tests.  
\end{itemize}

The vintages dataset is the direct output of the extraction process and preserves the chronology of publications exactly as they appeared. By contrast, the releases dataset is a research-oriented transformation of the RTD, specifically designed to facilitate the study of revisions. Both formats are complementary: the vintages dataset ensures transparency and replicability, while the releases dataset provides the structure needed for econometric testing.

To illustrate the difference, we focus on a window that captures the lockdown effects of the COVID-19 pandemic. This period registers unusually negative monthly growth rates that are easy to track visually. Table~\ref{tab:vintages} illustrates the structure of the RTD: columns represent vintages, while rows correspond to target periods or events. For instance, the July 2020 vintage contained growth figures for May 2019 through May 2020. That WR included the third estimate for March 2020 (-16.30) and the first estimate for May 2020 (-32.80). To guide interpretation, first releases in each row are highlighted in blue, second releases in red, third releases in green, and fourth releases in yellow.

The releases dataset reorganizes the same information so that each column groups all publications corresponding to the same release sequence (first, second, third, etc.) across target periods. Table~\ref{tab:releases} provides a visual representation of this reorganization. The first release of each target period is gathered in the $y^1_t$ column, the second in the $y^2_t$ column, and so forth. For example, the figures for February and April 2020 highlighted in blue in Table~\ref{tab:vintages} appear in different columns within the RTD but are grouped together in the $y^1_t$ column of Table~\ref{tab:releases}, since both correspond to first estimates. Similarly, the red-highlighted figures in Table~\ref{tab:vintages} are grouped under the $y^2_t$ column in Table~\ref{tab:releases}, and so on. 

This procedure, widely adopted in the literature, facilitates the computation of revisions as differences between consecutive release columns. In particular, the ``Last release'' column ($H$) contains the definitive values for each period, after which no further significant revisions are recorded. This structure makes explicit the sequence of information updates and provides a clear framework for the rationality and benchmarking tests presented in the main paper.


\begin{table}[t!]
\caption{Dataset of monthly vintages}\label{tab:vintages}
\resizebox{\textwidth}{!}{%
\input{tables/Tab_Vintages}
}\\[2mm]
\footnotesize \textbf{Notes:} This table illustrates the vintage format of a real-time database. Each column corresponds to a specific data vintage — that is, the set of estimates available in the WR at the end of a given month. Each row corresponds to a target period (e.g., a specific month for which GDP growth is estimated). The publication lag of the first release is two months. 
\end{table}


\begin{table}[!b]
\caption{Dataset of monthly releases}
\label{tab:releases}
\resizebox{\textwidth}{!}{\footnotesize{%
\input{tables/Tab_Releases}
}
%
}\\[2mm]
\footnotesize \textbf{Notes:} This table presents the release format of the  data in Table \ref{tab:vintages}, reorganized by target period to track successive estimates over time. Each row corresponds to a given target period (e.g., a specific month of GDP growth), and each column captures $y^h_t$, i.e. the $h$-th release of that estimate. 
\end{table}

%-----------------------------------------------------------------------
% 4. Peruvian GDP as a Real-Time Indicator
%-----------------------------------------------------------------------
\clearpage
\section{Coverage of the RTD}
\label{section:gdp_rtd_indicators}

We now summarize the coverage and structure of the RTD, which supports a comprehensive analysis of GDP as a real-time indicator of economic activity. 

The dataset includes monthly, quarterly, and annual GDP growth series, with temporal and horizon coverage detailed in Table~\ref{tab:rt_sum}. Sectoral disaggregation follows INEI’s level-9 classification—the most detailed level available—which distinguishes sectors such as manufacturing, commerce, agriculture, mining, and a wide range of services. The category “other services” includes real estate, education, and health.


\begin{table}[b!]
\caption{Sectoral GDP as a real-time indicator}
\label{tab:rt_sum}
\resizebox{\columnwidth}{!}{
\input{tables/Tab_RT_Summarize}
%
}\\[2mm]
\footnotesize \textbf{Notes:} The disaggregation of economic activities follows level 9 of INEI’s official classification. Under this classification, the “other services” sector includes a diverse set of activities, such as real estate and personal services, including education and health (14.89\%). The following categories are also identified: transportation, storage, postal and courier services (4.97\%); accommodation and food services (2.86\%); telecommunications and other information services (2.66\%); financial and insurance services (3.22\%); business services (4.24\%); product taxes (8.29\%); and public administration and defense (4.29\%).
\end{table}

\clearpage
%-----------------------------------------------------------------------
% 5. Replication and Availability
%-----------------------------------------------------------------------

\section{Replication and Availability}
\label{section:replication}

All scripts used in this supplementary material were developed following good programming practices and include complete documentation to ensure the reproducibility of results. Replication codes will be available upon request and will be made publicly accessible through an open GitHub repository once the article is accepted.

The repository will include, among other resources:

\begin{itemize}  
    \item \texttt{Python} scripts and functions for the construction of vintage and release datasets, particularly for updating new publications (2013--present). These routines cover automated downloading, extraction, cleaning, and data processing.  
    \item Documentation detailing how to access both vintage and release data from any software or programming language, with ready-to-use formats suitable for future research.  
\end{itemize}

The repository structure is designed to ensure full replicability while facilitating future extensions. All functions are programmed to handle heterogeneous formats robustly, allowing for adaptability to changes in the official release process.

\end{document}