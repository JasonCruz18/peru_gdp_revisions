{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127505dd-d5cc-4829-9190-6314ae54b3ca",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; color: #292929;\">\n",
    "  <h1 style=\"margin-bottom: 10px;\">New GDP Real-Time Dataset</h1>\n",
    "  <div style=\"height: 2px; width: 90%; margin: 0 auto; background-color: #292929;\"></div>\n",
    "  <h2>Documentation</h2>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b19f9-8caf-48a1-ac70-90ff99489590",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; margin-right: 40px;\">\n",
    "  <span style=\"display: inline-block; margin-right: 10px;\">\n",
    "    <a href=\"https://github.com/JasonCruz18\" target=\"_blank\">\n",
    "      <img src=\"https://cdn.jsdelivr.net/gh/devicons/devicon/icons/github/github-original.svg\" alt=\"GitHub\" style=\"width: 24px;\">\n",
    "    </a>\n",
    "  </span>\n",
    "  <span style=\"display: inline-block;\">\n",
    "    <a href=\"mailto:jj.cruza@up.edu.pe\">\n",
    "      <img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4e/Mail_%28iOS%29.svg\" alt=\"Email\" style=\"width: 24px;\">\n",
    "    </a>\n",
    "  </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96357866-58f8-4d8b-b25a-b9b145465322",
   "metadata": {},
   "source": [
    "**Author:** Jason Cruz  \n",
    "**Last updated:** 08/13/2025  \n",
    "**Python version:** 3.12  \n",
    "**Project:** Rationality and Nowcasting on Peruvian GDP Revisions  \n",
    "\n",
    "---\n",
    "## üìå Summary\n",
    "This notebook documents the step-by-step **construction of datasets** for analyzing **Peruvian GDP revisions** from 2013‚Äì2024.  \n",
    "It covers:\n",
    "1. **Data acquisition** from the Central Reserve Bank of Peru's Weekly Reports (PDF).\n",
    "2. **Data cleaning** and extraction of GDP tables.\n",
    "3. **Creation of real-time GDP vintages**.\n",
    "4. **Preparation of the final revisions dataset**.\n",
    "5. **Export to SQL** for further analysis.\n",
    "\n",
    "üåê **Main Data Source:** [BCRP Weekly Report](https://www.bcrp.gob.pe/publicaciones/nota-semanal.html) (üì∞ WR, from here on)  \n",
    "Any questions or issues regarding the coding, please email [Jason üì®](mailto:jj.cruza@alum.up.edu.pe)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907046a",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac40ed0",
   "metadata": {},
   "source": [
    "If you don't have the libraries below, please use the following code (as example) to install the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c73193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d47b8-5873-426b-b739-e1fc05dcf8e5",
   "metadata": {},
   "source": [
    "Check out Python information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55588d8e-8df5-406a-8644-e67ff1dcbc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"üêç Python Information\")\n",
    "print(f\"  Version  : {sys.version.split()[0]}\")\n",
    "print(f\"  Compiler : {platform.python_compiler()}\")\n",
    "print(f\"  Build    : {platform.python_build()}\")\n",
    "print(f\"  OS       : {platform.system()} {platform.release()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "214f5982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# 1. PDF downloader\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import os  # For file and directory manipulation, for interacting with the operating system\n",
    "import random  # To generate random numbers\n",
    "from selenium import webdriver  # For automating web browsers\n",
    "from selenium.webdriver.common.by import By  # To locate elements on a webpage\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # To wait until certain conditions are met on a webpage.\n",
    "from selenium.webdriver.support import expected_conditions as EC  # To define expected conditions\n",
    "from selenium.common.exceptions import StaleElementReferenceException  # To handle exceptions related to elements on the webpage that are no longer available.\n",
    "import pygame # Allows you to handle graphics, sounds and input events.\n",
    "from webdriver_manager.chrome import ChromeDriverManager # To avoid compatibility issues with the ChromeDrive version of ChromeDrive\n",
    "\n",
    "import shutil # Used for high-level file operations, such as copying, moving, renaming, and deleting files and directories.\n",
    "\n",
    "\n",
    "# 2. Generate PDF input with key tables\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import fitz  # This library is used for working with PDF documents, including reading, writing, and modifying PDFs (PyMuPDF).\n",
    "import tkinter as tk  # This library is used for creating graphical user interfaces (GUIs) in Python.\n",
    "\n",
    "\n",
    "# 3. Data cleaning\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 3.1. A brief documentation on issus in the table information of the PDFs\n",
    "\n",
    "from PIL import Image  # Used for opening, manipulating, and saving image files.\n",
    "import matplotlib.pyplot as plt  # Used for creating static, animated, and interactive visualizations.\n",
    "\n",
    "# 3.2. Extracting tables and data cleanup\n",
    "\n",
    "import pdfplumber  # For extracting text and metadata from PDF files\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import unicodedata  # For manipulating Unicode data\n",
    "import re  # For regular expressions operations\n",
    "from datetime import datetime  # For working with dates and times\n",
    "import locale  # For locale-specific formatting of numbers, dates, and currencies\n",
    "\n",
    "# 3.2.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "\n",
    "import tabula  # Used to extract tables from PDF files into pandas DataFrames\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO  # Used for creating graphical user interfaces\n",
    "from sqlalchemy import create_engine  # Used for connecting to and interacting with SQL databases\n",
    "\n",
    "# 3.2.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "\n",
    "import roman\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# 4. Real-time data of Peru's GDP growth rates\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import psycopg2  # For interacting with PostgreSQL databases\n",
    "from sqlalchemy import create_engine, text  # For creating and executing SQL queries using SQLAlchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ef8f8",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5afa5-c77a-4bd4-a0f4-509e2095728d",
   "metadata": {},
   "source": [
    "Before preprocessing new GDP releases data, we will:\n",
    "\n",
    "* **Create necessary folders** for storing inputs, outputs, logs, and screenshots.\n",
    "* **Connect to the PostgreSQL database** containing GDP revisions datasets.\n",
    "* **Import helper functions** from `new_gdp_datasets_functions.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc1c80",
   "metadata": {},
   "source": [
    "**Create necessary folders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbb4b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ digital_pdf created\n",
      "üìÇ digital_pdf\\raw_pdf created\n",
      "üìÇ digital_pdf\\input_pdf created\n",
      "üìÇ record created\n",
      "üìÇ alert_track created\n"
     ]
    }
   ],
   "source": [
    "# Define base folder for saving all digital PDFs\n",
    "digital_pdf = 'digital_pdf'\n",
    "\n",
    "# Define subfolder for saving the original PDFs as downloaded from the BCRP website\n",
    "raw_pdf = os.path.join(digital_pdf, 'raw_pdf')\n",
    "\n",
    "# Define subfolder for saving reduced PDFs containing only selected pages with GDP growth tables (monthly, quarterly, and annual frequencies)\n",
    "input_pdf = os.path.join(digital_pdf, 'input_pdf')\n",
    "\n",
    "# Define folder for saving .txt files with download and dataframe record\n",
    "record = 'record'\n",
    "\n",
    "# Define folder for saving warning bells. This is for download notifications (see section 1).\n",
    "alert_track = 'alert_track'\n",
    "\n",
    "# Create all required folders (if they do not already exist) and confirm creation\n",
    "for folder in [digital_pdf, raw_pdf, input_pdf, record, alert_track]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"üìÇ {folder} created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e36f49d-15ba-481e-b16b-0ae56d5d0c12",
   "metadata": {},
   "source": [
    "**Connect to the PostgreSQL database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bdd5dc",
   "metadata": {},
   "source": [
    "The following function will establish a connection to the `gdp_revisions_datasets` database in `PostgreSQL`. The **input data** used in this jupyter notebook will be loaded from this `PostgreSQL` database, and similarly, all **output data** generated by this jupyter notebook will be stored in that database. Ensure that you set the necessary parameters to access the server once you have obtained the required permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e982f83",
   "metadata": {},
   "source": [
    "> üí° **Tip:** To request permissions, please email [Jason üì®](mailto:jj.cruza@alum.up.edu.pe)  \n",
    "> ‚ö†Ô∏è **Warning:** Make sure you have set your SQL credentials as environment variables before proceeding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3b60634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlalchemy_engine(database=\"gdp_revisions_datasets\", port=5432):\n",
    "    \"\"\"\n",
    "    Create an SQLAlchemy engine to connect to the PostgreSQL database.\n",
    "    \n",
    "    Environment Variables Required:\n",
    "        CIUP_SQL_USER: SQL username\n",
    "        CIUP_SQL_PASS: SQL password\n",
    "        CIUP_SQL_HOST: SQL host address\n",
    "\n",
    "    Args:\n",
    "        database (str): Name of the database. Default is 'gdp_revisions_datasets'.\n",
    "        port (int): Port number. Default is 5432.\n",
    "\n",
    "    Returns:\n",
    "        engine (sqlalchemy.engine.Engine): SQLAlchemy engine object.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If required environment variables are missing.\n",
    "\n",
    "    Example:\n",
    "        engine = create_sqlalchemy_engine()\n",
    "    \"\"\"\n",
    "    user = os.environ.get('CIUP_SQL_USER')\n",
    "    password = os.environ.get('CIUP_SQL_PASS')\n",
    "    host = os.environ.get('CIUP_SQL_HOST')\n",
    "\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"‚ùå Missing environment variables: CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS\")\n",
    "\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    print(f\"üîó Connected to PostgreSQL database: {database} at {host}:{port}\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a76e853-8dc9-45e6-9f30-cde33dd3966e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Connected to PostgreSQL database: gdp_revisions_datasets at localhost:5432\n"
     ]
    }
   ],
   "source": [
    "engine = create_sqlalchemy_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b819ed7-9661-4efd-972e-b38e78f48ae3",
   "metadata": {},
   "source": [
    "**Import helper functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a836f",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è Please, check the script `new_gdp_datasets_functions.py` which contains all the functions required by this _jupyter notebook_. The functions there are ordered according to the sections of this jupyter notebok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83d1e89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_gdp_datasets_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f3192",
   "metadata": {},
   "source": [
    "## 1. PDF Downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98250a64",
   "metadata": {},
   "source": [
    "Our main source for data collection is the [BCRP Weekly Report](https://www.bcrp.gob.pe/publicaciones/nota-semanal.html). The weekly report is a periodic (weekly) publication of the BCRP in compliance with article 84 of the Peruvian Constitution and articles 2 and 74 of the BCRP's organic law, which include, among its functions, the periodic publication of the main national macroeconomic statistics.\n",
    "    \n",
    "Our project requires the publication of **two tables**: the table of monthly growth rates of real GDP (12-month percentage changes), and the table of quarterly (annual) growth rates of real GDP. These tables are referred to as **Table 1** and **Table 2**, respectively, throughout this jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d95c04",
   "metadata": {},
   "source": [
    "### Scraper bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcc4e3",
   "metadata": {},
   "source": [
    "This section automates the download of the **BCRP Weekly Report PDFs** directly from the official BCRP website.\n",
    "\n",
    "**What it does:**\n",
    "1. Opens the official BCRP Weekly Report page.\n",
    "2. Finds and collects all PDF links.\n",
    "3. Downloads them in chronological order (oldest to newest).\n",
    "4. Optionally plays a notification sound every N downloads.\n",
    "5. Organizes downloaded PDFs into year-based folders.\n",
    "\n",
    "> üí° If a CAPTCHA appears, solve it manually in the browser window and re-run the cell.\n",
    "\n",
    "> üîÅ This script uses webdriver-manager to automatically handle browser drivers (default: Chrome), so you DO NOT need to manually download ChromeDriver, GeckoDriver, etc. If you want to change browser for your replication, modify the 'browser' parameter in init_driver().\n",
    "\n",
    "> üéµ Place your own MP3 file in `alert_track` folder for download notifications. Recommended free sources (CC0/public domain):\n",
    ">  - Pixabay Audio: https://pixabay.com/music/\n",
    ">  - FreeSound: https://freesound.org/\n",
    ">  - FreePD: https://freepd.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee0199bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Starting PDF Downloader for BCRP Weekly Reports...\n",
      "\n",
      "üåê BCRP site opened successfully.\n",
      "üîé Found 154 WR on page (one per month).\n",
      "\n",
      "1. ‚úÖ Downloaded: ns-04-2019.pdf\n",
      "‚è≥ Waiting 6.04 seconds...\n",
      "2. ‚úÖ Downloaded: ns-07-2019.pdf\n",
      "‚è≥ Waiting 9.22 seconds...\n",
      "3. ‚úÖ Downloaded: ns-10-2019.pdf\n",
      "‚è≥ Waiting 7.91 seconds...\n",
      "4. ‚úÖ Downloaded: ns-13-2019.pdf\n",
      "‚è≥ Waiting 6.57 seconds...\n",
      "5. ‚úÖ Downloaded: ns-17-2019.pdf\n",
      "‚è≥ Waiting 7.36 seconds...\n",
      "6. ‚úÖ Downloaded: ns-20-2019.pdf\n",
      "‚è≥ Waiting 5.04 seconds...\n",
      "7. ‚úÖ Downloaded: ns-23-2019.pdf\n",
      "‚è≥ Waiting 9.19 seconds...\n",
      "8. ‚úÖ Downloaded: ns-26-2019.pdf\n",
      "‚è≥ Waiting 5.64 seconds...\n",
      "9. ‚úÖ Downloaded: ns-29-2019.pdf\n",
      "‚è≥ Waiting 8.57 seconds...\n",
      "10. ‚úÖ Downloaded: ns-33-2019.pdf\n",
      "‚è≥ Waiting 9.45 seconds...\n",
      "11. ‚úÖ Downloaded: ns-36-2019.pdf\n",
      "‚è≥ Waiting 7.48 seconds...\n",
      "12. ‚úÖ Downloaded: ns-39-2019.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚è∏Ô∏è Continue? (y = yes, any other key = stop):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ Waiting 6.52 seconds...\n",
      "13. ‚úÖ Downloaded: ns-03-2020.pdf\n",
      "‚è≥ Waiting 8.70 seconds...\n",
      "14. ‚úÖ Downloaded: ns-07-2020.pdf\n",
      "‚è≥ Waiting 5.75 seconds...\n",
      "15. ‚úÖ Downloaded: ns-11-2020.pdf\n",
      "‚è≥ Waiting 9.79 seconds...\n",
      "16. ‚úÖ Downloaded: ns-16-2020.pdf\n",
      "‚è≥ Waiting 9.86 seconds...\n",
      "17. ‚úÖ Downloaded: ns-20-2020.pdf\n",
      "‚è≥ Waiting 6.06 seconds...\n",
      "18. ‚úÖ Downloaded: ns-24-2020.pdf\n",
      "‚è≥ Waiting 9.41 seconds...\n",
      "19. ‚úÖ Downloaded: ns-28-2020.pdf\n",
      "‚è≥ Waiting 8.94 seconds...\n",
      "20. ‚úÖ Downloaded: ns-32-2020.pdf\n",
      "‚è≥ Waiting 5.70 seconds...\n",
      "21. ‚úÖ Downloaded: ns-36-2020.pdf\n",
      "‚è≥ Waiting 8.51 seconds...\n",
      "22. ‚úÖ Downloaded: ns-39-2020.pdf\n",
      "‚è≥ Waiting 8.99 seconds...\n",
      "23. ‚úÖ Downloaded: ns-43-2020.pdf\n",
      "‚è≥ Waiting 8.59 seconds...\n",
      "24. ‚úÖ Downloaded: ns-47-2020.pdf\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "‚è∏Ô∏è Continue? (y = yes, any other key = stop):  n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üõë Download stopped by user.\n",
      "\n",
      "üëã Browser closed.\n",
      "\n",
      "üìä Summary:\n",
      "\n",
      "üîó Total monthly links kept: 154\n",
      "üóÇÔ∏è 72 already downloaded PDFs were skipped.\n",
      "‚ûï Newly downloaded: 24\n",
      "‚è±Ô∏è Time: 300 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run the function to start the scraper bot\n",
    "download_pdfs(\n",
    "    bcrp_url = \"https://www.bcrp.gob.pe/publicaciones/nota-semanal.html\",\n",
    "    raw_pdf_folder = raw_pdf,\n",
    "    download_record_folder = record,\n",
    "    download_record_txt = 'new_downloaded_pdfs.txt',\n",
    "    alert_track_folder = alert_track,\n",
    "    max_downloads = 60\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773491f5-fd62-497b-9f94-59e5095c5659",
   "metadata": {},
   "source": [
    "Probably the üì∞ WR were downloaded in a single folder, but we would like the WR to be sorted by years. The following code sorts the PDFs into subfolders (years) for us by placing each WR according to the year of its publication. This happens in the **\"blink of an eye\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ee016a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the directory\n",
    "files = os.listdir(raw_pdf)\n",
    "\n",
    "# Call the function to organize files\n",
    "organize_files_by_year(raw_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b482a-b33d-4059-b4a2-805ba4612fd8",
   "metadata": {},
   "source": [
    "# WR-08-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a626509-2142-4de1-ba7f-9e47b7a8c81a",
   "metadata": {},
   "source": [
    "This  is crucial for the upcoming steps, specially for the section 3, cleansing. If -in the future- you enconuter some issues by executing cleaing it is likely to atributte to the pdf nature. IN that case, you can return to this code to replace defectiv pdfs for those convinient ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d75a9-308b-4fa1-848a-9771fcffbb1b",
   "metadata": {},
   "source": [
    "Don't worry about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad4344-deba-476d-91e7-6871c6ba4996",
   "metadata": {},
   "source": [
    "T√∫ puedes hacer lo mismo si te enfrentas a un inconveniente similar. Incluso puedes descargar los casos excepecionales de WR de un mismo mes y reemplazar los defectuosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3e956de-ead1-4439-a3c5-bab8aeb75a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß© Replacing 2 PDF(s) under: digital_pdf\\raw_pdf\n",
      "ü¶† Quarantine enabled ‚Üí digital_pdf\\raw_pdf\\_quarantine\n",
      "‚¨áÔ∏è  2017: downloading ns-07-2017 ‚Ä¶\n",
      "‚úÖ  2017: ns-08-2017.pdf ‚Üí ns-07-2017.pdf (moved to _quarantine)\n",
      "‚¨áÔ∏è  2019: downloading ns-22-2019 ‚Ä¶\n",
      "‚úÖ  2019: ns-23-2019.pdf ‚Üí ns-22-2019.pdf (moved to _quarantine)\n",
      "\n",
      "üìä Summary: ‚úÖ 2 done ¬∑ ‚ùå 0 failed\n"
     ]
    }
   ],
   "source": [
    "# Replace specific defective PDFs (friendly outputs with icons)\n",
    "replace_ns_pdfs(\n",
    "    items=[\n",
    "        (\"2017\", \"ns-08-2017.pdf\", \"ns-07-2017\"), # Enter the year (folder) that contains the defective PDF, the defective PDF, and the new chosen PDF \n",
    "        (\"2019\", \"ns-23-2019.pdf\", \"ns-22-2019\"), # The same one above\n",
    "    ],\n",
    "    root_folder=raw_pdf, # base folder with /2017, /2019, ...\n",
    "    record_folder=record, # folder with new_downloaded_pdfs.txt\n",
    "    download_record_txt = 'new_downloaded_pdfs.txt',\n",
    "    quarantine=os.path.join(raw_pdf, \"_quarantine\")  # set to None to delete instead\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d24d2",
   "metadata": {},
   "source": [
    "## 2. Generate PDF input with key tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666f310",
   "metadata": {},
   "source": [
    "Now that we have downloaded the üì∞ WR from the Central Bank, we should know that each of these files has more than 100 pages, but not all of them contain the information required for this project.\n",
    "\n",
    "All we really want is a couple of pages from each üì∞ WR, one for **Table 1** (monthly real GDP growth) and one for **Table 2** (annual and quarterly real GDP growth). The code below is executed to maintain the **two key pages** with both tables of each PDF plus the cover page that contains the information that helps us identify one üì∞ WR from another such as its date of publication and serial number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6af50-3b5b-44f2-859a-3b37d4b57495",
   "metadata": {},
   "source": [
    "_quarentine will be discard of the input PDF generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae30e931",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: 2016\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40be0f24f46045e6a9bb66a366282093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating input PDFs in 2016:   0%|          | 0/12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shortened PDFs saved in 'digital_pdf\\input_pdf' (12 new, 0 skipped)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to continue to the next folder after '2016'? (y = yes / n = no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: 2017\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a25fb3641f14898ba7aeed314447954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating input PDFs in 2017:   0%|          | 0/12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shortened PDFs saved in 'digital_pdf\\input_pdf' (12 new, 0 skipped)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to continue to the next folder after '2017'? (y = yes / n = no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: 2018\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b6d2b5fc648443db74792376be0d48f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating input PDFs in 2018:   0%|          | 0/12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shortened PDFs saved in 'digital_pdf\\input_pdf' (12 new, 0 skipped)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to continue to the next folder after '2018'? (y = yes / n = no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: 2019\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f566c995fe246b18d1a60e3c5f18811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating input PDFs in 2019:   0%|          | 0/12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shortened PDFs saved in 'digital_pdf\\input_pdf' (12 new, 0 skipped)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to continue to the next folder after '2019'? (y = yes / n = no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: 2020\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6484e103334bf1a6edf13d8bf9c8c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating input PDFs in 2020:   0%|          | 0/12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Shortened PDFs saved in 'digital_pdf\\input_pdf' (12 new, 0 skipped)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to continue to the next folder after '2020'? (y = yes / n = no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è© 36 input PDFs already generated for years: 2013, 2014, 2015\n",
      "\n",
      "üìä Summary:\n",
      "\n",
      "üìÇ 9 folders (years) found containing raw PDFs\n",
      "üóÇÔ∏è Already generated input PDFs: 36\n",
      "‚ûï Newly generated input PDFs: 60\n",
      "‚è±Ô∏è Time: 96 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run the function to generate trimmed PDFs for input\n",
    "generate_input_pdfs(\n",
    "    raw_pdf_folder = raw_pdf,\n",
    "    input_pdf_folder = input_pdf,\n",
    "    input_pdf_record_folder = record,\n",
    "    input_pdf_record_txt = 'new_generated_input_pdfs.txt',\n",
    "    keywords = [\"ECONOMIC SECTORS\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643079a",
   "metadata": {},
   "source": [
    "Again, probably the WR (PDF files, now of few pages) were stored in disorder in the `input_pdf_folder` folder. The following code sorts the PDFs into subfolders (years) by placing each WR (which now includes only the key tables) according to the year of its publication. This happens in the **\"blink of an eye\"**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae87395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the directory\n",
    "files = os.listdir(input_pdf)\n",
    "\n",
    "# Call the function to organize files\n",
    "organize_files_by_year(input_pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e1e92",
   "metadata": {},
   "source": [
    "## 3. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100857d4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "Since we already have the PDFs <span style=\"font-size: 24px;\">&#128462;</span> with just the tables required for this project, we can start extracting them. Then we can proceed with data cleaning.\n",
    "</p>  \n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357318e8",
   "metadata": {},
   "source": [
    "### 3.2 Extracting tables and data cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea58b1c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The main library used for extracting tables from PDFs <span style=\"font-size: 24px;\">&#128462;</span> is <code>pdfplumber</code>. You can review the official documentation by clicking <a href=\"https://github.com/jsvine/pdfplumber\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">here</a>.\n",
    "</p>\n",
    "    \n",
    "<p>     \n",
    "    The functions in <b>Section 3</b> of the <code>\"new_gdp_datasets_functions.py\"</code> script were built to deal with each of these issues. An interesting exercise is to compare the original tables (the ones in the PDF <span style=\"font-size: 24px;\">&#128462;</span>) and the cleaned tables (by the cleanup codes below). Thus, the cleanup codes for <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a> and <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a> generates two dictionaries, the first one stores the raw tables; that is, the original tables from the PDF <span style=\"font-size: 24px;\">&#128462;</span> extracted by the <code>pdfplumber</code> library, while the second dictionary stores the fully cleaned tables.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070fb47",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    The code iterates through each PDF <span style=\"font-size: 24px;\">&#128462;</span> and extracts the two required tables from each. The extracted information is then transformed into dataframes and the columns and values are cleaned up to conform to Python conventions (pythonic).\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436c2d1",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.2.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 1.</span> Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65139cc2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The basic criterion to start extracting tables is to use keywords (sufficient condition). I mean, tables containing the following keywords meet the requirements to be extracted.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e77729e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords to search in the page text\n",
    "keywords = [\"ECONOMIC SECTORS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4ac96",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <b>\"ns_dates\"</b> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c510db0-2a30-41b6-8bc4-d7d713ce5d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder 2013\n",
      "  1. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-04-2013.pdf: ns_04_2013_1\n",
      "  2. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-08-2013.pdf: ns_08_2013_1\n",
      "  3. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-12-2013.pdf: ns_12_2013_1\n",
      "  4. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-16-2013.pdf: ns_16_2013_1\n",
      "  5. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-21-2013.pdf: ns_21_2013_1\n",
      "  6. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-25-2013.pdf: ns_25_2013_1\n",
      "  7. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-29-2013.pdf: ns_29_2013_1\n",
      "  8. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-33-2013.pdf: ns_33_2013_1\n",
      "  9. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-37-2013.pdf: ns_37_2013_1\n",
      "  10. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-42-2013.pdf: ns_42_2013_1\n",
      "  11. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-46-2013.pdf: ns_46_2013_1\n",
      "  12. DataFrame generated for file digital_pdf\\input_pdf\\2013\\ns-50-2013.pdf: ns_50_2013_1\n",
      "Processing folder 2014\n",
      "  1. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-04-2014.pdf: ns_04_2014_1\n",
      "  2. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-08-2014.pdf: ns_08_2014_1\n",
      "  3. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-12-2014.pdf: ns_12_2014_1\n",
      "  4. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-15-2014.pdf: ns_15_2014_1\n",
      "  5. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-20-2014.pdf: ns_20_2014_1\n",
      "  6. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-24-2014.pdf: ns_24_2014_1\n",
      "  7. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-28-2014.pdf: ns_28_2014_1\n",
      "  8. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-32-2014.pdf: ns_32_2014_1\n",
      "  9. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-36-2014.pdf: ns_36_2014_1\n",
      "  10. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-41-2014.pdf: ns_41_2014_1\n",
      "  11. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-45-2014.pdf: ns_45_2014_1\n",
      "  12. DataFrame generated for file digital_pdf\\input_pdf\\2014\\ns-49-2014.pdf: ns_49_2014_1\n",
      "Processing folder 2015\n",
      "  1. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-04-2015.pdf: ns_04_2015_1\n",
      "  2. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-08-2015.pdf: ns_08_2015_1\n",
      "  3. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-12-2015.pdf: ns_12_2015_1\n",
      "  4. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-16-2015.pdf: ns_16_2015_1\n",
      "  5. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-21-2015.pdf: ns_21_2015_1\n",
      "  6. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-24-2015.pdf: ns_24_2015_1\n",
      "  7. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-28-2015.pdf: ns_28_2015_1\n",
      "  8. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-32-2015.pdf: ns_32_2015_1\n",
      "  9. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-36-2015.pdf: ns_36_2015_1\n",
      "  10. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-40-2015.pdf: ns_40_2015_1\n",
      "  11. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-45-2015.pdf: ns_45_2015_1\n",
      "  12. DataFrame generated for file digital_pdf\\input_pdf\\2015\\ns-48-2015.pdf: ns_48_2015_1\n",
      "Processing folder 2016\n",
      "  1. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-04-2016.pdf: ns_04_2016_1\n",
      "  2. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-08-2016.pdf: ns_08_2016_1\n",
      "  3. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-11-2016.pdf: ns_11_2016_1\n",
      "  4. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-16-2016.pdf: ns_16_2016_1\n",
      "  5. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-20-2016.pdf: ns_20_2016_1\n",
      "  6. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-24-2016.pdf: ns_24_2016_1\n",
      "  7. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-28-2016.pdf: ns_28_2016_1\n",
      "  8. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-32-2016.pdf: ns_32_2016_1\n",
      "  9. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-37-2016.pdf: ns_37_2016_1\n",
      "  10. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-41-2016.pdf: ns_41_2016_1\n",
      "  11. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-44-2016.pdf: ns_44_2016_1\n",
      "  12. DataFrame generated for file digital_pdf\\input_pdf\\2016\\ns-48-2016.pdf: ns_48_2016_1\n",
      "Processing folder 2017\n",
      "  1. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-04-2017.pdf: ns_04_2017_1\n",
      "  2. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-07-2017.pdf: ns_07_2017_1\n",
      "  3. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-13-2017.pdf: ns_13_2017_1\n",
      "  4. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-16-2017.pdf: ns_16_2017_1\n",
      "  5. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-20-2017.pdf: ns_20_2017_1\n",
      "  6. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-25-2017.pdf: ns_25_2017_1\n",
      "  7. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-28-2017.pdf: ns_28_2017_1\n",
      "  8. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-33-2017.pdf: ns_33_2017_1\n",
      "  9. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-37-2017.pdf: ns_37_2017_1\n",
      "  10. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-41-2017.pdf: ns_41_2017_1\n",
      "  11. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-46-2017.pdf: ns_46_2017_1\n",
      "  12. DataFrame generated for file digital_pdf\\input_pdf\\2017\\ns-49-2017.pdf: ns_49_2017_1\n",
      "Processing folder 2018\n",
      "  1. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-03-2018.pdf: ns_03_2018_1\n",
      "  2. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-07-2018.pdf: ns_07_2018_1\n",
      "  3. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-11-2018.pdf: ns_11_2018_1\n",
      "  4. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-15-2018.pdf: ns_15_2018_1\n",
      "  5. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-20-2018.pdf: ns_20_2018_1\n",
      "  6. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-24-2018.pdf: ns_24_2018_1\n",
      "  7. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-28-2018.pdf: ns_28_2018_1\n",
      "  8. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-33-2018.pdf: ns_33_2018_1\n",
      "  9. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-37-2018.pdf: ns_37_2018_1\n",
      "  10. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-42-2018.pdf: ns_42_2018_1\n",
      "  11. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-46-2018.pdf: ns_46_2018_1\n",
      "  12. DataFrame generated for file digital_pdf\\input_pdf\\2018\\ns-49-2018.pdf: ns_49_2018_1\n",
      "Processing folder 2019\n",
      "  1. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-04-2019.pdf: ns_04_2019_1\n",
      "  2. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-07-2019.pdf: ns_07_2019_1\n",
      "  3. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-10-2019.pdf: ns_10_2019_1\n",
      "  4. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-13-2019.pdf: ns_13_2019_1\n",
      "  5. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-17-2019.pdf: ns_17_2019_1\n",
      "  6. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-20-2019.pdf: ns_20_2019_1\n",
      "  7. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-22-2019.pdf: ns_22_2019_1\n",
      "  8. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-26-2019.pdf: ns_26_2019_1\n",
      "  9. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-29-2019.pdf: ns_29_2019_1\n",
      "  10. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-33-2019.pdf: ns_33_2019_1\n",
      "  11. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-36-2019.pdf: ns_36_2019_1\n",
      "  12. DataFrame generated for file digital_pdf\\input_pdf\\2019\\ns-39-2019.pdf: ns_39_2019_1\n",
      "Processing folder 2020\n",
      "  1. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-03-2020.pdf: ns_03_2020_1\n",
      "  2. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-07-2020.pdf: ns_07_2020_1\n",
      "  3. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-11-2020.pdf: ns_11_2020_1\n",
      "  4. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-16-2020.pdf: ns_16_2020_1\n",
      "  5. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-20-2020.pdf: ns_20_2020_1\n",
      "  6. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-24-2020.pdf: ns_24_2020_1\n",
      "  7. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-28-2020.pdf: ns_28_2020_1\n",
      "  8. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-32-2020.pdf: ns_32_2020_1\n",
      "  9. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-36-2020.pdf: ns_36_2020_1\n",
      "  10. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-39-2020.pdf: ns_39_2020_1\n",
      "  11. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-43-2020.pdf: ns_43_2020_1\n",
      "  12. DataFrame generated for file digital_pdf\\input_pdf\\2020\\ns-47-2020.pdf: ns_47_2020_1\n",
      "Processing completed for all folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import locale\n",
    "import pdfplumber\n",
    "import tabula\n",
    "import pandas as pd\n",
    "from tkinter import Tk, messagebox\n",
    "\n",
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Dictionary to store generated DataFrames\n",
    "new_dataframes_dict_1 = {}\n",
    "\n",
    "# Path for the processed folders log file\n",
    "record_path = 'record/new_generated_dataframes_1.txt'\n",
    "\n",
    "# Function to correct month names\n",
    "def correct_month_name(month):\n",
    "    months_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "    return months_mapping.get(month, month)\n",
    "\n",
    "# Function to register processed folder\n",
    "def register_processed_folder(folder, num_processed_files):\n",
    "    with open(record_path, 'a') as file:\n",
    "        file.write(f\"{folder}:{num_processed_files}\\n\")\n",
    "\n",
    "# Function to check if folder has been processed\n",
    "def folder_processed(folder):\n",
    "    if not os.path.exists(record_path):\n",
    "        return False\n",
    "    with open(record_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(folder):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to process PDF file (extract table from first page)\n",
    "def process_pdf(pdf_path):\n",
    "    new_tables_dict_1 = {}\n",
    "    table_counter = 1\n",
    "\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None\n",
    "\n",
    "    new_filename = os.path.splitext(filename)[0].replace('-', '_')\n",
    "\n",
    "    # Extract table from first page only\n",
    "    tables = tabula.read_pdf(pdf_path, pages=1, multiple_tables=False, stream=True)\n",
    "    for j, table_df in enumerate(tables, start=1):\n",
    "        dataframe_name = f\"{new_filename}_1\"\n",
    "        new_tables_dict_1[dataframe_name] = table_df\n",
    "        table_counter += 1\n",
    "\n",
    "    return id_ns, year, new_tables_dict_1, 1  # keyword_count replaced by 1\n",
    "\n",
    "# Function to process folder\n",
    "def process_folder(folder):\n",
    "    print(f\"Processing folder {os.path.basename(folder)}\")\n",
    "    pdf_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.pdf')]\n",
    "\n",
    "    num_pdfs_processed = 0\n",
    "    num_dataframes_generated = 0\n",
    "    table_counter = 1\n",
    "    new_tables_dict_1 = {}\n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        id_ns, year, tables_dict_temp, _ = process_pdf(pdf_file)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for dataframe_name, df in tables_dict_temp.items():\n",
    "                file_name = os.path.splitext(os.path.basename(pdf_file))[0].replace('-', '_')\n",
    "                dataframe_name = f\"{file_name}_1\"\n",
    "\n",
    "                # Store raw DataFrame\n",
    "                new_tables_dict_1[dataframe_name] = df.copy()\n",
    "\n",
    "                # Apply cleaning pipeline\n",
    "                df_clean = df.copy()\n",
    "\n",
    "                # Use your same cleaning functions as before\n",
    "                if any(col.isdigit() and len(col) == 4 for col in df_clean.columns):\n",
    "                    df_clean = swap_nan_se(df_clean)\n",
    "                    df_clean = split_column_by_pattern(df_clean)\n",
    "                    df_clean = drop_rare_caracter_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = relocate_last_columns(df_clean)\n",
    "                    df_clean = replace_first_dot(df_clean)\n",
    "                    df_clean = swap_first_second_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = remove_digit_slash(df_clean)\n",
    "                    df_clean = replace_var_perc_first_column(df_clean)\n",
    "                    df_clean = replace_var_perc_last_columns(df_clean)\n",
    "                    df_clean = replace_number_moving_average(df_clean)\n",
    "                    df_clean = separate_text_digits(df_clean)\n",
    "                    df_clean = exchange_values(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = find_year_column(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                else:\n",
    "                    df_clean = check_first_row(df_clean)\n",
    "                    df_clean = check_first_row_1(df_clean)\n",
    "                    df_clean = replace_first_row_with_columns(df_clean)\n",
    "                    df_clean = swap_nan_se(df_clean)\n",
    "                    df_clean = split_column_by_pattern(df_clean)\n",
    "                    df_clean = drop_rare_caracter_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = relocate_last_columns(df_clean)\n",
    "                    df_clean = swap_first_second_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = remove_digit_slash(df_clean)\n",
    "                    df_clean = replace_var_perc_first_column(df_clean)\n",
    "                    df_clean = replace_var_perc_last_columns(df_clean)\n",
    "                    df_clean = replace_number_moving_average(df_clean)\n",
    "                    df_clean = expand_column(df_clean)\n",
    "                    df_clean = split_values_1(df_clean)\n",
    "                    df_clean = split_values_2(df_clean)\n",
    "                    df_clean = split_values_3(df_clean)\n",
    "                    df_clean = separate_text_digits(df_clean)\n",
    "                    df_clean = exchange_values(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = find_year_column(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_nan_with_previous_column_1(df_clean)\n",
    "                    df_clean = replace_nan_with_previous_column_2(df_clean)\n",
    "                    df_clean = replace_nan_with_previous_column_3(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "                # Add 'year' and 'id_ns' columns\n",
    "                df_clean.insert(0, 'year', year)\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "\n",
    "                # Store cleaned DataFrame\n",
    "                new_dataframes_dict_1[dataframe_name] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. DataFrame generated for file {pdf_file}: {dataframe_name}')\n",
    "                num_dataframes_generated += 1\n",
    "                table_counter += 1\n",
    "        \n",
    "        num_pdfs_processed += 1\n",
    "\n",
    "    return num_pdfs_processed, num_dataframes_generated, new_tables_dict_1\n",
    "\n",
    "# Function to process folders\n",
    "def process_folders():\n",
    "    input_pdf_folder = input_pdf\n",
    "    folders = [os.path.join(input_pdf_folder, d) for d in os.listdir(input_pdf_folder) if os.path.isdir(os.path.join(input_pdf_folder, d))]\n",
    "    \n",
    "    new_tables_dict_1 = {}\n",
    "    \n",
    "    for folder in folders:\n",
    "        if folder_processed(folder):\n",
    "            print(f\"Folder {folder} has already been processed.\")\n",
    "            continue\n",
    "        \n",
    "        num_pdfs_processed, num_dataframes_generated, tables_dict_temp = process_folder(folder)\n",
    "        \n",
    "        new_tables_dict_1.update(tables_dict_temp)\n",
    "        \n",
    "        register_processed_folder(folder, num_pdfs_processed)\n",
    "\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)\n",
    "        message = f\"Process {folder} complete. Processed {num_pdfs_processed} PDF(s) and generated {num_dataframes_generated} DataFrame(s). Continue with next folder?\"\n",
    "        if not messagebox.askyesno(\"Continue?\", message):\n",
    "            break\n",
    "            \n",
    "    print(\"Processing completed for all folders.\")\n",
    "    \n",
    "    return new_tables_dict_1\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    new_tables_dict_1 = process_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421e85b1-3a1c-4d6a-8a64-48bff19e792c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import os\n",
    "\n",
    "# Path to the PDF\n",
    "pdf_path = r\"C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\RA\\CIUP\\GDP Revisions\\GitHub\\peru_gdp_revisions\\gdp_revisions_datasets\\digital_pdf\\raw_pdf\\ns-22-2019.pdf\"\n",
    "\n",
    "# Open PDF with pdfplumber\n",
    "with pdfplumber.open(pdf_path) as pdf:\n",
    "    first_page = pdf.pages[0]  # only first page\n",
    "\n",
    "    # Extract tables\n",
    "    tables = first_page.extract_tables()\n",
    "\n",
    "    # Inspect tables\n",
    "    if tables:\n",
    "        for i, table in enumerate(tables, 1):\n",
    "            print(f\"\\nTable {i}:\")\n",
    "            for row in table:\n",
    "                print(row)\n",
    "    else:\n",
    "        print(\"No tables found on the first page.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15f0a6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ns_04_2013_1', 'ns_08_2013_1', 'ns_12_2013_1', 'ns_16_2013_1', 'ns_21_2013_1', 'ns_25_2013_1', 'ns_29_2013_1', 'ns_33_2013_1', 'ns_37_2013_1', 'ns_42_2013_1', 'ns_46_2013_1', 'ns_50_2013_1', 'ns_04_2014_1', 'ns_08_2014_1', 'ns_12_2014_1', 'ns_15_2014_1', 'ns_20_2014_1', 'ns_24_2014_1', 'ns_28_2014_1', 'ns_32_2014_1', 'ns_36_2014_1', 'ns_41_2014_1', 'ns_45_2014_1', 'ns_49_2014_1', 'ns_04_2015_1', 'ns_08_2015_1', 'ns_12_2015_1', 'ns_16_2015_1', 'ns_21_2015_1', 'ns_24_2015_1', 'ns_28_2015_1', 'ns_32_2015_1', 'ns_36_2015_1', 'ns_40_2015_1', 'ns_45_2015_1', 'ns_48_2015_1', 'ns_04_2016_1', 'ns_08_2016_1', 'ns_11_2016_1', 'ns_16_2016_1', 'ns_20_2016_1', 'ns_24_2016_1', 'ns_28_2016_1', 'ns_32_2016_1', 'ns_37_2016_1', 'ns_41_2016_1', 'ns_44_2016_1', 'ns_48_2016_1', 'ns_04_2017_1', 'ns_07_2017_1', 'ns_13_2017_1', 'ns_16_2017_1', 'ns_20_2017_1', 'ns_25_2017_1', 'ns_28_2017_1', 'ns_33_2017_1', 'ns_37_2017_1', 'ns_41_2017_1', 'ns_46_2017_1', 'ns_49_2017_1', 'ns_03_2018_1', 'ns_07_2018_1', 'ns_11_2018_1', 'ns_15_2018_1', 'ns_20_2018_1', 'ns_24_2018_1', 'ns_28_2018_1', 'ns_33_2018_1', 'ns_37_2018_1', 'ns_42_2018_1', 'ns_46_2018_1', 'ns_49_2018_1', 'ns_04_2019_1', 'ns_07_2019_1', 'ns_10_2019_1', 'ns_13_2019_1', 'ns_17_2019_1', 'ns_20_2019_1', 'ns_22_2019_1', 'ns_26_2019_1', 'ns_29_2019_1', 'ns_33_2019_1', 'ns_36_2019_1', 'ns_39_2019_1', 'ns_03_2020_1', 'ns_07_2020_1', 'ns_11_2020_1', 'ns_16_2020_1', 'ns_20_2020_1', 'ns_24_2020_1', 'ns_28_2020_1', 'ns_32_2020_1', 'ns_36_2020_1', 'ns_39_2020_1', 'ns_43_2020_1', 'ns_47_2020_1'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tables_dict_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8329629e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ns_04_2013_1', 'ns_08_2013_1', 'ns_12_2013_1', 'ns_16_2013_1', 'ns_21_2013_1', 'ns_25_2013_1', 'ns_29_2013_1', 'ns_33_2013_1', 'ns_37_2013_1', 'ns_42_2013_1', 'ns_46_2013_1', 'ns_50_2013_1', 'ns_04_2014_1', 'ns_08_2014_1', 'ns_12_2014_1', 'ns_15_2014_1', 'ns_20_2014_1', 'ns_24_2014_1', 'ns_28_2014_1', 'ns_32_2014_1', 'ns_36_2014_1', 'ns_41_2014_1', 'ns_45_2014_1', 'ns_49_2014_1', 'ns_04_2015_1', 'ns_08_2015_1', 'ns_12_2015_1', 'ns_16_2015_1', 'ns_21_2015_1', 'ns_24_2015_1', 'ns_28_2015_1', 'ns_32_2015_1', 'ns_36_2015_1', 'ns_40_2015_1', 'ns_45_2015_1', 'ns_48_2015_1', 'ns_04_2016_1', 'ns_08_2016_1', 'ns_11_2016_1', 'ns_16_2016_1', 'ns_20_2016_1', 'ns_24_2016_1', 'ns_28_2016_1', 'ns_32_2016_1', 'ns_37_2016_1', 'ns_41_2016_1', 'ns_44_2016_1', 'ns_48_2016_1', 'ns_04_2017_1', 'ns_07_2017_1', 'ns_13_2017_1', 'ns_16_2017_1', 'ns_20_2017_1', 'ns_25_2017_1', 'ns_28_2017_1', 'ns_33_2017_1', 'ns_37_2017_1', 'ns_41_2017_1', 'ns_46_2017_1', 'ns_49_2017_1', 'ns_03_2018_1', 'ns_07_2018_1', 'ns_11_2018_1', 'ns_15_2018_1', 'ns_20_2018_1', 'ns_24_2018_1', 'ns_28_2018_1', 'ns_33_2018_1', 'ns_37_2018_1', 'ns_42_2018_1', 'ns_46_2018_1', 'ns_49_2018_1', 'ns_04_2019_1', 'ns_07_2019_1', 'ns_10_2019_1', 'ns_13_2019_1', 'ns_17_2019_1', 'ns_20_2019_1', 'ns_22_2019_1', 'ns_26_2019_1', 'ns_29_2019_1', 'ns_33_2019_1', 'ns_36_2019_1', 'ns_39_2019_1', 'ns_03_2020_1', 'ns_07_2020_1', 'ns_11_2020_1', 'ns_16_2020_1', 'ns_20_2020_1', 'ns_24_2020_1', 'ns_28_2020_1', 'ns_32_2020_1', 'ns_36_2020_1', 'ns_39_2020_1', 'ns_43_2020_1', 'ns_47_2020_1'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataframes_dict_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a6cc13c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>2018</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>2019</th>\n",
       "      <th>Unnamed: 12</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Unnamed: 15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SECTORES ECON√ìMICOS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ECONOMIC SECTORS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Abr.</td>\n",
       "      <td>May.</td>\n",
       "      <td>Jun.</td>\n",
       "      <td>Jul.</td>\n",
       "      <td>Ago. Sep.</td>\n",
       "      <td>Oct.</td>\n",
       "      <td>Nov.</td>\n",
       "      <td>Dic.</td>\n",
       "      <td>A√±o</td>\n",
       "      <td>Ene.</td>\n",
       "      <td>Feb.</td>\n",
       "      <td>Mar.</td>\n",
       "      <td>Abr.</td>\n",
       "      <td>Ene.-Abr.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Agropecuario 2/</td>\n",
       "      <td>11,9</td>\n",
       "      <td>16,2</td>\n",
       "      <td>4,6</td>\n",
       "      <td>4,6</td>\n",
       "      <td>8,3 7,3</td>\n",
       "      <td>8,2</td>\n",
       "      <td>5,9</td>\n",
       "      <td>3,1</td>\n",
       "      <td>7,8</td>\n",
       "      <td>4,5</td>\n",
       "      <td>4,9</td>\n",
       "      <td>5,3</td>\n",
       "      <td>3,0</td>\n",
       "      <td>4,3 Agriculture and Livestock 2/</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Agr√≠cola</td>\n",
       "      <td>14,7</td>\n",
       "      <td>19,0</td>\n",
       "      <td>3,3</td>\n",
       "      <td>5,1</td>\n",
       "      <td>10,5 9,5</td>\n",
       "      <td>10,2</td>\n",
       "      <td>6,4</td>\n",
       "      <td>1,0</td>\n",
       "      <td>9,4</td>\n",
       "      <td>4,2</td>\n",
       "      <td>5,2</td>\n",
       "      <td>5,9</td>\n",
       "      <td>2,4</td>\n",
       "      <td>4,2</td>\n",
       "      <td>Agriculture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pecuario</td>\n",
       "      <td>6,5</td>\n",
       "      <td>9,8</td>\n",
       "      <td>7,7</td>\n",
       "      <td>3,8</td>\n",
       "      <td>5,7 5,0</td>\n",
       "      <td>6,0</td>\n",
       "      <td>5,2</td>\n",
       "      <td>6,2</td>\n",
       "      <td>5,5</td>\n",
       "      <td>4,8</td>\n",
       "      <td>4,6</td>\n",
       "      <td>4,4</td>\n",
       "      <td>4,3</td>\n",
       "      <td>4,5</td>\n",
       "      <td>Livestock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0 Unnamed: 1 Unnamed: 2 Unnamed: 3 Unnamed: 4       2018  \\\n",
       "0  SECTORES ECON√ìMICOS        NaN        NaN        NaN        NaN        NaN   \n",
       "1                  NaN       Abr.       May.       Jun.       Jul.  Ago. Sep.   \n",
       "2      Agropecuario 2/       11,9       16,2        4,6        4,6    8,3 7,3   \n",
       "3             Agr√≠cola       14,7       19,0        3,3        5,1   10,5 9,5   \n",
       "4             Pecuario        6,5        9,8        7,7        3,8    5,7 5,0   \n",
       "\n",
       "  Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9 Unnamed: 10  2019 Unnamed: 12  \\\n",
       "0        NaN        NaN        NaN        NaN         NaN   NaN         NaN   \n",
       "1       Oct.       Nov.       Dic.        A√±o        Ene.  Feb.        Mar.   \n",
       "2        8,2        5,9        3,1        7,8         4,5   4,9         5,3   \n",
       "3       10,2        6,4        1,0        9,4         4,2   5,2         5,9   \n",
       "4        6,0        5,2        6,2        5,5         4,8   4,6         4,4   \n",
       "\n",
       "  Unnamed: 13                       Unnamed: 14       Unnamed: 15  \n",
       "0         NaN                               NaN  ECONOMIC SECTORS  \n",
       "1        Abr.                         Ene.-Abr.               NaN  \n",
       "2         3,0  4,3 Agriculture and Livestock 2/               NaN  \n",
       "3         2,4                               4,2       Agriculture  \n",
       "4         4,3                               4,5         Livestock  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_tables_dict_1['ns_22_2019_1'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "084ecc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id_ns</th>\n",
       "      <th>sectores_economicos</th>\n",
       "      <th>economic_sectors</th>\n",
       "      <th>2018_abr</th>\n",
       "      <th>2018_may</th>\n",
       "      <th>2018_jun</th>\n",
       "      <th>2018_jul</th>\n",
       "      <th>2018_ago</th>\n",
       "      <th>2018_sep</th>\n",
       "      <th>2018_oct</th>\n",
       "      <th>2018_nov</th>\n",
       "      <th>2018_dic</th>\n",
       "      <th>2018_year</th>\n",
       "      <th>2019_ene</th>\n",
       "      <th>2019_feb</th>\n",
       "      <th>2019_mar</th>\n",
       "      <th>2019_abr</th>\n",
       "      <th>2019_ene_abr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>agropecuario</td>\n",
       "      <td>agriculture and livestock</td>\n",
       "      <td>11.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>agricola</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>14.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>10.5</td>\n",
       "      <td>9.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>pecuario</td>\n",
       "      <td>livestock</td>\n",
       "      <td>6.5</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.5</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>pesca</td>\n",
       "      <td>fishing</td>\n",
       "      <td>81.2</td>\n",
       "      <td>26.7</td>\n",
       "      <td>-7.9</td>\n",
       "      <td>-17.3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>22.7</td>\n",
       "      <td>188.5</td>\n",
       "      <td>225.9</td>\n",
       "      <td>39.7</td>\n",
       "      <td>-31.3</td>\n",
       "      <td>-9.5</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-63.0</td>\n",
       "      <td>-37.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>mineria e hidrocarburos</td>\n",
       "      <td>mining and fuel</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>-1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>mineria metalica</td>\n",
       "      <td>metals</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-5.9</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-2.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>hidrocarburos</td>\n",
       "      <td>fuel</td>\n",
       "      <td>10.9</td>\n",
       "      <td>12.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-26.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>40.0</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>manufactura</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>21.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>9.8</td>\n",
       "      <td>12.1</td>\n",
       "      <td>12.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-13.2</td>\n",
       "      <td>-4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>procesadores recursos primarios</td>\n",
       "      <td>based on raw materials</td>\n",
       "      <td>42.8</td>\n",
       "      <td>23.5</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>-6.5</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>41.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>-28.3</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>3.1</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>-19.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>manufactura no primaria</td>\n",
       "      <td>nonprimary</td>\n",
       "      <td>12.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>electricidad y agua</td>\n",
       "      <td>electricity and water</td>\n",
       "      <td>6.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.3</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>construccion</td>\n",
       "      <td>construction</td>\n",
       "      <td>10.1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>5.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>11.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.4</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>8.7</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>comercio</td>\n",
       "      <td>commerce</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>otros servicios</td>\n",
       "      <td>other services</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>derechos de importacion y otros impuestos</td>\n",
       "      <td>import duties and other taxes</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>pbi</td>\n",
       "      <td>gdp</td>\n",
       "      <td>7.8</td>\n",
       "      <td>6.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>sectores primarios</td>\n",
       "      <td>primary sectors</td>\n",
       "      <td>10.9</td>\n",
       "      <td>9.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>-3.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>sectores no primarios</td>\n",
       "      <td>non primary sectors</td>\n",
       "      <td>6.9</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.4</td>\n",
       "      <td>4.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>pbi desestacionalizado</td>\n",
       "      <td>seasonally adjusted gdp</td>\n",
       "      <td>6.5</td>\n",
       "      <td>7.9</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-2.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>indicadores de demanda</td>\n",
       "      <td>domestic demand indicators</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>demanda interna sin inventarios</td>\n",
       "      <td>domestic demand without inventories</td>\n",
       "      <td>7.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.9</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019</td>\n",
       "      <td>22</td>\n",
       "      <td>demanda interna</td>\n",
       "      <td>domestic demand</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year id_ns                        sectores_economicos  \\\n",
       "1   2019    22                               agropecuario   \n",
       "2   2019    22                                   agricola   \n",
       "3   2019    22                                   pecuario   \n",
       "4   2019    22                                      pesca   \n",
       "5   2019    22                    mineria e hidrocarburos   \n",
       "6   2019    22                           mineria metalica   \n",
       "7   2019    22                              hidrocarburos   \n",
       "8   2019    22                                manufactura   \n",
       "9   2019    22            procesadores recursos primarios   \n",
       "10  2019    22                    manufactura no primaria   \n",
       "11  2019    22                        electricidad y agua   \n",
       "12  2019    22                               construccion   \n",
       "13  2019    22                                   comercio   \n",
       "14  2019    22                            otros servicios   \n",
       "15  2019    22  derechos de importacion y otros impuestos   \n",
       "16  2019    22                                        pbi   \n",
       "17  2019    22                         sectores primarios   \n",
       "18  2019    22                      sectores no primarios   \n",
       "19  2019    22                     pbi desestacionalizado   \n",
       "20  2019    22                     indicadores de demanda   \n",
       "21  2019    22            demanda interna sin inventarios   \n",
       "22  2019    22                            demanda interna   \n",
       "\n",
       "                       economic_sectors  2018_abr  2018_may  2018_jun  \\\n",
       "1             agriculture and livestock      11.9      16.2       4.6   \n",
       "2                           agriculture      14.7      19.0       3.3   \n",
       "3                             livestock       6.5       9.8       7.7   \n",
       "4                               fishing      81.2      26.7      -7.9   \n",
       "5                       mining and fuel       1.0       2.1      -4.6   \n",
       "6                                metals      -0.6       0.4      -5.7   \n",
       "7                                  fuel      10.9      12.5       2.6   \n",
       "8                         manufacturing      21.0      10.6       1.6   \n",
       "9                based on raw materials      42.8      23.5      -0.4   \n",
       "10                           nonprimary      12.8       4.8       2.4   \n",
       "11                electricity and water       6.5       4.4       4.2   \n",
       "12                         construction      10.1      10.0       2.4   \n",
       "13                             commerce       4.9       3.3       1.6   \n",
       "14                       other services       5.2       5.2       4.3   \n",
       "15        import duties and other taxes       8.2       8.0       1.4   \n",
       "16                                  gdp       7.8       6.6       2.0   \n",
       "17                      primary sectors      10.9       9.7      -1.6   \n",
       "18                  non primary sectors       6.9       5.6       3.2   \n",
       "19              seasonally adjusted gdp       6.5       7.9       7.4   \n",
       "20           domestic demand indicators       NaN       NaN       NaN   \n",
       "21  domestic demand without inventories       7.4       5.0       4.4   \n",
       "22                      domestic demand       8.8       7.4       2.1   \n",
       "\n",
       "    2018_jul  2018_ago  2018_sep  2018_oct  2018_nov  2018_dic  2018_year  \\\n",
       "1        4.6       8.3       7.3       8.2       5.9       3.1        7.8   \n",
       "2        5.1      10.5       9.5      10.2       6.4       1.0        9.4   \n",
       "3        3.8       5.7       5.0       6.0       5.2       6.2        5.5   \n",
       "4      -17.3      26.0      19.7      22.7     188.5     225.9       39.7   \n",
       "5       -5.2      -3.9       0.8      -2.4      -2.5      -1.2       -1.3   \n",
       "6       -5.7       0.1      -1.4      -3.1      -3.7      -1.7       -1.5   \n",
       "7       -2.2     -26.3      15.5       2.2       4.8       1.4        0.0   \n",
       "8        2.1       2.1       1.1       9.8      12.1      12.4        6.2   \n",
       "9       -6.5      -0.8       3.3       8.9      41.0      47.0       13.2   \n",
       "10       5.0       3.0       0.5      10.0       3.4       1.7        3.7   \n",
       "11       4.6       3.3       3.8       5.1       6.5       7.5        4.4   \n",
       "12       5.3       0.3      -1.9       9.0      11.8       4.6        5.4   \n",
       "13       2.7       2.5       1.4       2.6       2.4       2.5        2.6   \n",
       "14       4.4       4.5       3.9       4.3       4.8       4.3        4.5   \n",
       "15       4.4       0.4      -0.4       6.7       2.4       3.4        3.8   \n",
       "16       2.6       2.4       2.3       4.6       5.2       4.7        4.0   \n",
       "17      -3.0      -0.7       2.6       1.5       6.6       7.4        3.3   \n",
       "18       4.2       3.2       2.2       5.4       4.8       4.0        4.2   \n",
       "19       2.6      -3.3      -2.5       2.4       7.3       7.5        NaN   \n",
       "20       NaN       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "21       3.3       2.3       0.7       4.3       4.9       2.8        3.9   \n",
       "22       1.6       3.6       4.2       4.7       2.3       3.9        4.3   \n",
       "\n",
       "    2019_ene  2019_feb  2019_mar  2019_abr  2019_ene_abr  \n",
       "1        4.5       4.9       5.3       3.0           4.3  \n",
       "2        4.2       5.2       5.9       2.4           4.2  \n",
       "3        4.8       4.6       4.4       4.3           4.5  \n",
       "4      -31.3      -9.5      -7.4     -63.0         -37.3  \n",
       "5       -1.3      -0.7       0.1      -2.9          -1.2  \n",
       "6       -1.4      -5.9       0.3      -1.7          -2.1  \n",
       "7       -0.7      40.0      -0.4      -9.0           4.5  \n",
       "8       -5.4      -1.3       3.7     -13.2          -4.4  \n",
       "9      -28.3     -10.2       3.1     -34.0         -19.9  \n",
       "10       4.1       1.3       3.9      -3.3           1.5  \n",
       "11       5.3       5.9       6.7       3.8           5.4  \n",
       "12      -1.1       0.5       5.8       8.7           3.6  \n",
       "13       2.5       1.8       3.0       3.0           2.6  \n",
       "14       3.9       4.1       3.9       3.8           3.9  \n",
       "15       5.7       0.1       0.8       1.1           1.9  \n",
       "16       1.6       2.0       3.2       0.0           1.7  \n",
       "17      -5.0      -0.6       1.7      -8.3          -3.3  \n",
       "18       3.5       2.7       3.6       2.7           3.1  \n",
       "19       3.8      -0.3      -2.0      -1.5           NaN  \n",
       "20       NaN       NaN       NaN       NaN           NaN  \n",
       "21       2.1       1.6       2.9       2.5           2.3  \n",
       "22       0.9       1.1       2.6      -0.3           1.0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = new_dataframes_dict_1['ns_22_2019_1']\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee02360",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[(df_1['sectores_economicos'] == 'agropecuario') | (df_1['economic_sectors'] == 'agriculture and livestock')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c0eb2f",
   "metadata": {},
   "source": [
    "<div id=\"3-2-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3f814",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.2.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 2.</span> Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419acde4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The basic criterion to start extracting tables is to use keywords (sufficient condition). I mean, tables containing the following keywords meet the requirements to be extracted.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b455f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords to search in the page text\n",
    "keywords = [\"ECONOMIC SECTORS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86af3dc",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <code>ns_dates</code> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c328b004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9. DataFrame generated for file input_pdf\\2024\\ns-09-2024.pdf: ns_09_2024_2\n",
      "  10. DataFrame generated for file input_pdf\\2024\\ns-10-2024.pdf: ns_10_2024_2\n",
      "  11. DataFrame generated for file input_pdf\\2024\\ns-11-2024.pdf: ns_11_2024_2\n",
      "  12. DataFrame generated for file input_pdf\\2024\\ns-12-2024.pdf: ns_12_2024_2\n",
      "  13. DataFrame generated for file input_pdf\\2024\\ns-13-2024.pdf: ns_13_2024_2\n",
      "  14. DataFrame generated for file input_pdf\\2024\\ns-14-2024.pdf: ns_14_2024_2\n",
      "  15. DataFrame generated for file input_pdf\\2024\\ns-15-2024.pdf: ns_15_2024_2\n",
      "  16. DataFrame generated for file input_pdf\\2024\\ns-16-2024.pdf: ns_16_2024_2\n",
      "  17. DataFrame generated for file input_pdf\\2024\\ns-17-2024.pdf: ns_17_2024_2\n",
      "  18. DataFrame generated for file input_pdf\\2024\\ns-18-2024.pdf: ns_18_2024_2\n",
      "  19. DataFrame generated for file input_pdf\\2024\\ns-19-2024.pdf: ns_19_2024_2\n",
      "  20. DataFrame generated for file input_pdf\\2024\\ns-20-2024.pdf: ns_20_2024_2\n",
      "  21. DataFrame generated for file input_pdf\\2024\\ns-21-2024.pdf: ns_21_2024_2\n",
      "  22. DataFrame generated for file input_pdf\\2024\\ns-22-2024.pdf: ns_22_2024_2\n",
      "  23. DataFrame generated for file input_pdf\\2024\\ns-23-2024.pdf: ns_23_2024_2\n",
      "  24. DataFrame generated for file input_pdf\\2024\\ns-24-2024.pdf: ns_24_2024_2\n",
      "  25. DataFrame generated for file input_pdf\\2024\\ns-25-2024.pdf: ns_25_2024_2\n",
      "  26. DataFrame generated for file input_pdf\\2024\\ns-26-2024.pdf: ns_26_2024_2\n",
      "  27. DataFrame generated for file input_pdf\\2024\\ns-27-2024.pdf: ns_27_2024_2\n",
      "  28. DataFrame generated for file input_pdf\\2024\\ns-28-2024.pdf: ns_28_2024_2\n",
      "  29. DataFrame generated for file input_pdf\\2024\\ns-29-2024.pdf: ns_29_2024_2\n",
      "  30. DataFrame generated for file input_pdf\\2024\\ns-30-2024.pdf: ns_30_2024_2\n",
      "  31. DataFrame generated for file input_pdf\\2024\\ns-31-2024.pdf: ns_31_2024_2\n",
      "  32. DataFrame generated for file input_pdf\\2024\\ns-32-2024.pdf: ns_32_2024_2\n",
      "  33. DataFrame generated for file input_pdf\\2024\\ns-33-2024.pdf: ns_33_2024_2\n",
      "  34. DataFrame generated for file input_pdf\\2024\\ns-34-2024.pdf: ns_34_2024_2\n",
      "  35. DataFrame generated for file input_pdf\\2024\\ns-35-2024.pdf: ns_35_2024_2\n",
      "  36. DataFrame generated for file input_pdf\\2024\\ns-36-2024.pdf: ns_36_2024_2\n",
      "  37. DataFrame generated for file input_pdf\\2024\\ns-37-2024.pdf: ns_37_2024_2\n",
      "  38. DataFrame generated for file input_pdf\\2024\\ns-38-2024.pdf: ns_38_2024_2\n",
      "  39. DataFrame generated for file input_pdf\\2024\\ns-39-2024.pdf: ns_39_2024_2\n",
      "  40. DataFrame generated for file input_pdf\\2024\\ns-40-2024.pdf: ns_40_2024_2\n",
      "  41. DataFrame generated for file input_pdf\\2024\\ns-41-2024.pdf: ns_41_2024_2\n",
      "  42. DataFrame generated for file input_pdf\\2024\\ns-42-2024.pdf: ns_42_2024_2\n",
      "  43. DataFrame generated for file input_pdf\\2024\\ns-43-2024.pdf: ns_43_2024_2\n",
      "Processing completed for all folders.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import locale\n",
    "import pdfplumber\n",
    "import tabula\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tkinter import Tk, messagebox\n",
    "\n",
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Dictionary to store generated DataFrames\n",
    "new_dataframes_dict_2 = {}\n",
    "\n",
    "# Path for the processed folders log file\n",
    "record_path = 'record/new_generated_dataframes_2.txt'\n",
    "\n",
    "# Function to correct month names\n",
    "def correct_month_name(month):\n",
    "    months_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Add more mappings as needed\n",
    "    }\n",
    "    return months_mapping.get(month, month)\n",
    "\n",
    "# Function to register processed folder\n",
    "def register_processed_folder(folder, num_processed_files):\n",
    "    with open(record_path, 'a') as file:\n",
    "        file.write(f\"{folder}:{num_processed_files}\\n\")\n",
    "        \n",
    "# Function to check if folder has been processed\n",
    "def folder_processed(folder):\n",
    "    if not os.path.exists(record_path):\n",
    "        return False\n",
    "    with open(record_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(folder):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to process PDF file (extract table from second page)\n",
    "def process_pdf(pdf_path):\n",
    "    new_tables_dict_2 = {}  # Local dictionary for each PDF\n",
    "    table_counter = 1\n",
    "\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None\n",
    "\n",
    "    new_filename = os.path.splitext(filename)[0].replace('-', '_')\n",
    "\n",
    "    # Extract table from second page only\n",
    "    tables = tabula.read_pdf(pdf_path, pages=2, multiple_tables=False, stream=True)\n",
    "    for j, table_df in enumerate(tables, start=1):\n",
    "        dataframe_name = f\"{new_filename}_2\"\n",
    "        new_tables_dict_2[dataframe_name] = table_df\n",
    "        table_counter += 1\n",
    "\n",
    "    return id_ns, year, new_tables_dict_2, 2  # keyword_count replaced by 2\n",
    "\n",
    "# Function to process folder\n",
    "def process_folder(folder):\n",
    "    print(f\"Processing folder {os.path.basename(folder)}\")\n",
    "    pdf_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.pdf')]\n",
    "\n",
    "    num_pdfs_processed = 0\n",
    "    num_dataframes_generated = 0\n",
    "    table_counter = 1\n",
    "    new_tables_dict_2 = {}  # Declare tables_dict outside main loop\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        id_ns, year, tables_dict_temp, _ = process_pdf(pdf_file)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for dataframe_name, df in tables_dict_temp.items():\n",
    "                file_name = os.path.splitext(os.path.basename(pdf_file))[0].replace('-', '_')\n",
    "                dataframe_name = f\"{file_name}_2\"\n",
    "\n",
    "                # Store raw DataFrame\n",
    "                new_tables_dict_2[dataframe_name] = df.copy()\n",
    "\n",
    "                # Apply cleaning pipeline\n",
    "                df_clean = df.copy()\n",
    "                if df_clean.iloc[0, 0] is np.nan:\n",
    "                    # 20 lines of cleaning\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = separate_years(df_clean)\n",
    "                    df_clean = relocate_roman_numerals(df_clean)\n",
    "                    df_clean = extract_mixed_values(df_clean)\n",
    "                    df_clean = replace_first_row_nan(df_clean)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = swap_first_second_row(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = drop_nan_row(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = split_values(df_clean)\n",
    "                    df_clean = separate_text_digits(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                else:\n",
    "                    # 15 lines of cleaning\n",
    "                    df_clean = exchange_roman_nan(df_clean)\n",
    "                    df_clean = exchange_columns(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = remove_digit_slash(df_clean)\n",
    "                    df_clean = last_column_es(df_clean)\n",
    "                    df_clean = swap_first_second_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = separate_text_digits(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "                # Add 'year' and 'id_ns' columns\n",
    "                df_clean.insert(0, 'year', year)\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "\n",
    "                # Store cleaned DataFrame\n",
    "                new_dataframes_dict_2[dataframe_name] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. DataFrame generated for file {pdf_file}: {dataframe_name}')\n",
    "                num_dataframes_generated += 1\n",
    "                table_counter += 1\n",
    "                    \n",
    "        num_pdfs_processed += 1\n",
    "\n",
    "    return num_pdfs_processed, num_dataframes_generated, new_tables_dict_2\n",
    "        \n",
    "# Function to process folders\n",
    "def process_folders():\n",
    "    input_pdf_folder = input_pdf\n",
    "    folders = [os.path.join(input_pdf_folder, d) for d in os.listdir(input_pdf_folder) if os.path.isdir(os.path.join(input_pdf_folder, d))]\n",
    "\n",
    "    new_tables_dict_2 = {}\n",
    "    \n",
    "    for folder in folders:\n",
    "        if folder_processed(folder):\n",
    "            print(f\"Folder {folder} has already been processed.\")\n",
    "            continue\n",
    "        \n",
    "        num_pdfs_processed, num_dataframes_generated, tables_dict_temp = process_folder(folder)\n",
    "        \n",
    "        new_tables_dict_2.update(tables_dict_temp)\n",
    "        \n",
    "        register_processed_folder(folder, num_pdfs_processed)\n",
    "        \n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)\n",
    "        message = f\"Process {folder} complete. Processed {num_pdfs_processed} PDF(s) and generated {num_dataframes_generated} DataFrame(s). Continue with next folder?\"\n",
    "        if not messagebox.askyesno(\"Continue?\", message):\n",
    "            break\n",
    "            \n",
    "    print(\"Processing completed for all folders.\")\n",
    "\n",
    "    return new_tables_dict_2\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    new_tables_dict_2 = process_folders()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77706358",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f272f429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_tables_dict_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a46bbe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_dataframes_dict_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tables_dict_2['ns_43_2024_2'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dataframes_dict_2['ns_43_2024_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667d97b8",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217183e7",
   "metadata": {},
   "source": [
    "<div id=\"4\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8989d65",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Real-time data of Peru's GDP growth rates</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a04abd",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "This section creates the GDP growth rate vintages for Peru using <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a> and <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a>, which were extracted and cleaned in the previous section. Each table from each WR (PDF <span style=\"font-size: 24px;\">&#128462;</span>) was extracted and cleaned individually in the previous section. Here, we will concatenate all the tables for a specific economic sector, thus creating a vintage dataset of (real) GDP growth by economic sector from <b>2013</b> to <b>2024</b>.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2971c7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    <span style=\"font-size: 24px; color: #FFA823; font-weight: bold;\">&#9888;</span>\n",
    "As preferred or as appropriate, you can create the data manually, step by step, or focus on specific sectors or frequencies. Alternatively, you can choose a more efficient or automated approach by generating the data for all sectors and frequencies simultaneously.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aed3953",
   "metadata": {},
   "source": [
    "<div id=\"4-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ee7f3",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Manual process of data creation in real time: sector by sector and frequency by frequency.\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ef0a33",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    With this method you can create and inspect the dataset sector by sector and frequency by frequency. This is useful if you want to create data only for particular sectors and frequencies.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb9ebdf",
   "metadata": {},
   "source": [
    "<div id=\"select_sector\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ec604",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Select <code>sector_economico</code> and <code>economic_sector</code></span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb3ca8",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "When executing the following code, a window will be displayed with options in <b>Spanish</b> and <b>English</b> to select <b>economic sectors</b>. Choose them to concatenate Peru GDP growth rates (annual, quarterly or monthly) by sector.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09df1d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to display the window and capture the selected values\n",
    "selected_spanish, selected_english, sector = show_option_window()\n",
    "\n",
    "# Display the selected values\n",
    "print(f\"You have selected sector = {sector}, selected_spanish = {selected_spanish}, and selected_english = {selected_english}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d69443",
   "metadata": {},
   "source": [
    "<div id=\"select_freq\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33746e78",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Select <code>frequency</code></span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6652f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to show the popup window\n",
    "frequency = show_frequency_window()\n",
    "print(\"Selected frequency:\", frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba4800d",
   "metadata": {},
   "source": [
    "<div id=\"counter\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f78b39d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Set counter (dataframe name suffix)</span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be4b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to set the counter\n",
    "if frequency == \"monthly\":\n",
    "    counter = 1\n",
    "elif frequency == \"quarterly\":\n",
    "    counter = 2\n",
    "elif frequency == \"annual\":\n",
    "    counter = 2\n",
    "else:\n",
    "    counter = None \n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e6ca98",
   "metadata": {},
   "source": [
    "<div id=\"4-1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2b142e",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.1.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Growth rates datasets concatenation for all frequencies\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ac89a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically construct the function name and dictionary name\n",
    "function_name = f\"concatenate_{frequency}_df\"\n",
    "dataframe_dict_name = f\"new_dataframes_dict_{counter}\"\n",
    "\n",
    "# Check that both the function and dictionary exist in the global scope\n",
    "if function_name in globals() and dataframe_dict_name in globals():\n",
    "    # Call the function using its reference from globals()\n",
    "    globals()[f\"new_{sector}_{frequency}_growth_rates\"] = globals()[function_name](\n",
    "        globals()[dataframe_dict_name], selected_spanish, selected_english\n",
    "    )\n",
    "else:\n",
    "    print(f\"Error: {function_name} or {dataframe_dict_name} does not exist in the global scope.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2fcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "globals()[f\"new_{sector}_{frequency}_growth_rates\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4f057",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f60c74",
   "metadata": {},
   "source": [
    "<div id=\"4-1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2418a10",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.1.2.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Uploading data to SQL</span></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c80fc4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Finally, we upload all the datasets generated in this jupyter notebook to the <code>'gdp_revisions_datasets'</code> database of <code>PostgresSQL</code>.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e1970c",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_sqlalchemy_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be882f24",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Loading\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623149b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"new_{sector}_{frequency}_growth_rates\"].to_sql(f'new_{sector}_{frequency}_growth_rates', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60157eab",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 20px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#select_sector\" style=\"color: rgb(255, 32, 78); text-decoration: none;\">‚Æù</a>\n",
    "    </span> \n",
    "    <a href=\"#select_sector\" style=\"color: rgb(255, 32, 78); text-decoration: none;\">Back to select sectors.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6d115",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 20px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#select_freq\" style=\"color: rgb(255, 32, 78); text-decoration: none;\">‚Æù</a>\n",
    "    </span> \n",
    "    <a href=\"#select_freq\" style=\"color: rgb(255, 32, 78); text-decoration: none;\">Back to select frequency.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a58528",
   "metadata": {},
   "source": [
    "<div id=\"4-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cac195",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Automatic data creation process in real time: all sectors and frequencies at the same time.\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d138910",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    With this method you can create the dataset for all sectors and all frequencies at the same time. This is more efficient if the goal is to generate all possible combinations of datasets for <code>sector</code> and <code>frequency</code> (without excluding any sector or frequency).\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b2bfe",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    List of frequencies to be used to create concatenated datasets\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c56b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = [\n",
    "        \"monthly\", \n",
    "        \"quarterly\",\n",
    "        \"annual\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dbac57",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    Function to process growth rates datasets: concatenate and load to SQL\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d9e3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_new_datasets_to_sql(sector, frequency):\n",
    "    # Initialize counter for loaded DataFrames\n",
    "    total_loaded = 0\n",
    "\n",
    "    # Set counter based on frequency\n",
    "    if frequency == \"monthly\":\n",
    "        counter = 1\n",
    "    elif frequency in [\"quarterly\", \"annual\"]:\n",
    "        counter = 2\n",
    "    else:\n",
    "        print(f\"Unknown frequency: {frequency}\")\n",
    "        return None\n",
    "\n",
    "    # Dynamically build function and dictionary names\n",
    "    function_name = f\"concatenate_{frequency}_df\"\n",
    "    dataframe_dict_name = f\"new_dataframes_dict_{counter}\"\n",
    "\n",
    "    if function_name in globals() and dataframe_dict_name in globals():\n",
    "        # Generate the DataFrame\n",
    "        df_name = f\"new_{sector}_{frequency}_growth_rates\"\n",
    "        globals()[df_name] = globals()[function_name](\n",
    "            globals()[dataframe_dict_name], option_mapping[sector][0], option_mapping[sector][1]\n",
    "        )\n",
    "\n",
    "        # Load to SQL\n",
    "        engine = create_sqlalchemy_engine()\n",
    "        globals()[df_name].to_sql(df_name, engine, index=False, if_exists='replace')\n",
    "\n",
    "        return globals()[df_name]\n",
    "    else:\n",
    "        print(f\"Error: {function_name} or {dataframe_dict_name} does not exist in the global scope.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20687226",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    Run the function to create concatenated datasets for all sectors and frequencies and load to SQL\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0581a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize counter\n",
    "processed_datasets = 0\n",
    "\n",
    "# Process all combinations\n",
    "for sector in option_mapping.keys():\n",
    "    for frequency in frequencies:\n",
    "        print(f\"Processing {sector} - {frequency}\")\n",
    "        df = process_new_datasets_to_sql(sector, frequency)\n",
    "        if df is not None:\n",
    "            display(df.head(10))  # Display the first 10 rows\n",
    "            processed_datasets += 1  # Increment counter\n",
    "\n",
    "# Display total number of processed datasets\n",
    "print(f\"Total datasets processed: {processed_datasets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd18b4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b448c020",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 16px; background-color: #F5F5F5; padding: 18px; line-height: 1.5; font-family: 'PT Serif Pro Book';\">\n",
    "    <span style=\"font-size: 24px; color: #FFA823; font-weight: bold;\">&#9888;</span>\n",
    "    Once you have all the datasets generated by this script (<code>new_gdp_datasets.ipynb</code>) you can concatenate with those generated in the script <code>old_gdp_datasets.ipynb</code>. <b>Section 6</b> of the script <code>aux_files_to_sql.ipynb</code> concatenates both <b>new</b> and <b>old</b> datasets for <b>all sectors</b> and <b>all frequencies</b>.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc920fd",
   "metadata": {},
   "source": [
    "---\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3eae11d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb22e11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
