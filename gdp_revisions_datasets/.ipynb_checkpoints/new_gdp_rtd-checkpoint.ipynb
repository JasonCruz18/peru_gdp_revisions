{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127505dd-d5cc-4829-9190-6314ae54b3ca",
   "metadata": {},
   "source": [
    "# New GDP Real-Time Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96357866-58f8-4d8b-b25a-b9b145465322",
   "metadata": {},
   "source": [
    "**Author:** Jason Cruz  \n",
    "**Last updated:** 08/13/2025  \n",
    "**Python version:** 3.12  \n",
    "**Project:** Rationality and Nowcasting on Peruvian GDP Revisions  \n",
    "\n",
    "---\n",
    "## üìå Summary\n",
    "This notebook documents the step-by-step **construction of real-time datasets** for **Peruvian GDP revisions** since 2013‚ÄìPRESENT. It covers:\n",
    "\n",
    "1. **Downloading PDFs** (actually Weekly Reports (WR)) from the Central Reserve Bank of Peru's website.\n",
    "2. **Generating PDF inputs** by shorten them in order to keep key pages containing required tables where GDP growth rates are in.\n",
    "3. **Cleaning-up data** extracted from input PDFs.\n",
    "4. **Concatenating real-time datasets across years by frequency** \n",
    "5. **Storing RTD to SQL** for availability to users upon request and further analysis.\n",
    "\n",
    "üåê **Main Data Source:** [BCRP Weekly Report](https://www.bcrp.gob.pe/publicaciones/nota-semanal.html) (üì∞ WR, from here on)  \n",
    "Any questions or issues regarding the coding, please email [Jason üì®](mailto:jj.cruza@up.edu.pe)  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907046a",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac40ed0",
   "metadata": {},
   "source": [
    "If you don't have the libraries below, please use the following code (as example) to install the required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c73193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d47b8-5873-426b-b739-e1fc05dcf8e5",
   "metadata": {},
   "source": [
    "Check out Python information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55588d8e-8df5-406a-8644-e67ff1dcbc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üêç Python Information\n",
      "  Version  : 3.12.1\n",
      "  Compiler : MSC v.1916 64 bit (AMD64)\n",
      "  Build    : ('main', 'Jan 19 2024 15:44:08')\n",
      "  OS       : Windows 10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"üêç Python Information\")\n",
    "print(f\"  Version  : {sys.version.split()[0]}\")\n",
    "print(f\"  Compiler : {platform.python_compiler()}\")\n",
    "print(f\"  Build    : {platform.python_build()}\")\n",
    "print(f\"  OS       : {platform.system()} {platform.release()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b819ed7-9661-4efd-972e-b38e78f48ae3",
   "metadata": {},
   "source": [
    "**Import helper functions**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403a836f",
   "metadata": {},
   "source": [
    "> ‚ö†Ô∏è Please, check the script `new_gdp_datasets_functions.py` which contains all the functions required by this _jupyter notebook_. The functions there are ordered according to the sections of this jupyter notebok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b7cb8e-8405-457d-a329-2a6cefa17844",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdp_rtd_pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ef8f8",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e5afa5-c77a-4bd4-a0f4-509e2095728d",
   "metadata": {},
   "source": [
    "Before preprocessing new GDP releases data, we will:\n",
    "\n",
    "* **Create necessary folders** for storing inputs, outputs, logs, and screenshots.\n",
    "* **Connect to the PostgreSQL database** containing GDP revisions datasets.\n",
    "* **Import helper functions** from `new_gdp_datasets_functions.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97cc1c80",
   "metadata": {},
   "source": [
    "**Create necessary folders**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc6db37-7963-4c46-95f7-404ee54664c3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51762441-7a80-4c30-ac06-0be260372738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter relative path (default='.'):  .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Using path: C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\RA\\CIUP\\GDP Revisions\\GitHub\\peru_gdp_revisions\\gdp_revisions_datasets\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd()\n",
    "user_input = input(\"Enter relative path (default='.'): \").strip() or \".\"\n",
    "target_path = (PROJECT_ROOT / user_input).resolve()\n",
    "target_path.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"üìÇ Using path: {target_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c21c6c2-92fe-453f-9a19-71aee798b2b8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "622f3192",
   "metadata": {},
   "source": [
    "## 1. Downloading PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98250a64",
   "metadata": {},
   "source": [
    "Our main source for data collection is the [BCRP Weekly Report](https://www.bcrp.gob.pe/publicaciones/nota-semanal.html). The weekly report is a periodic (weekly) publication of the BCRP in compliance with article 84 of the Peruvian Constitution and articles 2 and 74 of the BCRP's organic law, which include, among its functions, the periodic publication of the main national macroeconomic statistics.\n",
    "    \n",
    "Our project requires the publication of **two tables**: the table of monthly growth rates of real GDP (12-month percentage changes), and the table of quarterly (annual) growth rates of real GDP. These tables are referred to as **Table 1** and **Table 2**, respectively, throughout this jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d95c04",
   "metadata": {},
   "source": [
    "### Scraper bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcc4e3",
   "metadata": {},
   "source": [
    "This section automates the download of the **BCRP Weekly Report PDFs** directly from the official BCRP website.\n",
    "\n",
    "**What it does:**\n",
    "1. Opens the official BCRP Weekly Report page.\n",
    "2. Finds and collects all PDF links.\n",
    "3. Downloads them in chronological order (oldest to newest).\n",
    "4. Optionally plays a notification sound every N downloads.\n",
    "5. Organizes downloaded PDFs into year-based folders.\n",
    "\n",
    "> üí° If a CAPTCHA appears, solve it manually in the browser window and re-run the cell.\n",
    "\n",
    "> üîÅ This script uses webdriver-manager to automatically handle browser drivers (default: Chrome), so you DO NOT need to manually download ChromeDriver, GeckoDriver, etc. If you want to change browser for your replication, modify the 'browser' parameter in init_driver().\n",
    "\n",
    "> üéµ Place your own MP3 file in `alert_track` folder for download notifications. Recommended free sources (CC0/public domain):\n",
    ">  - Pixabay Audio: https://pixabay.com/music/\n",
    ">  - FreeSound: https://freesound.org/\n",
    ">  - FreePD: https://freepd.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb4b638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ pdf created\n",
      "üìÇ pdf\\raw created\n",
      "üìÇ pdf\\input created\n",
      "üìÇ record created\n",
      "üìÇ alert_track created\n"
     ]
    }
   ],
   "source": [
    "# Define base folder for saving all digital PDFs\n",
    "pdf_folder = 'pdf'\n",
    "\n",
    "# Define subfolder for saving the original PDFs as downloaded from the BCRP website\n",
    "raw_pdf_subfolder = os.path.join(pdf_folder, 'raw')\n",
    "\n",
    "# Define subfolder for saving reduced PDFs containing only selected pages with GDP growth tables (monthly, quarterly, and annual frequencies)\n",
    "input_pdf_subfolder = os.path.join(pdf_folder, 'input')\n",
    "\n",
    "# Define folder for saving .txt files with download and dataframe record\n",
    "record_folder = 'record'\n",
    "\n",
    "# Define folder for saving warning bells. This is for download notifications (see section 1).\n",
    "alert_track_folder = 'alert_track'\n",
    "\n",
    "# Create all required folders (if they do not already exist) and confirm creation\n",
    "for folder in [pdf_folder, raw_pdf_subfolder, input_pdf_subfolder, record_folder, alert_track_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"üìÇ {folder} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ee0199bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Starting PDF downloader for BCRP WR...\n",
      "\n",
      "üåê BCRP site opened successfully.\n",
      "üîé Found 154 WR blocks on page (one per month).\n",
      "\n",
      "1. ‚úîÔ∏è Downloaded: ns-31-2024.pdf\n",
      "‚è≥ Waiting 6.73 seconds...\n",
      "2. ‚úîÔ∏è Downloaded: ns-35-2024.pdf\n",
      "‚è≥ Waiting 9.39 seconds...\n",
      "3. ‚úîÔ∏è Downloaded: ns-39-2024.pdf\n",
      "‚è≥ Waiting 5.95 seconds...\n",
      "4. ‚úîÔ∏è Downloaded: ns-43-2024.pdf\n",
      "‚è≥ Waiting 9.00 seconds...\n",
      "\n",
      "üëã Browser closed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Run the function to start the scraper bot\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mpdf_downloader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbcrp_url\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://www.bcrp.gob.pe/publicaciones/nota-semanal.html\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mraw_pdf_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw_pdf_subfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_record_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecord_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownload_record_txt\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1_downloaded_pdfs.txt\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43malert_track_folder\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43malert_track_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_downloads\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdownloads_per_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheadless\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documentos\\RA\\CIUP\\GDP Revisions\\GitHub\\peru_gdp_revisions\\gdp_revisions_datasets\\gdp_rtd_pipeline.py:456\u001b[39m, in \u001b[36mpdf_downloader\u001b[39m\u001b[34m(bcrp_url, raw_pdf_folder, download_record_folder, download_record_txt, alert_track_folder, max_downloads, downloads_per_batch, headless)\u001b[39m\n\u001b[32m    453\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müèÅ Download limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_downloads\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m new PDFs reached.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    454\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m         \u001b[43mrandom_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEFAULT_MIN_WAIT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDEFAULT_MAX_WAIT\u001b[49m\u001b[43m)\u001b[49m                 \u001b[38;5;66;03m# Gentle pacing to mimic a human user\u001b[39;00m\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m StaleElementReferenceException:\n\u001b[32m    459\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚ö†Ô∏è StaleElementReferenceException encountered. Consider re-running.\u001b[39m\u001b[33m\"\u001b[39m)  \n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Documentos\\RA\\CIUP\\GDP Revisions\\GitHub\\peru_gdp_revisions\\gdp_revisions_datasets\\gdp_rtd_pipeline.py:183\u001b[39m, in \u001b[36mrandom_wait\u001b[39m\u001b[34m(min_time, max_time)\u001b[39m\n\u001b[32m    181\u001b[39m wait_time = random.uniform(min_time, max_time)                          \u001b[38;5;66;03m# Inclusive random delay\u001b[39;00m\n\u001b[32m    182\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m‚è≥ Waiting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwait_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m seconds...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m183\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait_time\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Run the function to start the scraper bot\n",
    "pdf_downloader(\n",
    "    bcrp_url = \"https://www.bcrp.gob.pe/publicaciones/nota-semanal.html\",\n",
    "    raw_pdf_folder = raw_pdf_subfolder,\n",
    "    download_record_folder = record_folder,\n",
    "    download_record_txt = '1_downloaded_pdfs.txt',\n",
    "    alert_track_folder = alert_track_folder,\n",
    "    max_downloads = 60,\n",
    "    downloads_per_batch = 6, \n",
    "    headless = False \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773491f5-fd62-497b-9f94-59e5095c5659",
   "metadata": {},
   "source": [
    "Probably the üì∞ WR were downloaded in a single folder, but we would like the WR to be sorted by years. The following code sorts the PDFs into subfolders (years) for us by placing each WR according to the year of its publication. This happens in the **\"blink of an eye\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854039b-4e01-47ea-8a6e-eae871829d78",
   "metadata": {},
   "source": [
    "Check your raw_pdf_subfolder out, every PDF should be placed in a year folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ee016a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è No 4-digit year detected in filename: _quarantine\n"
     ]
    }
   ],
   "source": [
    "# Get the list of files in the directory\n",
    "files = os.listdir(raw_pdf_subfolder)\n",
    "\n",
    "# Call the function to organize files\n",
    "organize_files_by_year(raw_pdf_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b482a-b33d-4059-b4a2-805ba4612fd8",
   "metadata": {},
   "source": [
    "# WR-08-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a626509-2142-4de1-ba7f-9e47b7a8c81a",
   "metadata": {},
   "source": [
    "This  is crucial for the upcoming steps, specially for the section 3, cleansing. If -in the future- you enconuter some issues by executing cleaing it is likely to atributte to the pdf nature. IN that case, you can return to this code to replace defectiv pdfs for those convinient ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d75a9-308b-4fa1-848a-9771fcffbb1b",
   "metadata": {},
   "source": [
    "Don't worry about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad4344-deba-476d-91e7-6871c6ba4996",
   "metadata": {},
   "source": [
    "T√∫ puedes hacer lo mismo si te enfrentas a un inconveniente similar. Incluso puedes descargar los casos excepecionales de WR de un mismo mes y reemplazar los defectuosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e956de-ead1-4439-a3c5-bab8aeb75a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace specific defective PDFs (friendly outputs with icons)\n",
    "replace_defective_pdfs(\n",
    "    items=[\n",
    "        (\"2017\", \"ns-08-2017.pdf\", \"ns-07-2017\"), # Enter the year (folder) that contains the defective PDF, the defective PDF, and the new chosen PDF \n",
    "        (\"2019\", \"ns-23-2019.pdf\", \"ns-22-2019\"), # The same one above\n",
    "    ],\n",
    "    root_folder=input_pdf_subfolder, # base folder with /2017, /2019, ...\n",
    "    record_folder=record_folder, # folder with new_downloaded_pdfs.txt\n",
    "    download_record_txt = '1_downloaded_pdfs.txt',\n",
    "    quarantine=os.path.join(input_pdf_subfolder, \"_quarantine\")  # set to None to delete instead\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d24d2",
   "metadata": {},
   "source": [
    "## 2. Generating PDF inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666f310",
   "metadata": {},
   "source": [
    "Now that we have downloaded the üì∞ WR from the Central Bank, we should know that each of these files has more than 100 pages, but not all of them contain the information required for this project.\n",
    "\n",
    "All we really want is a couple of pages from each üì∞ WR, one for **Table 1** (monthly real GDP growth) and one for **Table 2** (annual and quarterly real GDP growth). The code below is executed to maintain the **two key pages** with both tables of each PDF plus the cover page that contains the information that helps us identify one üì∞ WR from another such as its date of publication and serial number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6af50-3b5b-44f2-859a-3b37d4b57495",
   "metadata": {},
   "source": [
    "_quarentine will be discard of the input PDF generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae30e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÇ Processing folder: 2024\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating input PDFs with key tables in 2024: 100%|\u001b[38;2;230;0;76m‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\u001b[0m| 11/11\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úîÔ∏è Shortened PDFs saved in 'pdf\\input' (5 new, 6 skipped)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to continue to the next folder after '2024'? (y = yes / n = no):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚è© 132 input PDFs already generated for years: 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 2023\n",
      "\n",
      "üìä Summary:\n",
      "\n",
      "üìÇ 13 folders (years) found containing raw PDFs\n",
      "üóÉÔ∏è Already generated input PDFs: 138\n",
      "‚ûï Newly generated input PDFs: 5\n",
      "‚è±Ô∏è 14 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run the function to generate trimmed PDFs for input\n",
    "pdf_input_generator(\n",
    "    raw_pdf_folder = raw_pdf_subfolder,\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    input_pdf_record_folder = record_folder,\n",
    "    input_pdf_record_txt = '2_generated_input_pdfs.txt',\n",
    "    keywords = [\"ECONOMIC SECTORS\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643079a",
   "metadata": {},
   "source": [
    "Again, probably the WR (PDF files, now of few pages) were stored in disorder in the `input_pdf_folder` folder. The following code sorts the PDFs into subfolders (years) by placing each WR (which now includes only the key tables) according to the year of its publication. This happens in the **\"blink of an eye\"**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the directory\n",
    "files = os.listdir(input_pdf_subfolder)\n",
    "\n",
    "# Call the function to organize files\n",
    "organize_files_by_year(input_pdf_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e1e92",
   "metadata": {},
   "source": [
    "## 3. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100857d4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "Since we already have the PDFs <span style=\"font-size: 24px;\">&#128462;</span> with just the tables required for this project, we can start extracting them. Then we can proceed with data cleaning.\n",
    "</p>  \n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357318e8",
   "metadata": {},
   "source": [
    "### 3.2 Extracting tables and data cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea58b1c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The main library used for extracting tables from PDFs <span style=\"font-size: 24px;\">&#128462;</span> is <code>pdfplumber</code>. You can review the official documentation by clicking <a href=\"https://github.com/jsvine/pdfplumber\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">here</a>.\n",
    "</p>\n",
    "    \n",
    "<p>     \n",
    "    The functions in <b>Section 3</b> of the <code>\"new_gdp_datasets_functions.py\"</code> script were built to deal with each of these issues. An interesting exercise is to compare the original tables (the ones in the PDF <span style=\"font-size: 24px;\">&#128462;</span>) and the cleaned tables (by the cleanup codes below). Thus, the cleanup codes for <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a> and <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a> generates two dictionaries, the first one stores the raw tables; that is, the original tables from the PDF <span style=\"font-size: 24px;\">&#128462;</span> extracted by the <code>pdfplumber</code> library, while the second dictionary stores the fully cleaned tables.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070fb47",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    The code iterates through each PDF <span style=\"font-size: 24px;\">&#128462;</span> and extracts the two required tables from each. The extracted information is then transformed into dataframes and the columns and values are cleaned up to conform to Python conventions (pythonic).\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436c2d1",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.2.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 1.</span> Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65139cc2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The basic criterion to start extracting tables is to use keywords (sufficient condition). I mean, tables containing the following keywords meet the requirements to be extracted.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d4ac96",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <b>\"ns_dates\"</b> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bffcd08-7763-4eed-ad99-d3bce3644f90",
   "metadata": {},
   "source": [
    "Si por alguna raz√≥n ejecutas el c√≥digo de la secci√≥n 3 y no continuas ejecutando la secci√≥n subsecuente, puedes estar tranquilo de que un registro los guard√≥. La pr√≥xima vez que visite este script basta con empezar desde esta secci√≥n 3 (eliminando el txt) para generar los dataframes que no se guardaron en ningun lado, estos son insumos esenciales para la secci√≥n 4. Alternativamente puede guardar todos los dataframes generados en una carpeta como respaldo y empezar desde la secci√≥n 4 carg√°ndolos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd60792-ec6d-441c-a61a-2ced241a4f2f",
   "metadata": {},
   "source": [
    "# Section 3 ‚Äî Cleaning pipelines (Table 1 & Table 2)\n",
    "\n",
    "### Functions\n",
    "- `new_table_1_cleaner(...)` ‚Üí cleans **Table 1 (monthly)** pages and returns two dicts:\n",
    "  - `raw_tables_dict_1`: raw tables exactly as extracted from PDFs, keyed as `ns_xx_yyyy_1`.\n",
    "  - `new_dataframes_dict_1`: cleaned tables ready for downstream steps, keyed as `ns_xx_yyyy_1`.\n",
    "\n",
    "- `new_table_2_cleaner(...)` ‚Üí cleans **Table 2 (quarterly/annual)** pages and returns:\n",
    "  - `raw_tables_dict_2`: raw tables, keyed as `ns_xx_yyyy_2`.\n",
    "  - `new_dataframes_dict_2`: cleaned tables, keyed as `ns_xx_yyyy_2`.\n",
    "\n",
    "Both functions:\n",
    "- **skip** year folder `_quarantine`\n",
    "- maintain a **record txt** (chronologically sorted: year ‚Üí issue)  \n",
    "- show **Jupyter progress bars** (magenta = active, blue = finished)\n",
    "- write a **log file**:\n",
    "  - Table 1 ‚Üí `logs/3_cleaner_1.log`\n",
    "  - Table 2 ‚Üí `logs/3_cleaner_2.log`\n",
    "\n",
    "### Arguments\n",
    "- `input_pdf_folder: str`  \n",
    "  Root containing year subfolders with input PDFs (e.g., `input_pdf_subfolder/2017/ns-07-2017.pdf`).\n",
    "\n",
    "- `record_folder: str`  \n",
    "  Folder where the record txt is stored (e.g., `record/`).\n",
    "\n",
    "- `record_txt: str` *(optional)*  \n",
    "  Record filename. Defaults:\n",
    "  - Table 1 ‚Üí `new_generated_dataframes_1.txt`\n",
    "  - Table 2 ‚Üí `new_generated_dataframes_2.txt`\n",
    "\n",
    "- `log_folder: str` *(optional, default `logs`)*  \n",
    "  Where the `.log` files are written.\n",
    "\n",
    "- `log_txt: str` *(optional)*  \n",
    "  Log filename. Defaults:\n",
    "  - Table 1 ‚Üí `3_cleaner_1.log`\n",
    "  - Table 2 ‚Üí `3_cleaner_2.log`\n",
    "\n",
    "- `persist: bool` *(optional, default `False`)*  \n",
    "  If `True`, save cleaned tables to disk and update a manifest.  \n",
    "  If `False`, nothing is saved (keeps repo light and re-runnable).\n",
    "\n",
    "- `persist_folder: str | None` *(optional)*  \n",
    "  Base folder for persisted outputs (default: `./data/clean`).  \n",
    "  Layout when `persist=True`:\n",
    "    data/clean/\n",
    "    table_1/\n",
    "    manifest.csv\n",
    "    2017/\n",
    "    ns-07-2017.parquet (or .csv if Parquet engine unavailable)\n",
    "    table_2/\n",
    "    manifest.csv\n",
    "    2017/\n",
    "    ns-07-2017.parquet\n",
    "\n",
    "- `pipeline_version: str` *(optional, default `\"s3.0.0\"`)*  \n",
    "Version tag recorded in `manifest.csv` for cache/audit. Bump it when the cleaning logic changes.\n",
    "\n",
    "### Typical calls\n",
    "\n",
    "```python\n",
    "# Table 1 (monthly)\n",
    "raw_1, clean_1 = new_table_1_cleaner(\n",
    "  input_pdf_folder=input_pdf_subfolder,\n",
    "  record_folder=record_folder,\n",
    "  persist=True,                           # turn on checkpointing (Parquet/CSV + manifest)\n",
    "  persist_folder=clean_data,              # e.g., os.path.join(project_root, \"data\", \"clean\")\n",
    "  pipeline_version=\"s3.0.0\"\n",
    ")\n",
    "\n",
    "# Table 2 (quarterly/annual)\n",
    "raw_2, clean_2 = new_table_2_cleaner(\n",
    "  input_pdf_folder=input_pdf_subfolder,\n",
    "  record_folder=record_folder,\n",
    "  persist=True,\n",
    "  persist_folder=clean_data,\n",
    "  pipeline_version=\"s3.0.0\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4aabed-81df-4d47-af89-ab1fc70f6f0c",
   "metadata": {},
   "source": [
    "\n",
    "If you want the runners to *also* write the cleaned dicts out to a single combined Parquet/CSV per table (alongside the per-WR files), I can add that as an optional flag (`persist_combined=True`) without changing the defaults.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7075989-80c9-42f6-8a9e-df0728e67ace",
   "metadata": {},
   "source": [
    "# If you will run until this section and you are planning to go back and retake from section 4, enter \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021e356-54c3-4b4e-8e2e-666578a86b54",
   "metadata": {},
   "source": [
    "# Table 1 data into *row-based* vintage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6659e030-643c-4894-87a8-b85b1cfbf408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ data created\n",
      "üìÇ data\\input created\n",
      "üìÇ data\\output created\n"
     ]
    }
   ],
   "source": [
    "# Define base folder for saving vintages data (.csv)\n",
    "data_folder = 'data'\n",
    "\n",
    "# Define subfolder for saving \n",
    "input_data_subfolder = os.path.join(data_folder, 'input')\n",
    "\n",
    "# Define subfolder for saving \n",
    "output_data_subfolder = os.path.join(data_folder, 'output')\n",
    "\n",
    "# Create all required folders (if they do not already exist) and confirm creation\n",
    "for folder in [data_folder, input_data_subfolder, output_data_subfolder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"üìÇ {folder} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2388f-faa2-4eb7-abce-8b61e8d7b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1, clean_1, vintages_1 = new_table_1_cleaner(\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = 'new_created_rtd_tab_1.txt',\n",
    "    persist = True,\n",
    "    persist_folder = input_data_subfolder,\n",
    "    pipeline_version = \"s3.0.0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3004d-e825-41a2-8247-81fa5cceec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ecc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1392888-be8b-4b95-98cf-ebd71d34dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a4fe9-54cc-48b6-901c-b0b5396fe68d",
   "metadata": {},
   "source": [
    "# Checking the cleaning version out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88e1dd-8c85-481b-9a42-3d3b8174cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df100 = vintages_1[\"ns_04_2022_1\"]\n",
    "print(df100.attrs)\n",
    "# {'pipeline_version': 's3.0.0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48b6ed-b2ce-44cd-b19e-930ff305f8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8229f-e230-494f-97b1-bcf4e6a9ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1[\"ns_04_2022_1\"].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef214918-2835-4738-8ec0-5ea98e3e2d8d",
   "metadata": {},
   "source": [
    "# Table 2 data into *row-based* vintage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcfe1b-9f63-4850-937f-ca582be3ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_2, clean_2, vintages_2 = new_table_2_cleaner(\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = 'new_created_rtd_tab_2.txt',\n",
    "    persist = True,\n",
    "    persist_folder = input_data_subfolder,\n",
    "    pipeline_version = \"s3.0.0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb0dd4-9e7e-4255-95dd-5fe8175be6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2386c0-bf54-4d0a-b67d-97352ad8203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df200 = vintages_2[\"ns_04_2022_2\"]\n",
    "print(df200.attrs)\n",
    "# {'pipeline_version': 's3.0.0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d77e3-f8f3-4c31-a25e-cf3af14adae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2c580-8454-45c8-902f-11f4bfda68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_2[\"ns_04_2022_1\"].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8989d65",
   "metadata": {},
   "source": [
    "## 4. GDP Real-Time dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfeae0-b5b0-4629-855a-a5556a43465a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ebedad3-c21c-4d63-85d5-b0c3bcfeba7a",
   "metadata": {},
   "source": [
    "**Connect to the PostgreSQL database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30582cc-ab70-4aba-b054-02fb48757b40",
   "metadata": {},
   "source": [
    "The following function will establish a connection to the `gdp_revisions_datasets` database in `PostgreSQL`. The **input data** used in this jupyter notebook will be loaded from this `PostgreSQL` database, and similarly, all **output data** generated by this jupyter notebook will be stored in that database. Ensure that you set the necessary parameters to access the server once you have obtained the required permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad90ec-db3c-4e20-a1d2-6d09c0779170",
   "metadata": {},
   "source": [
    "> üí° **Tip:** To request permissions, please email [Jason üì®](mailto:jj.cruza@alum.up.edu.pe)  \n",
    "> ‚ö†Ô∏è **Warning:** Make sure you have set your SQL credentials as environment variables before proceeding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da345bbe-0d12-4340-9275-938bfef26fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b60634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlalchemy_engine(database=\"gdp_revisions_datasets\", port=5432):\n",
    "    \"\"\"\n",
    "    Create an SQLAlchemy engine to connect to the PostgreSQL database.\n",
    "    \n",
    "    Environment Variables Required:\n",
    "        CIUP_SQL_USER: SQL username\n",
    "        CIUP_SQL_PASS: SQL password\n",
    "        CIUP_SQL_HOST: SQL host address\n",
    "\n",
    "    Args:\n",
    "        database (str): Name of the database. Default is 'gdp_revisions_datasets'.\n",
    "        port (int): Port number. Default is 5432.\n",
    "\n",
    "    Returns:\n",
    "        engine (sqlalchemy.engine.Engine): SQLAlchemy engine object.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If required environment variables are missing.\n",
    "\n",
    "    Example:\n",
    "        engine = create_sqlalchemy_engine()\n",
    "    \"\"\"\n",
    "    user = os.environ.get('CIUP_SQL_USER')\n",
    "    password = os.environ.get('CIUP_SQL_PASS')\n",
    "    host = os.environ.get('CIUP_SQL_HOST')\n",
    "\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"‚ùå Missing environment variables: CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS\")\n",
    "\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    print(f\"üîó Connected to PostgreSQL database: {database} at {host}:{port}\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76e853-8dc9-45e6-9f30-cde33dd3966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_sqlalchemy_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958b6af-25e7-4ec3-9d1d-c436bed32709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e4426-8320-4dfe-bf4e-fb3ca1d211c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1 = concatenate_table_1(\n",
    "    input_data_subfolder=input_data_subfolder,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=\"4_concatenated_rtd_tab_1.txt\",\n",
    "    persist=True,\n",
    "    persist_folder=output_data_subfolder,\n",
    "    csv_file_label=\"monthly_gdp_rtd.csv\",   # your custom name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c00c29-942f-49a9-9c44-96a80b9f6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a63583-7b4f-4d38-9128-227128066754",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfcc1c0-c027-4084-af58-91d042df0cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c411a38-f585-4c9d-83d6-19c5bcff89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_2 = concatenate_table_2(\n",
    "    input_data_subfolder=input_data_subfolder,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=\"4_concatenated_rtd_tab_2.txt\",\n",
    "    persist=True,\n",
    "    persist_folder=output_data_subfolder,\n",
    "    csv_file_label=\"quarterly_annual_gdp_rtd.csv\",  # your custom name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d6f6a-a5e7-431d-a512-4eb4fb7a1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb546a-6b80-4c88-a3d1-672c972aabcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecce1c-ffee-4f3b-9723-91f85a2ae9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57c55f-4ffd-4402-b06e-3c7c3c407191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552a123-c9f8-4bee-a035-72fa78b73dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c5741-7555-4fa0-b4b0-22596446ff6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9f79e7-a7bc-479d-a41d-6f6fb4398117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0a2b2503-e10e-4aef-ad23-5f48235e6293",
   "metadata": {},
   "source": [
    "# Revision Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e210bbb1-dae3-4daa-84b8-4596a9017013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ metadata created\n",
      "üìÇ pdf created\n",
      "üìÇ pdf\\input created\n",
      "üìÇ record created\n"
     ]
    }
   ],
   "source": [
    "# Define base folder for saving all digital PDFs\n",
    "metadata_folder = 'metadata'\n",
    "\n",
    "# Define base folder for saving all digital PDFs\n",
    "pdf_folder = 'pdf'\n",
    "\n",
    "# Define subfolder for saving reduced PDFs containing only selected pages with GDP growth tables (monthly, quarterly, and annual frequencies)\n",
    "input_pdf_subfolder = os.path.join(pdf_folder, 'input')\n",
    "\n",
    "# Define folder for saving .txt files with download and dataframe record\n",
    "record_folder = 'record'\n",
    "\n",
    "# Create all required folders (if they do not already exist) and confirm creation\n",
    "for folder in [metadata_folder, pdf_folder, input_pdf_subfolder, record_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"üìÇ {folder} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35972c04-3b3d-434d-8ae2-718b460a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base_year_list for mapping base years (modify or extend this list as needed)\n",
    "base_year_list = [\n",
    "    {\"year\": 1994, \"wr\": 1, \"base_year\": 1990},\n",
    "    {\"year\": 2000, \"wr\": 28, \"base_year\": 1994},\n",
    "    {\"year\": 2014, \"wr\": 11, \"base_year\": 2007},\n",
    "    {\"year\": 2022, \"wr\": 20, \"base_year\": 2019},\n",
    "    # Add more mappings if needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dba404-f4e5-495c-adf1-7714fb3ab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to update the metadata\n",
    "updated_df = update_metadata(\n",
    "    metadata_folder = metadata_folder,\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = \"wr_metadata.txt\",\n",
    "    wr_metadata_csv = \"wr_metadata.csv\",\n",
    "    base_year_list = base_year_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730862b-944b-47fa-b4a3-9ef75c43607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.iloc[-30:]   # last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed0066-cbbc-467d-b5c3-f55faf8c68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_df[\"benchmark_revision\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f17c6-aa9e-4453-860a-5e9f6169778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_df[\"base_year\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9643b2d4-3c6b-40ef-b945-f1a7e21c2a76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c13eabb9-af86-41e9-a3f4-ab9cb9183660",
   "metadata": {},
   "source": [
    "# Drop base year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc92104-cfd4-4466-9d9f-2b1886d014b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_year_list_2 = [\n",
    "    \"2000m7\",   # 1990 -> 1994\n",
    "    \"2014m3\",   # 1994 -> 2007\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06d1cbc5-64b0-45e1-952e-37642dabd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_revisions_by_affected = apply_base_year_sentinel(\n",
    "    base_year_list=base_year_list_2,\n",
    "    sentinel=-999999.0,\n",
    "    output_data_subfolder=output_data_subfolder,\n",
    "    csv_file_label=\"monthly_gdp_rtd.csv\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb74e8-7f22-4756-96ea-eb86a2aa400e",
   "metadata": {},
   "source": [
    "# Releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d86a426-4e03-48b3-98a4-26f8f7f16395",
   "metadata": {},
   "outputs": [],
   "source": [
    "removed_revisions_by_affected = apply_base_year_sentinel(\n",
    "    base_year_list=base_year_list_2,\n",
    "    sentinel=-999999.0,\n",
    "    output_data_subfolder=output_data_subfolder,\n",
    "    csv_file_label=\"monthly_gdp_rtd.csv\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
