{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0ee00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0953333",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter bt pro roman'; color: rgb(0, 65, 75);\">\n",
    "<h1>\n",
    "Old GDP Revisions Datasets\n",
    "</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323e5f0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter bt pro roman'; color: rgb(0, 65, 75);\">\n",
    "<h3>\n",
    "Documentation\n",
    "<br>\n",
    "____________________\n",
    "<br>\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc075bd7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'PT Serif Pro Book'; color: rgb(0, 65, 75); font-size: 16px;\">\n",
    "    Jason Cruz\n",
    "    <br>\n",
    "    <a href=\"mailto:jj.cruza@up.edu.pe\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">\n",
    "        jj.cruza@up.edu.pe\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0f23d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "This <span style=\"color: rgb(0, 65, 75);\">jupyter notebook</span> documents step-by-step the <b>construction of old datasets</b> for the project <b>'Revisions and Biases in Preliminary GDP Estimates in Peru'</b>.\n",
    "\n",
    "This jupyter notebook goes from the cleaning of the tables (Weekly Reports, WR) provided confidentially by the Central Bank to the construction of the <b>vintages</b> and <b>revisions</b> datasets from 1994-2024.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2a19fb",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;line-height: 1.5;\">\n",
    "<span style=\"font-size: 24px;\">&#128196;</span> The Weekly Report/<i>Nota Semanal</i> (WR/<i>NS</i>) of the Central Bank.\n",
    "    <br>\n",
    "    <span style=\"font-size: 24px;\">&#8987;</span> Available since <b>1994-2012</b> (Table 1) and since <b>1997-2012</b> (Table 2). \n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516ae6c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Amaya; text-align: left; color: rgb(0, 65, 75); font-size:16px\">The following <b>outline is functional</b>. By utilising the provided buttons, users are able to enhance their experience by browsing this script.<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820c1d92",
   "metadata": {},
   "source": [
    "<div id=\"outilne\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15589700",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #292929; padding: 10px; line-height: 1.5; font-family: 'PT Serif Pro Book';\">\n",
    "    <h2 style=\"text-align: left; color: #E0E0E0;\">\n",
    "        Outline\n",
    "    </h2>\n",
    "    <br>\n",
    "    <a href=\"#libraries\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        Libraries</a>\n",
    "    <br>\n",
    "    <a href=\"#setup\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        Initial set-up</a>\n",
    "    <br>\n",
    "    <a href=\"#1\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        1. Duplicate tables for all other NS ids</a>\n",
    "    <br>\n",
    "    <a href=\"#1-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        1.1. Table 1.</a>\n",
    "    <br>\n",
    "    <a href=\"#1-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        1.2. Table 2.</a>\n",
    "    <br>\n",
    "    <a href=\"#2\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        2. Data cleaning</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        2.1. Extracting tables and data cleanup.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-2-1\" style=\"color: #94FFD8; font-size: 14px; margin-left: 40px;\">\n",
    "        2.2.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-2-2\" style=\"color: #94FFD8; font-size: 14px; margin-left: 40px;\">\n",
    "        2.2.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.</a>\n",
    "    <br>\n",
    "    <a href=\"#3\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">3. Real-time data of Peru's GDP growth rates</a>\n",
    "    <br>\n",
    "    <a href=\"#3-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.1. Annual vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.2. Quarterly vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-3\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.3. Monthly vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-4\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.4. Loading SQL.</a>\n",
    "    <br>\n",
    "    <a href=\"#4\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">4. GDP final revision dataset</a>\n",
    "    <br>\n",
    "    <a href=\"#4-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.1. Annual revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#4-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.2. Quarterly revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#4-3\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.3. Monthly revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#5\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">5. Uploading data to SQL</a>\n",
    "    <br>\n",
    "    <a href=\"#5-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        5.1. Vintages.</a>\n",
    "    <br>\n",
    "    <a href=\"#5-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        5.2. Revisions.</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7c4d6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    Any questions or issues regarding the coding, please email Jason Cruz <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123); text-decoration: none;\"><span style=\"font-size: 24px;\">&#x2709;</span>\n",
    "    </a>.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff8772",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    If you don't have the libraries below, please use the following code (as example) to install the required libraries.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f517f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21974a",
   "metadata": {},
   "source": [
    "<div id=\"libraries\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a752d8fe",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    <h2>\n",
    "    Libraries\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00415459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Duplicate tables for all other NS ids\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# 1.1. Table 1\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Data cleaning\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2.2. Extracting tables and data cleanup\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import unicodedata  # For manipulating Unicode data\n",
    "import re  # For regular expressions operations\n",
    "from datetime import datetime  # For working with dates and times\n",
    "import locale  # For locale-specific formatting of numbers, dates, and currencies\n",
    "import numpy as np\n",
    "import unidecode\n",
    "\n",
    "# 2.2.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "\n",
    "import tabula  # Used to extract tables from PDF files into pandas DataFrames\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO  # Used for creating graphical user interfaces\n",
    "from sqlalchemy import create_engine  # Used for connecting to and interacting with SQL databases\n",
    "\n",
    "# 2.2.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "\n",
    "import roman\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# 3. Real-time data of Peru's GDP growth rates\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import psycopg2  # For interacting with PostgreSQL databases\n",
    "from sqlalchemy import create_engine, text  # For creating and executing SQL queries using SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8167e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d73758",
   "metadata": {},
   "source": [
    "<div id=\"setup\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fbf38",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark;\">\n",
    "    <h2>\n",
    "    Initial set-up\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eda909e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> Setting the base path. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cda3c14",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your base path to set your main working directory, then press enter: \n",
      "C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\Research Assistant\\CIUP\\GDP Revisions\\gdp_revisions\\old_database\\raw_data\n",
      "Base path correctly setted.\n"
     ]
    }
   ],
   "source": [
    "# Ask the user for the base path\n",
    "base_path = input(\"Please enter your base path to set your main working directory, then press enter: \\n\")\n",
    "\n",
    "# Check if the path is valid\n",
    "if os.path.isdir(base_path):\n",
    "    print(f\"Basbme path correctly setted.\")\n",
    "    os.chdir(base_path)\n",
    "else:\n",
    "    print(\"The entered path is not valid. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae590bfb",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    Download the <code>.zip</code> files of <code>table_1</code> and <code>table_2</code> and paste them into your base path set above. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a4e45f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sectores_economicos</th>\n",
       "      <th>economic_sectors</th>\n",
       "      <th>1992_ene</th>\n",
       "      <th>1992_feb</th>\n",
       "      <th>1992_mar</th>\n",
       "      <th>1992_abr</th>\n",
       "      <th>1992_may</th>\n",
       "      <th>1992_jun</th>\n",
       "      <th>1992_jul</th>\n",
       "      <th>1992_ago</th>\n",
       "      <th>...</th>\n",
       "      <th>1993_mar</th>\n",
       "      <th>1993_abr</th>\n",
       "      <th>1993_may</th>\n",
       "      <th>1993_jun</th>\n",
       "      <th>1993_jul</th>\n",
       "      <th>1993_ago</th>\n",
       "      <th>1993_sep</th>\n",
       "      <th>1993_oct</th>\n",
       "      <th>1993_nov</th>\n",
       "      <th>1993_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agropecuario</td>\n",
       "      <td>agriculture and livestock</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>-6.6</td>\n",
       "      <td>-13.4</td>\n",
       "      <td>-10.7</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>-12.9</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.9</td>\n",
       "      <td>4.4</td>\n",
       "      <td>9.2</td>\n",
       "      <td>18.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>9.9</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agricola</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>-2.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>-17.5</td>\n",
       "      <td>-15.3</td>\n",
       "      <td>-13.8</td>\n",
       "      <td>-19.7</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>7.3</td>\n",
       "      <td>12.5</td>\n",
       "      <td>27.9</td>\n",
       "      <td>25.0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>17.4</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pecuario</td>\n",
       "      <td>livestock</td>\n",
       "      <td>11.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-4.1</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-2.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pesca</td>\n",
       "      <td>fishing</td>\n",
       "      <td>-29.8</td>\n",
       "      <td>-26.4</td>\n",
       "      <td>-24.6</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>-20.4</td>\n",
       "      <td>-20.3</td>\n",
       "      <td>25.9</td>\n",
       "      <td>59.4</td>\n",
       "      <td>...</td>\n",
       "      <td>104.7</td>\n",
       "      <td>128.5</td>\n",
       "      <td>15.6</td>\n",
       "      <td>38.8</td>\n",
       "      <td>101.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>27.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>12.3</td>\n",
       "      <td>43.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineria</td>\n",
       "      <td>mining and fuel</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>-3.4</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>11.3</td>\n",
       "      <td>12.9</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mineria metalica</td>\n",
       "      <td>metals</td>\n",
       "      <td>3.4</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>-11.8</td>\n",
       "      <td>-17.8</td>\n",
       "      <td>-5.8</td>\n",
       "      <td>-12.7</td>\n",
       "      <td>-11.5</td>\n",
       "      <td>...</td>\n",
       "      <td>11.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.6</td>\n",
       "      <td>18.2</td>\n",
       "      <td>13.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>4.2</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>7.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>petroleo crudo</td>\n",
       "      <td>fuels</td>\n",
       "      <td>-7.6</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-6.7</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.9</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.1</td>\n",
       "      <td>5.7</td>\n",
       "      <td>10.7</td>\n",
       "      <td>8.4</td>\n",
       "      <td>11.8</td>\n",
       "      <td>8.8</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.4</td>\n",
       "      <td>6.3</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>manufactura</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-13.4</td>\n",
       "      <td>-8.4</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>-15.7</td>\n",
       "      <td>-11.6</td>\n",
       "      <td>...</td>\n",
       "      <td>11.5</td>\n",
       "      <td>14.1</td>\n",
       "      <td>6.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>17.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>procesadores recursos primarios</td>\n",
       "      <td>based on raw materials</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>-9.8</td>\n",
       "      <td>-9.7</td>\n",
       "      <td>-23.8</td>\n",
       "      <td>-12.3</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-2.9</td>\n",
       "      <td>...</td>\n",
       "      <td>33.1</td>\n",
       "      <td>40.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>9.1</td>\n",
       "      <td>27.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>12.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>13.9</td>\n",
       "      <td>15.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resto industria</td>\n",
       "      <td>non primary</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-8.5</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-8.1</td>\n",
       "      <td>-21.3</td>\n",
       "      <td>-14.6</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.8</td>\n",
       "      <td>12.4</td>\n",
       "      <td>19.1</td>\n",
       "      <td>14.8</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>construccion</td>\n",
       "      <td>construction</td>\n",
       "      <td>27.7</td>\n",
       "      <td>12.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.9</td>\n",
       "      <td>-3.7</td>\n",
       "      <td>-0.7</td>\n",
       "      <td>-9.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>22.9</td>\n",
       "      <td>18.6</td>\n",
       "      <td>27.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>11.4</td>\n",
       "      <td>28.8</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gobierno</td>\n",
       "      <td>government</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>35.1</td>\n",
       "      <td>45.5</td>\n",
       "      <td>37.8</td>\n",
       "      <td>7.6</td>\n",
       "      <td>...</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>otros</td>\n",
       "      <td>others</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>-6.1</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>...</td>\n",
       "      <td>2.6</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>5.2</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>comercio</td>\n",
       "      <td>commerce</td>\n",
       "      <td>4.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>13.6</td>\n",
       "      <td>-7.4</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-7.7</td>\n",
       "      <td>-2.1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.9</td>\n",
       "      <td>10.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>10.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>resto</td>\n",
       "      <td>remaining</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.9</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>-7.3</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>...</td>\n",
       "      <td>4.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pbi</td>\n",
       "      <td>gdp</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>-7.5</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>-3.1</td>\n",
       "      <td>-7.2</td>\n",
       "      <td>-5.7</td>\n",
       "      <td>...</td>\n",
       "      <td>5.7</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>11.6</td>\n",
       "      <td>11.2</td>\n",
       "      <td>10.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                sectores_economicos           economic_sectors  1992_ene  \\\n",
       "0                      agropecuario  agriculture and livestock       3.7   \n",
       "1                          agricola                agriculture      -2.7   \n",
       "2                          pecuario                  livestock      11.4   \n",
       "3                             pesca                    fishing     -29.8   \n",
       "4                           mineria            mining and fuel      -1.4   \n",
       "5                  mineria metalica                     metals       3.4   \n",
       "6                    petroleo crudo                      fuels      -7.6   \n",
       "7                       manufactura              manufacturing      -3.5   \n",
       "8   procesadores recursos primarios     based on raw materials     -19.0   \n",
       "9                   resto industria                non primary       5.6   \n",
       "10                     construccion               construction      27.7   \n",
       "11                         gobierno                 government      -3.9   \n",
       "12                            otros                     others       3.1   \n",
       "13                         comercio                   commerce       4.2   \n",
       "14                            resto                  remaining       2.5   \n",
       "15                              pbi                        gdp       1.3   \n",
       "\n",
       "    1992_feb  1992_mar  1992_abr  1992_may  1992_jun  1992_jul  1992_ago  ...  \\\n",
       "0        3.6      -2.4      -6.6     -13.4     -10.7     -10.2     -12.9  ...   \n",
       "1        2.2      -4.5      -9.8     -17.5     -15.3     -13.8     -19.7  ...   \n",
       "2        5.6       1.2       1.6       0.4       5.6       2.7       2.5  ...   \n",
       "3      -26.4     -24.6     -43.0     -20.4     -20.3      25.9      59.4  ...   \n",
       "4       -5.5     -11.1      -9.8     -12.3      -3.4      -8.3      -5.0  ...   \n",
       "5       -7.4     -16.0     -11.8     -17.8      -5.8     -12.7     -11.5  ...   \n",
       "6       -3.0      -3.8      -6.7      -4.0       0.0      -1.9       5.0  ...   \n",
       "7       -2.3       3.2     -13.4      -8.4      -7.7     -15.7     -11.6  ...   \n",
       "8       -9.8      -9.7     -23.8     -12.3      -6.9       0.7      -2.9  ...   \n",
       "9        0.9       9.0      -8.5      -6.4      -8.1     -21.3     -14.6  ...   \n",
       "10      12.8      22.0       4.9      -3.7      -0.7      -9.6      -0.6  ...   \n",
       "11       1.1      -0.6      -0.8      35.1      45.5      37.8       7.6  ...   \n",
       "12       4.9       6.9      -6.1      -5.2      -3.8      -7.4      -4.4  ...   \n",
       "13      11.2      13.6      -7.4      -3.3      -2.0      -7.7      -2.1  ...   \n",
       "14       1.9       3.5      -5.5      -6.2      -4.6      -7.3      -5.5  ...   \n",
       "15       1.8       2.8      -7.5      -5.7      -3.1      -7.2      -5.7  ...   \n",
       "\n",
       "    1993_mar  1993_abr  1993_may  1993_jun  1993_jul  1993_ago  1993_sep  \\\n",
       "0       -4.1      -2.4       0.9       4.4       9.2      18.3      15.9   \n",
       "1       -4.1      -1.7       2.9       7.3      12.5      27.9      25.0   \n",
       "2       -4.0      -4.0      -4.6      -4.1      -0.5       1.1       2.4   \n",
       "3      104.7     128.5      15.6      38.8     101.7       0.3      27.8   \n",
       "4       10.0       4.0       7.6       5.1      15.4      11.3      12.9   \n",
       "5       11.4       2.7       5.3       2.6      18.2      13.2      16.8   \n",
       "6        8.1       5.7      10.7       8.4      11.8       8.8       7.9   \n",
       "7       11.5      14.1       6.5      10.2      17.0      15.6      14.0   \n",
       "8       33.1      40.3       5.6       9.1      27.5       6.7      12.0   \n",
       "9        3.5       3.7       7.0      10.8      12.4      19.1      14.8   \n",
       "10       6.3       7.0      10.1      22.9      18.6      27.9      19.4   \n",
       "11       1.2       0.4      -0.4       1.0       2.1       0.4      -5.0   \n",
       "12       2.6       7.4       4.0       6.8       8.2       6.5       8.4   \n",
       "13      -1.3       9.0       2.1       3.9      10.9       1.5      10.6   \n",
       "14       4.8       6.5       5.0       8.3       6.7       9.2       7.3   \n",
       "15       5.7       7.2       4.5       7.6      11.6      11.2      10.5   \n",
       "\n",
       "    1993_oct  1993_nov  1993_mean  \n",
       "0        9.9       9.6        5.3  \n",
       "1       17.5      17.4        9.4  \n",
       "2        0.4       0.4       -2.2  \n",
       "3       20.6      12.3       43.6  \n",
       "4        6.0       1.4        8.1  \n",
       "5        4.2      -2.1        7.3  \n",
       "6        8.4       6.3        9.1  \n",
       "7        6.2       8.8        9.2  \n",
       "8        7.7      13.9       15.6  \n",
       "9        5.5       6.2        6.5  \n",
       "10      11.4      28.8       12.8  \n",
       "11       3.0      -1.0        0.1  \n",
       "12       5.2       6.5        5.0  \n",
       "13       2.8       8.0        4.0  \n",
       "14       6.4       5.7        5.6  \n",
       "15       6.3       7.5        6.7  \n",
       "\n",
       "[16 rows x 27 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prueba = pd.read_csv(f'{base_path}/table_1/1994/ns-03-1994.csv', delimiter=';')\n",
    "prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d826062b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67364826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save downloaded PDF files\n",
    "\n",
    "raw_pdf = 'raw_pdf' # to save raw data (.pdf).\n",
    "if not os.path.exists(raw_pdf):\n",
    "    os.mkdir(raw_pdf) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4294ef39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde1cd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73bb31bc",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6da554",
   "metadata": {},
   "source": [
    "<p style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following function will establish a connection to the <code>gdp_revisions_datasets</code> database in <code>PostgreSQL</code>. The <b>input data</b> used in this jupyter notebook will be loaded from this <code>PostgreSQL</code> database, and similarly, all <b>output data</b> generated by this jupyter notebook will be stored in that database. Ensure that you set the necessary parameters to access the server once you have obtained the required permissions.<p/>\n",
    "    \n",
    "<p style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "To request permissions, please email Jason Cruz <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123); text-decoration: none;\"> <span style=\"font-size: 24px;\">&#x2709;</span>\n",
    "    </a>.\n",
    "<p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4457bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlalchemy_engine():\n",
    "    \"\"\"\n",
    "    Function to create an SQLAlchemy engine using environment variables.\n",
    "    \n",
    "    Returns:\n",
    "        engine: SQLAlchemy engine object.\n",
    "    \"\"\"\n",
    "    # Get environment variables\n",
    "    user = os.environ.get('CIUP_SQL_USER')  # Get the SQL user from environment variables\n",
    "    password = os.environ.get('CIUP_SQL_PASS')  # Get the SQL password from environment variables\n",
    "    host = os.environ.get('CIUP_SQL_HOST')  # Get the SQL host from environment variables\n",
    "    port = 5432  # Set the SQL port to 5432\n",
    "    database = 'gdp_revisions_datasets'  # Set the database name 'gdp_revisions_datasets' from SQL\n",
    "\n",
    "    # Check if all environment variables are defined\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"Some environment variables are missing (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "    # Create connection string\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c975a54f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Import all other functions required by this jupyter notebook.\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bc0b35",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> Please, check the script <code>gdp_revisions_datasets_functions.py</code> which contains all the functions required by this jupyter notebook. The functions there are ordered according to the <a href=\"#outilne\" style=\"color: #3d30a2;\">sections</a> of this jupyter notebok.<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bae5607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gdp_revisions_datasets_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c3065",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6851a",
   "metadata": {},
   "source": [
    "<div id=\"1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e279c",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;; color: dark;\">1.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Duplicate tables for all other NS ids</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f4f70a",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    <p>The Central Bank has provided us with confidential data for Table 1 (1994-2012) and Table 2 (1997-2012). However, in each year we have been provided from the tables where the revisions occurred or, more generally, where the Central Bank has received from INEI the updated information of all NS tables.</p>\n",
    "    \n",
    "   <p>So, we will duplicate these tables to complete the total NS per year (50 approximately due to the number of weeks per year).</p>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e87d51c",
   "metadata": {},
   "source": [
    "<div id=\"1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f99e562",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">1.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Table 1\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6183f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgresSQL\n",
    "engine = create_sqlalchemy_engine()\n",
    "\n",
    "# Definir la consulta SQL para importar datos\n",
    "query = f\"SELECT * FROM old_raw_data_delivered\"\n",
    "\n",
    "# Importar los datos a un DataFrame de pandas\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Ruta base donde están las carpetas de años\n",
    "base_path = r\"C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 1\"\n",
    "\n",
    "# Función para duplicar archivos\n",
    "def duplicate_files(year, df_year, base_path):\n",
    "    year_path = os.path.join(base_path, str(year))\n",
    "    files = sorted([f for f in os.listdir(year_path) if f.endswith('.csv')])\n",
    "\n",
    "    # Obtener los archivos existentes\n",
    "    existing_files = {int(f.split('-')[1]): f for f in files}\n",
    "    \n",
    "    # Obtener el último archivo del año anterior\n",
    "    if year > 1994:\n",
    "        prev_year_path = os.path.join(base_path, str(year - 1))\n",
    "        prev_files = sorted([f for f in os.listdir(prev_year_path) if f.endswith('.csv')])\n",
    "        if prev_files:\n",
    "            last_prev_file = prev_files[-1]\n",
    "            last_prev_id_ns = int(last_prev_file.split('-')[1])\n",
    "        else:\n",
    "            last_prev_file = None\n",
    "            last_prev_id_ns = None\n",
    "    else:\n",
    "        last_prev_file = None\n",
    "        last_prev_id_ns = None\n",
    "\n",
    "    # Inicializar variables para duplicación\n",
    "    last_existing_file = last_prev_file\n",
    "    last_existing_id_ns = last_prev_id_ns\n",
    "\n",
    "    for index, row in df_year.iterrows():\n",
    "        id_ns = row['id_ns']\n",
    "        if row['delivered_1'] == 1:\n",
    "            last_existing_file = existing_files[id_ns]\n",
    "            last_existing_id_ns = id_ns\n",
    "        else:\n",
    "            # Crear nombre del nuevo archivo duplicado\n",
    "            new_file_name = f\"ns-{id_ns:02d}-{year}.csv\"\n",
    "            new_file_path = os.path.join(year_path, new_file_name)\n",
    "\n",
    "            # Duplicar archivo\n",
    "            if last_existing_file:\n",
    "                if last_existing_file in existing_files.values():\n",
    "                    src_file_path = os.path.join(year_path, last_existing_file)\n",
    "                else:\n",
    "                    src_file_path = os.path.join(prev_year_path, last_existing_file)\n",
    "                shutil.copy(src_file_path, new_file_path)\n",
    "                print(f\"Duplicated {last_existing_file} to {new_file_name}\")\n",
    "            else:\n",
    "                print(f\"No existing file to duplicate for {new_file_name}\")\n",
    "\n",
    "# Procesar cada año\n",
    "for year in range(2010, 2013):\n",
    "    df_year = df[df['year'] == year]\n",
    "    duplicate_files(year, df_year, base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b56460",
   "metadata": {},
   "source": [
    "<div id=\"1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f725783",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">1.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Table 2\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405986f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1ab98c0",
   "metadata": {},
   "source": [
    "<div id=\"2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be29d5",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;; color: dark;\">2.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Data cleaning</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dc7602",
   "metadata": {},
   "source": [
    "# Exclusivas para tablas entregadas por el BCRP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c61dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd86a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def limpiar_nombres_columnas(df):\n",
    "    # Eliminar tildes y convertir a minúsculas los nombres de las columnas\n",
    "    df.columns = df.columns.str.lower()\n",
    "    # Only normalize string column names\n",
    "    df.columns = [unicodedata.normalize('NFKD', col).encode('ASCII', 'ignore').decode('utf-8') if isinstance(col, str) else col for col in df.columns]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8061b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377a126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajustar_nombres_columnas(df):\n",
    "    # Comprobar que la primera observación de la primera columna sea NaN\n",
    "    if pd.isna(df.iloc[0, 0]) and pd.isna(df.iloc[0, -1]):\n",
    "        # Verificar los nombres de las columnas\n",
    "        if \"sectores economicos\" in df.columns[0] and \"economic sectors\" in df.columns[-1]:\n",
    "            # Reemplazar NaN por los nombres de las columnas correspondientes\n",
    "            df.iloc[0, 0] = \"sectores economicos\"\n",
    "            df.iloc[0, -1] = \"economic sectors\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb9142f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73d42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounding_values(df, decimales=1):\n",
    "    # Iterar sobre todas las columnas del DataFrame\n",
    "    for col in df.columns:\n",
    "        # Verificar si la columna es de tipo float\n",
    "        if df[col].dtype == 'float64':\n",
    "            # Redondear los valores de la columna al número de decimales especificado\n",
    "            df[col] = df[col].round(decimales)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9f3049",
   "metadata": {},
   "source": [
    "# Importando csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69dd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Substitua 'arquivo.csv' pelo caminho do seu arquivo CSV\n",
    "path = r'C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-07-2010.csv'\n",
    "\n",
    "# Carrega o arquivo CSV para um DataFrame\n",
    "df = pd.read_csv(path, delimiter=';')\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame para verificar se os dados foram carregados corretamente\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2b387f",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ffb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Establecer la localización en español\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Diccionario para almacenar los DataFrames generados\n",
    "old_dataframes_dict_1 = {}\n",
    "\n",
    "# Ruta del archivo de registro de carpetas procesadas\n",
    "registro_path = 'dataframes_record/old_carpetas_procesadas_1.txt'\n",
    "\n",
    "# Función para corregir los nombres de los meses\n",
    "def corregir_nombre_mes(mes):\n",
    "    meses_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Agrega más mapeos si es necesario para otros nombres de meses\n",
    "    }\n",
    "    return meses_mapping.get(mes, mes)\n",
    "\n",
    "def registrar_carpeta_procesada(carpeta, num_archivos_procesados):\n",
    "    with open(registro_path, 'a') as file:\n",
    "        file.write(f\"{carpeta}:{num_archivos_procesados}\\n\")\n",
    "\n",
    "def carpeta_procesada(carpeta):\n",
    "    if not os.path.exists(registro_path):\n",
    "        return False\n",
    "    with open(registro_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(carpeta):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def obtener_fecha(df, engine):\n",
    "    id_ns = df['id_ns'].iloc[0]\n",
    "    year = df['year'].iloc[0]\n",
    "    query = f\"SELECT date FROM dates_growth_rates WHERE id_ns = '{id_ns}' AND year = '{year}';\"\n",
    "    fecha = pd.read_sql(query, engine)\n",
    "    return fecha.iloc[0, 0] if not fecha.empty else None\n",
    "\n",
    "def procesar_archivo_csv(csv_path, engine):\n",
    "    old_tables_dict_1 = {}  # Diccionario local para cada archivo CSV\n",
    "    table_counter = 1\n",
    "\n",
    "    filename = os.path.basename(csv_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No se encontraron coincidencias para id_ns y year en el nombre del archivo:\", filename)\n",
    "        return None, None, None, None\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(csv_path))[0].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(csv_path, delimiter=';')\n",
    "    \n",
    "    nombre_dataframe = f\"{new_filename}_{table_counter}\"\n",
    "    old_tables_dict_1[nombre_dataframe] = df.copy()\n",
    "\n",
    "    # Aplicar las funciones de limpieza a una copia del DataFrame\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Funciones de limpieza (ajustar según sea necesario)\n",
    "    df_clean = limpiar_nombres_columnas(df_clean)\n",
    "    df_clean = ajustar_nombres_columnas(df_clean)\n",
    "    df_clean = drop_rare_caracter_row(df_clean)\n",
    "    df_clean = drop_nan_rows(df_clean)\n",
    "    df_clean = drop_nan_columns(df_clean)\n",
    "    df_clean = reset_index(df_clean)\n",
    "    df_clean = remove_digit_slash(df_clean)\n",
    "    df_clean = replace_var_perc_first_column(df_clean)\n",
    "    df_clean = replace_var_perc_last_columns(df_clean)\n",
    "    df_clean = replace_number_moving_average(df_clean)\n",
    "    df_clean = relocate_last_column(df_clean)\n",
    "    df_clean = clean_first_row(df_clean)\n",
    "    df_clean = find_year_column(df_clean)\n",
    "    year_columns = extract_years(df_clean)\n",
    "    df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "    df_clean = first_row_columns(df_clean)\n",
    "    df_clean = clean_columns_values(df_clean)\n",
    "    df_clean = convert_float(df_clean)\n",
    "    df_clean = replace_set_sep(df_clean)\n",
    "    df_clean = spaces_se_es(df_clean)\n",
    "    df_clean = replace_services(df_clean)\n",
    "    df_clean = rounding_values(df_clean, decimales=1)\n",
    "\n",
    "    # Añadir la columna 'year' al DataFrame limpio\n",
    "    df_clean.insert(0, 'year', year)\n",
    "    \n",
    "    # Añadir la columna 'id_ns' al DataFrame limpio\n",
    "    df_clean.insert(1, 'id_ns', id_ns)\n",
    "    \n",
    "    # Obtener la fecha correspondiente de la base de datos\n",
    "    fecha = obtener_fecha(df_clean, engine)\n",
    "    if fecha:\n",
    "        # Añadir la columna 'date' al DataFrame limpio\n",
    "        df_clean.insert(2, 'date', fecha)\n",
    "    else:\n",
    "        print(\"No se encontró fecha en la base de datos para id_ns:\", id_ns, \"y year:\", year)\n",
    "    \n",
    "    # Almacenar DataFrame limpio en old_dataframes_dict_1\n",
    "    old_dataframes_dict_1[nombre_dataframe] = df_clean\n",
    "\n",
    "    return id_ns, year, old_tables_dict_1\n",
    "\n",
    "def procesar_carpeta(carpeta, engine):\n",
    "    print(f\"Procesando la carpeta {os.path.basename(carpeta)}\")\n",
    "    csv_files = [os.path.join(carpeta, f) for f in os.listdir(carpeta) if f.endswith('.csv')]\n",
    "\n",
    "    num_csv_procesados = 0\n",
    "    num_dataframes_generados = 0\n",
    "\n",
    "    table_counter = 1  # Inicializar el contador de tabla aquí\n",
    "    old_tables_dict_1 = {}  # Declarar old_tables_dict_1 fuera del bucle principal\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        id_ns, year, tables_dict_temp = procesar_archivo_csv(csv_file, engine)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for nombre_df, df in tables_dict_temp.items():\n",
    "                nombre_archivo = os.path.splitext(os.path.basename(csv_file))[0].replace('-', '_')\n",
    "                nombre_df = f\"{nombre_archivo}_{table_counter}\"\n",
    "                \n",
    "                # Almacenar DataFrame sin procesar en old_tables_dict_1\n",
    "                old_tables_dict_1[nombre_df] = df.copy()\n",
    "                \n",
    "                # Procesar y limpiar el DataFrame\n",
    "                df_clean = df.copy()\n",
    "                \n",
    "                # Aplicar las funciones de limpieza a una copia del DataFrame\n",
    "                df_clean = limpiar_nombres_columnas(df_clean)\n",
    "                df_clean = ajustar_nombres_columnas(df_clean)\n",
    "                df_clean = drop_rare_caracter_row(df_clean)\n",
    "                df_clean = drop_nan_rows(df_clean)\n",
    "                df_clean = drop_nan_columns(df_clean)\n",
    "                df_clean = reset_index(df_clean)\n",
    "                df_clean = remove_digit_slash(df_clean)\n",
    "                df_clean = replace_var_perc_first_column(df_clean)\n",
    "                df_clean = replace_var_perc_last_columns(df_clean)\n",
    "                df_clean = replace_number_moving_average(df_clean)\n",
    "                df_clean = relocate_last_column(df_clean)\n",
    "                df_clean = clean_first_row(df_clean)\n",
    "                df_clean = find_year_column(df_clean)\n",
    "                year_columns = extract_years(df_clean)\n",
    "                df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "                df_clean = first_row_columns(df_clean)\n",
    "                df_clean = clean_columns_values(df_clean)\n",
    "                df_clean = convert_float(df_clean)\n",
    "                df_clean = replace_set_sep(df_clean)\n",
    "                df_clean = spaces_se_es(df_clean)\n",
    "                df_clean = replace_services(df_clean)\n",
    "                df_clean = rounding_values(df_clean, decimales=1)\n",
    "                \n",
    "                # Añadir la columna 'year' al DataFrame limpio\n",
    "                df_clean.insert(0, 'year', year)\n",
    "                \n",
    "                # Añadir la columna 'id_ns' al DataFrame limpio\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "                \n",
    "                # Obtener la fecha correspondiente de la base de datos\n",
    "                fecha = obtener_fecha(df_clean, engine)\n",
    "                if fecha:\n",
    "                    # Añadir la columna 'date' al DataFrame limpio\n",
    "                    df_clean.insert(2, 'date', fecha)\n",
    "                else:\n",
    "                    print(\"No se encontró fecha en la base de datos para id_ns:\", id_ns, \"y year:\", year)\n",
    "                \n",
    "                # Almacenar DataFrame limpio en old_dataframes_dict_1\n",
    "                old_dataframes_dict_1[nombre_df] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. El dataframe generado para el archivo {csv_file} es: {nombre_df}')\n",
    "                num_dataframes_generados += 1\n",
    "                table_counter += 1  # Incrementar el contador de tabla aquí\n",
    "        \n",
    "        num_csv_procesados += 1  # Incrementar el número de CSVs procesados por cada archivo en la carpeta\n",
    "\n",
    "    return num_csv_procesados, num_dataframes_generados, old_tables_dict_1\n",
    "\n",
    "def procesar_carpetas():\n",
    "    base_folder = r'C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 1'\n",
    "    carpetas = [os.path.join(base_folder, d) for d in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, d)) and re.match(r'\\d{4}', d)]\n",
    "    \n",
    "    old_tables_dict_1 = {}  # Inicializar old_tables_dict_1 aquí\n",
    "    \n",
    "    for carpeta in carpetas:\n",
    "        if carpeta_procesada(carpeta):\n",
    "            print(f\"La carpeta {carpeta} ya ha sido procesada.\")\n",
    "            continue\n",
    "        \n",
    "        num_csv_procesados, num_dataframes_generados, tables_dict_temp = procesar_carpeta(carpeta, engine)\n",
    "        \n",
    "        # Actualizar old_tables_dict_1 con los valores devueltos de procesar_carpeta()\n",
    "        old_tables_dict_1.update(tables_dict_temp)\n",
    "        \n",
    "        registrar_carpeta_procesada(carpeta, num_csv_procesados)\n",
    "\n",
    "        # Preguntar al usuario si desea continuar con la siguiente carpeta\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Para asegurar que la ventana esté en primer plano\n",
    "        \n",
    "        mensaje = f\"Se han generado {num_dataframes_generados} dataframes en la carpeta {carpeta}. ¿Deseas continuar con la siguiente carpeta?\"\n",
    "        continuar = messagebox.askyesno(\"Continuar\", mensaje)\n",
    "        root.destroy()\n",
    "\n",
    "        if not continuar:\n",
    "            print(\"Procesamiento detenido por el usuario.\")\n",
    "            break  # Romper el bucle for si el usuario decide no continuar\n",
    "\n",
    "    print(\"Procesamiento completado para todas las carpetas.\")  # Add a message to indicate completion\n",
    "\n",
    "    return old_tables_dict_1  # Devolver old_tables_dict_1 al final de la función\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Get environment variables\n",
    "    user = os.environ.get('CIUP_SQL_USER')\n",
    "    password = os.environ.get('CIUP_SQL_PASS')\n",
    "    host = os.environ.get('CIUP_SQL_HOST')\n",
    "    port = 5432\n",
    "    database = 'gdp_revisions_datasets'\n",
    "\n",
    "    # Check if all environment variables are defined\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"Some environment variables are missing (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "    # Create connection string\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    old_tables_dict_1 = procesar_carpetas()  # Capturar el valor devuelto de procesar_carpetas()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda07520",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tables_dict_1['ns_03_2010_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataframes_dict_1['ns_03_2010_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e77290",
   "metadata": {},
   "source": [
    "# TABLA 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744448b",
   "metadata": {},
   "source": [
    "# Cargando desde excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d919b7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Substitua 'arquivo.csv' pelo caminho do seu arquivo CSV\n",
    "path = r'C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 1\\table_1\\00_1.csv'\n",
    "\n",
    "# Carrega o arquivo CSV para um DataFrame\n",
    "df_clean = pd.read_csv(path, delimiter=';')\n",
    "\n",
    "# Exibe as primeiras linhas do DataFrame para verificar se os dados foram carregados corretamente\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc75a9b",
   "metadata": {},
   "source": [
    "# Total by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90766688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_total_with_year(df):\n",
    "    # Reemplazar 'TOTAL' con 'AÑO' en la primera fila\n",
    "    df.iloc[0] = df.iloc[0].apply(lambda x: 'AÑO' if \"TOTAL\" in str(x) else x)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10036cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = replace_total_with_year(df_clean)\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774512d6",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab041892",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime\n",
    "import locale\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Establecer la localización en español\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Diccionario para almacenar los DataFrames generados\n",
    "old_dataframes_dict_2 = {}\n",
    "\n",
    "# Ruta del archivo de registro de carpetas procesadas\n",
    "registro_path = 'dataframes_record/old_carpetas_procesadas_2.txt'\n",
    "\n",
    "# Función para corregir los nombres de los meses\n",
    "def corregir_nombre_mes(mes):\n",
    "    meses_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Agrega más mapeos si es necesario para otros nombres de meses\n",
    "    }\n",
    "    return meses_mapping.get(mes, mes)\n",
    "\n",
    "def registrar_carpeta_procesada(carpeta, num_archivos_procesados):\n",
    "    with open(registro_path, 'a') as file:\n",
    "        file.write(f\"{carpeta}:{num_archivos_procesados}\\n\")\n",
    "\n",
    "def carpeta_procesada(carpeta):\n",
    "    if not os.path.exists(registro_path):\n",
    "        return False\n",
    "    with open(registro_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(carpeta):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def obtener_fecha(df, engine):\n",
    "    id_ns = df['id_ns'].iloc[0]\n",
    "    year = df['year'].iloc[0]\n",
    "    query = f\"SELECT date FROM dates_growth_rates WHERE id_ns = '{id_ns}' AND year = '{year}';\"\n",
    "    fecha = pd.read_sql(query, engine)\n",
    "    return fecha.iloc[0, 0] if not fecha.empty else None\n",
    "\n",
    "def procesar_archivo_csv(csv_path, engine):\n",
    "    old_tables_dict_2 = {}  # Diccionario local para cada archivo CSV\n",
    "    table_counter = 1\n",
    "\n",
    "    filename = os.path.basename(csv_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No se encontraron coincidencias para id_ns y year en el nombre del archivo:\", filename)\n",
    "        return None, None, None, None\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(csv_path))[0].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(csv_path, delimiter=';')\n",
    "    \n",
    "    nombre_dataframe = f\"{new_filename}_{table_counter}\"\n",
    "    old_tables_dict_2[nombre_dataframe] = df.copy()\n",
    "\n",
    "    # Aplicar las funciones de limpieza a una copia del DataFrame\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Funciones de limpieza (ajustar según sea necesario)\n",
    "    df_clean = replace_total_with_year(df_clean)\n",
    "    df_clean = drop_nan_rows(df_clean)\n",
    "    year_columns = extract_years(df_clean)\n",
    "    df_clean = roman_arabic(df_clean)\n",
    "    df_clean = fix_duplicates(df_clean)\n",
    "    df_clean = relocate_last_column(df_clean)\n",
    "    df_clean = replace_first_row_nan(df_clean)\n",
    "    df_clean = clean_first_row(df_clean)\n",
    "    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "    df_clean = reset_index(df_clean)\n",
    "    df_clean = first_row_columns(df_clean)\n",
    "    df_clean = clean_columns_values(df_clean)\n",
    "    df_clean = reset_index(df_clean)\n",
    "    df_clean = convert_float(df_clean)\n",
    "    df_clean = replace_set_sep(df_clean)\n",
    "    df_clean = spaces_se_es(df_clean)\n",
    "    df_clean = replace_services(df_clean)\n",
    "    df_clean = rounding_values(df_clean, decimales=1)\n",
    "\n",
    "    # Añadir la columna 'year' al DataFrame limpio\n",
    "    df_clean.insert(0, 'year', year)\n",
    "    \n",
    "    # Añadir la columna 'id_ns' al DataFrame limpio\n",
    "    df_clean.insert(1, 'id_ns', id_ns)\n",
    "    \n",
    "    # Obtener la fecha correspondiente de la base de datos\n",
    "    fecha = obtener_fecha(df_clean, engine)\n",
    "    if fecha:\n",
    "        # Añadir la columna 'date' al DataFrame limpio\n",
    "        df_clean.insert(2, 'date', fecha)\n",
    "    else:\n",
    "        print(\"No se encontró fecha en la base de datos para id_ns:\", id_ns, \"y year:\", year)\n",
    "    \n",
    "    # Almacenar DataFrame limpio en old_dataframes_dict_2\n",
    "    old_dataframes_dict_2[nombre_dataframe] = df_clean\n",
    "\n",
    "    return id_ns, year, old_tables_dict_2\n",
    "\n",
    "def procesar_carpeta(carpeta, engine):\n",
    "    print(f\"Procesando la carpeta {os.path.basename(carpeta)}\")\n",
    "    csv_files = [os.path.join(carpeta, f) for f in os.listdir(carpeta) if f.endswith('.csv')]\n",
    "\n",
    "    num_csv_procesados = 0\n",
    "    num_dataframes_generados = 0\n",
    "\n",
    "    table_counter = 1  # Inicializar el contador de tabla aquí\n",
    "    old_tables_dict_2 = {}  # Declarar old_tables_dict_2 fuera del bucle principal\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        id_ns, year, tables_dict_temp = procesar_archivo_csv(csv_file, engine)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for nombre_df, df in tables_dict_temp.items():\n",
    "                nombre_archivo = os.path.splitext(os.path.basename(csv_file))[0].replace('-', '_')\n",
    "                nombre_df = f\"{nombre_archivo}_{table_counter}\"\n",
    "                \n",
    "                # Almacenar DataFrame sin procesar en old_tables_dict_2\n",
    "                old_tables_dict_2[nombre_df] = df.copy()\n",
    "                \n",
    "                # Procesar y limpiar el DataFrame\n",
    "                df_clean = df.copy()\n",
    "                \n",
    "                # Aplicar las funciones de limpieza a una copia del DataFrame\n",
    "                df_clean = replace_total_with_year(df_clean)\n",
    "                df_clean = drop_nan_rows(df_clean)\n",
    "                year_columns = extract_years(df_clean)\n",
    "                df_clean = roman_arabic(df_clean)\n",
    "                df_clean = fix_duplicates(df_clean)\n",
    "                df_clean = relocate_last_column(df_clean)\n",
    "                df_clean = replace_first_row_nan(df_clean)\n",
    "                df_clean = clean_first_row(df_clean)\n",
    "                df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                df_clean = reset_index(df_clean)\n",
    "                df_clean = first_row_columns(df_clean)\n",
    "                df_clean = clean_columns_values(df_clean)\n",
    "                df_clean = reset_index(df_clean)\n",
    "                df_clean = convert_float(df_clean)\n",
    "                df_clean = replace_set_sep(df_clean)\n",
    "                df_clean = spaces_se_es(df_clean)\n",
    "                df_clean = replace_services(df_clean)\n",
    "                df_clean = rounding_values(df_clean, decimales=1)\n",
    "                \n",
    "                # Añadir la columna 'year' al DataFrame limpio\n",
    "                df_clean.insert(0, 'year', year)\n",
    "                \n",
    "                # Añadir la columna 'id_ns' al DataFrame limpio\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "                \n",
    "                # Obtener la fecha correspondiente de la base de datos\n",
    "                fecha = obtener_fecha(df_clean, engine)\n",
    "                if fecha:\n",
    "                    # Añadir la columna 'date' al DataFrame limpio\n",
    "                    df_clean.insert(2, 'date', fecha)\n",
    "                else:\n",
    "                    print(\"No se encontró fecha en la base de datos para id_ns:\", id_ns, \"y year:\", year)\n",
    "                \n",
    "                # Almacenar DataFrame limpio en old_dataframes_dict_2\n",
    "                old_dataframes_dict_2[nombre_df] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. El dataframe generado para el archivo {csv_file} es: {nombre_df}')\n",
    "                num_dataframes_generados += 1\n",
    "                table_counter += 1  # Incrementar el contador de tabla aquí\n",
    "        \n",
    "        num_csv_procesados += 1  # Incrementar el número de CSVs procesados por cada archivo en la carpeta\n",
    "\n",
    "    return num_csv_procesados, num_dataframes_generados, old_tables_dict_2\n",
    "\n",
    "def procesar_carpetas():\n",
    "    base_folder = r'C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2'\n",
    "    carpetas = [os.path.join(base_folder, d) for d in os.listdir(base_folder) if os.path.isdir(os.path.join(base_folder, d)) and re.match(r'\\d{4}', d)]\n",
    "    \n",
    "    old_tables_dict_2 = {}  # Inicializar old_tables_dict_2 aquí\n",
    "    \n",
    "    for carpeta in carpetas:\n",
    "        if carpeta_procesada(carpeta):\n",
    "            print(f\"La carpeta {carpeta} ya ha sido procesada.\")\n",
    "            continue\n",
    "        \n",
    "        num_csv_procesados, num_dataframes_generados, tables_dict_temp = procesar_carpeta(carpeta, engine)\n",
    "        \n",
    "        # Actualizar old_tables_dict_2 con los valores devueltos de procesar_carpeta()\n",
    "        old_tables_dict_2.update(tables_dict_temp)\n",
    "        \n",
    "        registrar_carpeta_procesada(carpeta, num_csv_procesados)\n",
    "\n",
    "        # Preguntar al usuario si desea continuar con la siguiente carpeta\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Para asegurar que la ventana esté en primer plano\n",
    "        \n",
    "        mensaje = f\"Se han generado {num_dataframes_generados} dataframes en la carpeta {carpeta}. ¿Deseas continuar con la siguiente carpeta?\"\n",
    "        continuar = messagebox.askyesno(\"Continuar\", mensaje)\n",
    "        root.destroy()\n",
    "\n",
    "        if not continuar:\n",
    "            print(\"Procesamiento detenido por el usuario.\")\n",
    "            break  # Romper el bucle for si el usuario decide no continuar\n",
    "\n",
    "    print(\"Procesamiento completado para todas las carpetas.\")  # Add a message to indicate completion\n",
    "\n",
    "    return old_tables_dict_2  # Devolver old_tables_dict_2 al final de la función\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    # Get environment variables\n",
    "    user = os.environ.get('CIUP_SQL_USER')\n",
    "    password = os.environ.get('CIUP_SQL_PASS')\n",
    "    host = os.environ.get('CIUP_SQL_HOST')\n",
    "    port = 5432\n",
    "    database = 'gdp_revisions_datasets'\n",
    "\n",
    "    # Check if all environment variables are defined\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"Some environment variables are missing (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "    # Create connection string\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "    old_tables_dict_2 = procesar_carpetas()  # Capturar el valor devuelto de procesar_carpetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a6ccdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efb3390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tables_dict_2['ns_04_2010_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b05cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataframes_dict_2['ns_32_2010_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9f46c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3de81e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f889c679",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746f82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe8b508",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ef0eaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6f615e2a",
   "metadata": {},
   "source": [
    "# Duplicate table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39a3a37",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6cbc23",
   "metadata": {},
   "source": [
    "# Duplicate table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9840ed1e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Obtener variables de entorno\n",
    "user = os.environ.get('CIUP_SQL_USER')\n",
    "password = os.environ.get('CIUP_SQL_PASS')\n",
    "host = os.environ.get('CIUP_SQL_HOST')\n",
    "port = 5432\n",
    "database = 'gdp_revisions_datasets'\n",
    "\n",
    "# Verificar si todas las variables de entorno están definidas\n",
    "if not all([host, user, password]):\n",
    "    raise ValueError(\"Faltan algunas variables de entorno (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "# Crear la cadena de conexión\n",
    "connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# Crear el motor de SQLAlchemy\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# Definir la consulta SQL para importar datos\n",
    "query = f\"SELECT * FROM old_raw_data_delivered\"\n",
    "\n",
    "# Importar los datos a un DataFrame de pandas\n",
    "df = pd.read_sql(query, engine)\n",
    "\n",
    "# Ruta base donde están las carpetas de años\n",
    "base_path = r\"C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\"\n",
    "\n",
    "# Función para duplicar archivos\n",
    "def duplicate_files(year, df_year, base_path):\n",
    "    year_path = os.path.join(base_path, str(year))\n",
    "    files = sorted([f for f in os.listdir(year_path) if f.endswith('.csv')])\n",
    "\n",
    "    # Obtener los archivos existentes\n",
    "    existing_files = {int(f.split('-')[1]): f for f in files}\n",
    "    \n",
    "    # Obtener el último archivo del año anterior\n",
    "    if year > 1994:\n",
    "        prev_year_path = os.path.join(base_path, str(year - 1))\n",
    "        prev_files = sorted([f for f in os.listdir(prev_year_path) if f.endswith('.csv')])\n",
    "        if prev_files:\n",
    "            last_prev_file = prev_files[-1]\n",
    "            last_prev_id_ns = int(last_prev_file.split('-')[1])\n",
    "        else:\n",
    "            last_prev_file = None\n",
    "            last_prev_id_ns = None\n",
    "    else:\n",
    "        last_prev_file = None\n",
    "        last_prev_id_ns = None\n",
    "\n",
    "    # Inicializar variables para duplicación\n",
    "    last_existing_file = last_prev_file\n",
    "    last_existing_id_ns = last_prev_id_ns\n",
    "\n",
    "    for index, row in df_year.iterrows():\n",
    "        id_ns = row['id_ns']\n",
    "        if row['delivered_2'] == 1:\n",
    "            last_existing_file = existing_files[id_ns]\n",
    "            last_existing_id_ns = id_ns\n",
    "        else:\n",
    "            # Crear nombre del nuevo archivo duplicado\n",
    "            new_file_name = f\"ns-{id_ns:02d}-{year}.csv\"\n",
    "            new_file_path = os.path.join(year_path, new_file_name)\n",
    "\n",
    "            # Duplicar archivo\n",
    "            if last_existing_file:\n",
    "                if last_existing_file in existing_files.values():\n",
    "                    src_file_path = os.path.join(year_path, last_existing_file)\n",
    "                else:\n",
    "                    src_file_path = os.path.join(prev_year_path, last_existing_file)\n",
    "                shutil.copy(src_file_path, new_file_path)\n",
    "                print(f\"Duplicated {last_existing_file} to {new_file_name}\")\n",
    "            else:\n",
    "                print(f\"No existing file to duplicate for {new_file_name}\")\n",
    "\n",
    "# Procesar cada año\n",
    "for year in range(2010, 2013):\n",
    "    df_year = df[df['year'] == year]\n",
    "    duplicate_files(year, df_year, base_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0474e92",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7156504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
