{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127505dd-d5cc-4829-9190-6314ae54b3ca",
   "metadata": {},
   "source": [
    "# New GDP Real-Time Dataset\n",
    "\n",
    "> **Author:** Jason Cruz  \n",
    "  **Last updated:** 11/13/2025  \n",
    "  **Python version:** 3.12  \n",
    "  **Project:** Rationality and Nowcasting on Peruvian GDP Revisions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96357866-58f8-4d8b-b25a-b9b145465322",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Summary\n",
    "Welcome to the **Peruvian GDP Real-Time Dataset (RTD)** construction notebook! This notebook will guide you through the **step-by-step process** of creating your own RTD using GDP revisions from the **Central Reserve Bank of Peru** (BCRP). Whether you are a researcher, policymaker, or analyst, this notebook helps you construct real-time data of monthly GDP growth for Peru, starting from scratch.\n",
    "\n",
    "### What will this notebook help you achieve?\n",
    "1. **Downloading PDFs** from the BCRP Weekly Reports (WR).\n",
    "2. **Generating PDF inputs** by shortening them to focus on key pages containing GDP growth rate tables.\n",
    "3. **Cleaning-up extracted data** to ensure it's usable and building RTD.\n",
    "4. **Concatenating RTD** from different years and frequencies (monthly, quarterly, annual).\n",
    "5. **Updating metadata** for storing base years changes and other revisions-based information.\n",
    "6. **Converting RTD** to releases dataset for econometric analysis.\n",
    "\n",
    "üåê **Main Data Source:** [BCRP Weekly Report](https://www.bcrp.gob.pe/publicaciones/nota-semanal.html) (üì∞ WR, from here on)  \n",
    "For any questions or issues, feel free to reach out via email: [Jason üì®](mailto:jj.cruza@up.edu.pe)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552ce7a-bbdb-4ff2-b798-3bb3b1fcc33e",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Initial Set-up\n",
    "\n",
    "Before preprocessing the new GDP releases data, we need to perform some initial set-up steps:\n",
    "\n",
    "1. üß∞ **Import helper functions** from `gdp_rtd_pipeline.py` that are required for this notebook.\n",
    "2. üõ¢Ô∏è **Connect to the PostgreSQL database** that will contain GDP revisions datasets. _(This step is pending: direct access will be provided via ODBC or other methods, allowing users to connect from any software or programming language.)_\n",
    "3. üìÇ **Create necessary folders** to store inputs, outputs, logs, and screenshots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d9656-700e-461b-99c5-5ad2557ac8e1",
   "metadata": {},
   "source": [
    "> üöß Although the second step (database connection) is pending, the notebook currently works using **flat files (CSV)**. These CSV files will **not be saved in GitHub** as they are included in the `.gitignore` to ensure no data is stored publicly. Users can be confident that no data will be stored on GitHub. The notebook **automatically generates the CSV files**, giving users direct access to the dataset on their own systems. The data is created on the fly and can be saved locally for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7f538-dada-47a6-977d-d420aaf3cb22",
   "metadata": {},
   "source": [
    "### üß∞ Import helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c34e4-662e-43f6-890e-cc307da4da36",
   "metadata": {},
   "source": [
    "This notebook relies on a set of helper functions found in the script `gdp_rtd_pipeline.py`. These functions will be used throughout the notebook, so please ensure you have them ready by running the line of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b7cb8e-8405-457d-a329-2a6cefa17844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from gdp_rtd_pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907046a",
   "metadata": {},
   "source": [
    "> üõ†Ô∏è **Libraries:** Before you begin, please ensure that you have the required libraries installed and imported. See all the libraries you need section by section in `gdp_rtd_pipeline.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c73193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d47b8-5873-426b-b739-e1fc05dcf8e5",
   "metadata": {},
   "source": [
    "**Check out Python information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55588d8e-8df5-406a-8644-e67ff1dcbc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üêç Python Information\n",
      "  Version  : 3.12.1\n",
      "  Compiler : MSC v.1916 64 bit (AMD64)\n",
      "  Build    : ('main', 'Jan 19 2024 15:44:08')\n",
      "  OS       : Windows 10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"üêç Python Information\")\n",
    "print(f\"  Version  : {sys.version.split()[0]}\")\n",
    "print(f\"  Compiler : {platform.python_compiler()}\")\n",
    "print(f\"  Build    : {platform.python_build()}\")\n",
    "print(f\"  OS       : {platform.system()} {platform.release()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b9cd4-2433-4fcd-9da2-05d533b33fd5",
   "metadata": {},
   "source": [
    "### üìÇ Create necessary folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ef8f8",
   "metadata": {},
   "source": [
    "We will start by creating the necessary folders to store the data at various stages of processing. The following code ensures all required directories exist, and if not, it creates them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51762441-7a80-4c30-ac06-0be260372738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter relative path (default='.'):  .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using path: C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\RA\\CIUP\\GDP Revisions\\GitHub\\peru_gdp_revisions\\gdp_revisions_datasets\n",
      "üìÇ new_wr created\n",
      "üìÇ new_wr\\raw created\n",
      "üìÇ new_wr\\input created\n",
      "üìÇ data created\n",
      "üìÇ data\\input created\n",
      "üìÇ data\\output created\n",
      "üìÇ metadata created\n",
      "üìÇ new_wr created\n",
      "üìÇ new_wr\\input created\n",
      "üìÇ record created\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path  # Importing Path module from pathlib to handle file and directory paths in a cross-platform way.\n",
    "\n",
    "# Get current working directory\n",
    "PROJECT_ROOT = Path.cwd()  # Get the current working directory where the notebook is being executed.\n",
    "\n",
    "# User input for folder location\n",
    "user_input = input(\"Enter relative path (default='.'): \").strip() or \".\"  # Prompt user to input the folder path or use the default value \".\"\n",
    "target_path = (PROJECT_ROOT / user_input).resolve()  # Combine the project root directory with user input to get the full target path.\n",
    "\n",
    "# Create the necessary directories if they don't already exist\n",
    "target_path.mkdir(parents=True, exist_ok=True)  # Creates the target folder and any necessary parent directories.\n",
    "print(f\"Using path: {target_path}\")  # Print out the path being used for confirmation.\n",
    "\n",
    "# Define paths for saving data and PDFs\n",
    "pdf_folder = 'new_weekly_reports'  # This folder will store the new Weekly Reports (post-2013), which are in PDF format.\n",
    "raw_pdf_subfolder = os.path.join(pdf_folder, 'raw')  # Subfolder for saving the raw PDFs exactly as downloaded from the BCRP website.\n",
    "input_pdf_subfolder = os.path.join(pdf_folder, 'input')  # Subfolder for saving reduced PDFs that contain only the selected pages with GDP growth tables.\n",
    "\n",
    "data_folder = 'data'  # Main folder for storing all data files.\n",
    "input_data_subfolder = os.path.join(data_folder, 'input')  # Folder for storing preprocessed data throughout all periods (NEW+OLD data).\n",
    "output_data_subfolder = os.path.join(data_folder, 'output')  # Folder for storing final RTD datasets and releases after processing.\n",
    "\n",
    "# Create all folders if they don't exist yet\n",
    "for folder in [pdf_folder, raw_pdf_subfolder, input_pdf_subfolder, data_folder, input_data_subfolder, output_data_subfolder]:\n",
    "    os.makedirs(folder, exist_ok=True)  # Create each folder in the list if it doesn't already exist.\n",
    "    print(f\"üìÇ {folder} created\")  # Print confirmation for each folder created.\n",
    "\n",
    "# Additional folders for metadata, records, and alert tracking\n",
    "metadata_folder = 'metadata'  # Folder for storing metadata files like wr_metadata.csv.\n",
    "record_folder = 'record'  # Folder for storing .txt files that track the files already processed to avoid reprocessing them.\n",
    "alert_track_folder = 'alert_track'  # Folder for saving download notifications and alerts.\n",
    "\n",
    "# Create additional required folders\n",
    "for folder in [metadata_folder, pdf_folder, input_pdf_subfolder, record_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)  # Create the additional folders if they don't exist.\n",
    "    print(f\"üìÇ {folder} created\")  # Print confirmation for each of these additional folders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f3192",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Downloading PDFs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98250a64",
   "metadata": {},
   "source": [
    "The **BCRP Weekly Report** is our primary source of data collection for constructing the Peruvian GDP Real-Time Dataset (RTD). This report, published weekly by the **Central Reserve Bank of Peru (BCRP)**, is an official document that contains critical macroeconomic statistics, including GDP growth rates.\n",
    "\n",
    "The two main tables we focus on in this project are:\n",
    "- **Table 1:** Monthly GDP growth rates (real GDP, 12-month percentage changes)\n",
    "- **Table 2:** Quarterly/Annual GDP growth rates (real GDP, 12-month percentage changes)\n",
    "\n",
    "This section automates the process of downloading the **BCRP Weekly Report PDFs** directly from the official BCRP website, ensuring that we can collect the most up-to-date data for our analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è What the Scraper Bot Does:\n",
    "\n",
    "1. **Opens the official BCRP Weekly Report page** at [this link](https://www.bcrp.gob.pe/publicaciones/nota-semanal.html).\n",
    "2. **Finds and collects all PDF links** for the reports.\n",
    "3. **Downloads the PDFs** in chronological order (from oldest to newest).\n",
    "4. Optionally, plays a **notification sound** after every batch of downloads.\n",
    "5. **Organizes** the downloaded PDFs into year-based folders.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ö†Ô∏è Important Notes:\n",
    "\n",
    "- **CAPTCHA Handling**: If a CAPTCHA appears during the download process, you'll need to manually solve it in the browser window and then **re-run the script**. The script cannot bypass CAPTCHA verification.\n",
    "  \n",
    "- **Automatic WebDriver Management**: This script uses `webdriver-manager` to automatically handle browser drivers (by default, it uses Chrome). **No need to manually download ChromeDriver or GeckoDriver**. If you wish to use a different browser, you can modify the `browser` parameter in the `init_driver()` function.\n",
    "  \n",
    "- **Custom Notification Sound**: If you'd like to receive notifications when each batch of downloads finishes, you can place your own MP3 file in the `alert_track` folder. Here are some free sources for MP3 files:\n",
    "  - [Pixabay Audio](https://pixabay.com/music/) üéµ\n",
    "  - [FreeSound](https://freesound.org/) üé∂\n",
    "  - [FreePD](https://freepd.com/) üéº\n",
    "\n",
    "---\n",
    "\n",
    "### üîß Run the Scraper Bot\n",
    "\n",
    "Below, you can run the **scraper bot** to download the BCRP Weekly Reports automatically:\n",
    "\n",
    "```python\n",
    "# Run the function to start the scraper bot\n",
    "pdf_downloader(\n",
    "    bcrp_url = \"https://www.bcrp.gob.pe/publicaciones/nota-semanal.html\",  # URL of the BCRP Weekly Report\n",
    "    raw_pdf_folder = raw_pdf_subfolder,  # Folder to save the raw downloaded PDFs\n",
    "    download_record_folder = record_folder,  # Folder to store download logs\n",
    "    download_record_txt = '1_downloaded_pdfs.txt',  # Record of downloaded PDFs\n",
    "    alert_track_folder = alert_track_folder,  # Folder for MP3 alert sound\n",
    "    max_downloads = 60,  # Maximum number of PDFs to download\n",
    "    downloads_per_batch = 6,  # Number of PDFs to download per batch\n",
    "    headless = False  # Run in browser window (set to True for headless mode)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d95c04",
   "metadata": {},
   "source": [
    "### üì• Scraper Bot for BCRP Weekly Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0199bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the function to start the scraper bot\n",
    "pdf_downloader(\n",
    "    bcrp_url = \"https://www.bcrp.gob.pe/publicaciones/nota-semanal.html\",\n",
    "    raw_pdf_folder = raw_pdf_subfolder,\n",
    "    download_record_folder = record_folder,\n",
    "    download_record_txt = '1_downloaded_pdfs.txt',\n",
    "    alert_track_folder = alert_track_folder,\n",
    "    max_downloads = 60,\n",
    "    downloads_per_batch = 6, \n",
    "    headless = False \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773491f5-fd62-497b-9f94-59e5095c5659",
   "metadata": {},
   "source": [
    "Probably the üì∞ WR were downloaded in a single folder, but we would like the WR to be sorted by years. The following code sorts the PDFs into subfolders (years) for us by placing each WR according to the year of its publication. This happens in the **\"blink of an eye\"**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3854039b-4e01-47ea-8a6e-eae871829d78",
   "metadata": {},
   "source": [
    "Check your raw_pdf_subfolder out, every PDF should be placed in a year folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee016a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the directory\n",
    "files = os.listdir(raw_pdf_subfolder)\n",
    "\n",
    "# Call the function to organize files\n",
    "organize_files_by_year(raw_pdf_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574b482a-b33d-4059-b4a2-805ba4612fd8",
   "metadata": {},
   "source": [
    "# WR-08-2017"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a626509-2142-4de1-ba7f-9e47b7a8c81a",
   "metadata": {},
   "source": [
    "This  is crucial for the upcoming steps, specially for the section 3, cleansing. If -in the future- you enconuter some issues by executing cleaing it is likely to atributte to the pdf nature. IN that case, you can return to this code to replace defectiv pdfs for those convinient ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5d75a9-308b-4fa1-848a-9771fcffbb1b",
   "metadata": {},
   "source": [
    "Don't worry about it..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ad4344-deba-476d-91e7-6871c6ba4996",
   "metadata": {},
   "source": [
    "T√∫ puedes hacer lo mismo si te enfrentas a un inconveniente similar. Incluso puedes descargar los casos excepecionales de WR de un mismo mes y reemplazar los defectuosos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e956de-ead1-4439-a3c5-bab8aeb75a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace specific defective PDFs (friendly outputs with icons)\n",
    "replace_defective_pdfs(\n",
    "    items=[\n",
    "        (\"2017\", \"ns-08-2017.pdf\", \"ns-07-2017\"), # Enter the year (folder) that contains the defective PDF, the defective PDF, and the new chosen PDF \n",
    "        (\"2019\", \"ns-23-2019.pdf\", \"ns-22-2019\"), # The same one above\n",
    "    ],\n",
    "    root_folder=input_pdf_subfolder, # base folder with /2017, /2019, ...\n",
    "    record_folder=record_folder, # folder with new_downloaded_pdfs.txt\n",
    "    download_record_txt = '1_downloaded_pdfs.txt',\n",
    "    quarantine=os.path.join(input_pdf_subfolder, \"_quarantine\")  # set to None to delete instead\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d24d2",
   "metadata": {},
   "source": [
    "## 2. Generating PDF inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e666f310",
   "metadata": {},
   "source": [
    "Now that we have downloaded the üì∞ WR from the Central Bank, we should know that each of these files has more than 100 pages, but not all of them contain the information required for this project.\n",
    "\n",
    "All we really want is a couple of pages from each üì∞ WR, one for **Table 1** (monthly real GDP growth) and one for **Table 2** (annual and quarterly real GDP growth). The code below is executed to maintain the **two key pages** with both tables of each PDF plus the cover page that contains the information that helps us identify one üì∞ WR from another such as its date of publication and serial number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6af50-3b5b-44f2-859a-3b37d4b57495",
   "metadata": {},
   "source": [
    "_quarentine will be discard of the input PDF generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to generate trimmed PDFs for input\n",
    "pdf_input_generator(\n",
    "    raw_pdf_folder = raw_pdf_subfolder,\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    input_pdf_record_folder = record_folder,\n",
    "    input_pdf_record_txt = '2_generated_input_pdfs.txt',\n",
    "    keywords = [\"ECONOMIC SECTORS\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643079a",
   "metadata": {},
   "source": [
    "Again, probably the WR (PDF files, now of few pages) were stored in disorder in the `input_pdf_folder` folder. The following code sorts the PDFs into subfolders (years) by placing each WR (which now includes only the key tables) according to the year of its publication. This happens in the **\"blink of an eye\"**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the directory\n",
    "files = os.listdir(input_pdf_subfolder)\n",
    "\n",
    "# Call the function to organize files\n",
    "organize_files_by_year(input_pdf_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e1e92",
   "metadata": {},
   "source": [
    "## 3. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100857d4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "Since we already have the PDFs <span style=\"font-size: 24px;\">&#128462;</span> with just the tables required for this project, we can start extracting them. Then we can proceed with data cleaning.\n",
    "</p>  \n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357318e8",
   "metadata": {},
   "source": [
    "### 3.2 Extracting tables and data cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea58b1c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The main library used for extracting tables from PDFs <span style=\"font-size: 24px;\">&#128462;</span> is <code>pdfplumber</code>. You can review the official documentation by clicking <a href=\"https://github.com/jsvine/pdfplumber\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">here</a>.\n",
    "</p>\n",
    "    \n",
    "<p>     \n",
    "    The functions in <b>Section 3</b> of the <code>\"new_gdp_datasets_functions.py\"</code> script were built to deal with each of these issues. An interesting exercise is to compare the original tables (the ones in the PDF <span style=\"font-size: 24px;\">&#128462;</span>) and the cleaned tables (by the cleanup codes below). Thus, the cleanup codes for <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a> and <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a> generates two dictionaries, the first one stores the raw tables; that is, the original tables from the PDF <span style=\"font-size: 24px;\">&#128462;</span> extracted by the <code>pdfplumber</code> library, while the second dictionary stores the fully cleaned tables.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070fb47",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    The code iterates through each PDF <span style=\"font-size: 24px;\">&#128462;</span> and extracts the two required tables from each. The extracted information is then transformed into dataframes and the columns and values are cleaned up to conform to Python conventions (pythonic).\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436c2d1",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.2.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 1.</span> Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65139cc2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The basic criterion to start extracting tables is to use keywords (sufficient condition). I mean, tables containing the following keywords meet the requirements to be extracted.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bffcd08-7763-4eed-ad99-d3bce3644f90",
   "metadata": {},
   "source": [
    "Si por alguna raz√≥n ejecutas el c√≥digo de la secci√≥n 3 y no continuas ejecutando la secci√≥n subsecuente, puedes estar tranquilo de que un registro los guard√≥. La pr√≥xima vez que visite este script basta con empezar desde esta secci√≥n 3 (eliminando el txt) para generar los dataframes que no se guardaron en ningun lado, estos son insumos esenciales para la secci√≥n 4. Alternativamente puede guardar todos los dataframes generados en una carpeta como respaldo y empezar desde la secci√≥n 4 carg√°ndolos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4aabed-81df-4d47-af89-ab1fc70f6f0c",
   "metadata": {},
   "source": [
    "\n",
    "If you want the runners to *also* write the cleaned dicts out to a single combined Parquet/CSV per table (alongside the per-WR files), I can add that as an optional flag (`persist_combined=True`) without changing the defaults.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7075989-80c9-42f6-8a9e-df0728e67ace",
   "metadata": {},
   "source": [
    "# If you will run until this section and you are planning to go back and retake from section 4, enter \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021e356-54c3-4b4e-8e2e-666578a86b54",
   "metadata": {},
   "source": [
    "# Table 1 data into *row-based* vintage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659e030-643c-4894-87a8-b85b1cfbf408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base folder for saving vintages data (.csv)\n",
    "data_folder = 'data'\n",
    "\n",
    "# Define subfolder for saving \n",
    "input_data_subfolder = os.path.join(data_folder, 'input')\n",
    "\n",
    "# Define subfolder for saving \n",
    "output_data_subfolder = os.path.join(data_folder, 'output')\n",
    "\n",
    "# Create all required folders (if they do not already exist) and confirm creation\n",
    "for folder in [data_folder, input_data_subfolder, output_data_subfolder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"üìÇ {folder} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2388f-faa2-4eb7-abce-8b61e8d7b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1, clean_1, vintages_1 = new_table_1_cleaner(\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = 'new_created_rtd_tab_1.txt',\n",
    "    persist = True,\n",
    "    persist_folder = input_data_subfolder,\n",
    "    pipeline_version = \"s3.0.0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3004d-e825-41a2-8247-81fa5cceec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ecc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1392888-be8b-4b95-98cf-ebd71d34dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a4fe9-54cc-48b6-901c-b0b5396fe68d",
   "metadata": {},
   "source": [
    "# Checking the cleaning version out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88e1dd-8c85-481b-9a42-3d3b8174cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df100 = vintages_1[\"ns_04_2022_1\"]\n",
    "print(df100.attrs)\n",
    "# {'pipeline_version': 's3.0.0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48b6ed-b2ce-44cd-b19e-930ff305f8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8229f-e230-494f-97b1-bcf4e6a9ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1[\"ns_04_2022_1\"].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef214918-2835-4738-8ec0-5ea98e3e2d8d",
   "metadata": {},
   "source": [
    "# Table 2 data into *row-based* vintage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcfe1b-9f63-4850-937f-ca582be3ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_2, clean_2, vintages_2 = new_table_2_cleaner(\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = 'new_created_rtd_tab_2.txt',\n",
    "    persist = True,\n",
    "    persist_folder = input_data_subfolder,\n",
    "    pipeline_version = \"s3.0.0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb0dd4-9e7e-4255-95dd-5fe8175be6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2386c0-bf54-4d0a-b67d-97352ad8203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df200 = vintages_2[\"ns_04_2022_2\"]\n",
    "print(df200.attrs)\n",
    "# {'pipeline_version': 's3.0.0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d77e3-f8f3-4c31-a25e-cf3af14adae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2c580-8454-45c8-902f-11f4bfda68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_2[\"ns_04_2022_1\"].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8989d65",
   "metadata": {},
   "source": [
    "## 4. Concatenating RTD across years by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfeae0-b5b0-4629-855a-a5556a43465a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ebedad3-c21c-4d63-85d5-b0c3bcfeba7a",
   "metadata": {},
   "source": [
    "**Connect to the PostgreSQL database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30582cc-ab70-4aba-b054-02fb48757b40",
   "metadata": {},
   "source": [
    "The following function will establish a connection to the `gdp_revisions_datasets` database in `PostgreSQL`. The **input data** used in this jupyter notebook will be loaded from this `PostgreSQL` database, and similarly, all **output data** generated by this jupyter notebook will be stored in that database. Ensure that you set the necessary parameters to access the server once you have obtained the required permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad90ec-db3c-4e20-a1d2-6d09c0779170",
   "metadata": {},
   "source": [
    "> üí° **Tip:** To request permissions, please email [Jason üì®](mailto:jj.cruza@alum.up.edu.pe)  \n",
    "> ‚ö†Ô∏è **Warning:** Make sure you have set your SQL credentials as environment variables before proceeding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da345bbe-0d12-4340-9275-938bfef26fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b60634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlalchemy_engine(database=\"gdp_revisions_datasets\", port=5432):\n",
    "    \"\"\"\n",
    "    Create an SQLAlchemy engine to connect to the PostgreSQL database.\n",
    "    \n",
    "    Environment Variables Required:\n",
    "        CIUP_SQL_USER: SQL username\n",
    "        CIUP_SQL_PASS: SQL password\n",
    "        CIUP_SQL_HOST: SQL host address\n",
    "\n",
    "    Args:\n",
    "        database (str): Name of the database. Default is 'gdp_revisions_datasets'.\n",
    "        port (int): Port number. Default is 5432.\n",
    "\n",
    "    Returns:\n",
    "        engine (sqlalchemy.engine.Engine): SQLAlchemy engine object.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If required environment variables are missing.\n",
    "\n",
    "    Example:\n",
    "        engine = create_sqlalchemy_engine()\n",
    "    \"\"\"\n",
    "    user = os.environ.get('CIUP_SQL_USER')\n",
    "    password = os.environ.get('CIUP_SQL_PASS')\n",
    "    host = os.environ.get('CIUP_SQL_HOST')\n",
    "\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"‚ùå Missing environment variables: CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS\")\n",
    "\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    print(f\"üîó Connected to PostgreSQL database: {database} at {host}:{port}\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76e853-8dc9-45e6-9f30-cde33dd3966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_sqlalchemy_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958b6af-25e7-4ec3-9d1d-c436bed32709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e4426-8320-4dfe-bf4e-fb3ca1d211c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1 = concatenate_table_1(\n",
    "    input_data_subfolder=input_data_subfolder,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=\"4_concatenated_rtd_tab_1.txt\",\n",
    "    persist=True,\n",
    "    persist_folder=output_data_subfolder,\n",
    "    csv_file_label=\"monthly_gdp_rtd.csv\",   # your custom name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c00c29-942f-49a9-9c44-96a80b9f6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a63583-7b4f-4d38-9128-227128066754",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfcc1c0-c027-4084-af58-91d042df0cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c411a38-f585-4c9d-83d6-19c5bcff89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_2 = concatenate_table_2(\n",
    "    input_data_subfolder=input_data_subfolder,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=\"4_concatenated_rtd_tab_2.txt\",\n",
    "    persist=True,\n",
    "    persist_folder=output_data_subfolder,\n",
    "    csv_file_label=\"quarterly_annual_gdp_rtd.csv\",  # your custom name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d6f6a-a5e7-431d-a512-4eb4fb7a1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb546a-6b80-4c88-a3d1-672c972aabcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecce1c-ffee-4f3b-9723-91f85a2ae9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57c55f-4ffd-4402-b06e-3c7c3c407191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552a123-c9f8-4bee-a035-72fa78b73dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c5741-7555-4fa0-b4b0-22596446ff6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5155fa2-5dc2-41fc-afce-aaed1a104f76",
   "metadata": {},
   "source": [
    "## 5. Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b2503-e10e-4aef-ad23-5f48235e6293",
   "metadata": {},
   "source": [
    "### Revision Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210bbb1-dae3-4daa-84b8-4596a9017013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base folder for saving all digital PDFs\n",
    "metadata_folder = 'metadata'\n",
    "\n",
    "# Define base folder for saving all digital PDFs\n",
    "pdf_folder = 'pdf'\n",
    "\n",
    "# Define subfolder for saving reduced PDFs containing only selected pages with GDP growth tables (monthly, quarterly, and annual frequencies)\n",
    "input_pdf_subfolder = os.path.join(pdf_folder, 'input')\n",
    "\n",
    "# Define folder for saving .txt files with download and dataframe record\n",
    "record_folder = 'record'\n",
    "\n",
    "# Create all required folders (if they do not already exist) and confirm creation\n",
    "for folder in [metadata_folder, pdf_folder, input_pdf_subfolder, record_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"üìÇ {folder} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35972c04-3b3d-434d-8ae2-718b460a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base_year_list for mapping base years (modify or extend this list as needed)\n",
    "base_year_list = [\n",
    "    {\"year\": 1994, \"wr\": 1, \"base_year\": 1990},\n",
    "    {\"year\": 2000, \"wr\": 28, \"base_year\": 1994},\n",
    "    {\"year\": 2014, \"wr\": 11, \"base_year\": 2007},\n",
    "    {\"year\": 2022, \"wr\": 20, \"base_year\": 2019},\n",
    "    # Add more mappings if needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dba404-f4e5-495c-adf1-7714fb3ab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to update the metadata\n",
    "updated_df = update_metadata(\n",
    "    metadata_folder = metadata_folder,\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = \"wr_metadata.txt\",\n",
    "    wr_metadata_csv = \"wr_metadata.csv\",\n",
    "    base_year_list = base_year_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730862b-944b-47fa-b4a3-9ef75c43607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.iloc[-30:]   # last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed0066-cbbc-467d-b5c3-f55faf8c68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_df[\"benchmark_revision\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f17c6-aa9e-4453-860a-5e9f6169778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_df[\"base_year\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fd435-5ae3-4018-b80d-1ca3d32aa378",
   "metadata": {},
   "source": [
    "### 5.1 Generating adjusted RTDs by removing revisions affected by base years (based on metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13eabb9-af86-41e9-a3f4-ab9cb9183660",
   "metadata": {},
   "source": [
    "# Drop base year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc92104-cfd4-4466-9d9f-2b1886d014b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_year_list_2 = [\n",
    "    \"2000m7\",   # 1990 -> 1994\n",
    "    \"2014m3\",   # 1994 -> 2007\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1cbc5-64b0-45e1-952e-37642dabd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process both monthly and quarterly GDP files and save them with new names\n",
    "adjusted_rtd = apply_base_year_sentinel(\n",
    "    base_year_list=base_year_list_2,\n",
    "    sentinel=-999999.0,\n",
    "    output_data_subfolder=output_data_subfolder,\n",
    "    csv_file_labels=[\"monthly_gdp_rtd.csv\", \"quarterly_annual_gdp_rtd.csv\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e3ccf-dd44-48f5-97e5-61d7b9605efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the processed data (adjusted CSV files)\n",
    "adjusted_monthly_rtd = adjusted_rtd[\"by_adjusted_monthly_gdp_rtd.csv\"]\n",
    "adjusted_quarterly_rtd = adjusted_rtd[\"by_adjusted_quarterly_annual_gdp_rtd.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779bf6b-ef41-43dd-aeb1-6775ed332462",
   "metadata": {},
   "source": [
    "### 5.2 Generating benchmark RTD for revisions affected by benchmarking procedures (based on metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f884c94-dd2b-4a5d-b2f8-745bda1c43f3",
   "metadata": {},
   "source": [
    "# Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3784e9-9c97-4157-8d97-334c6cdb27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_file_labels = [\n",
    "    \"monthly_gdp_rtd\",\n",
    "    \"quarterly_annual_gdp_rtd\",\n",
    "    \"by_adjusted_monthly_gdp_rtd\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_rtd\"\n",
    "]\n",
    "benchmark_dataset_csv = [\n",
    "    \"monthly_gdp_benchmark\",\n",
    "    \"quarterly_annual_gdp_benchmark\",\n",
    "    \"by_adjusted_monthly_gdp_benchmark\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_benchmark\"\n",
    "]\n",
    "record_txt = \"_converted_to_benchmark.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177506c-ac9e-4ccb-967d-9bda6e786dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr_metadata_csv = \"wr_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e6e45-5a0e-4c58-9fb8-0e3c9da96b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = convert_to_benchmark_dataset(\n",
    "    output_data_subfolder=output_data_subfolder,\n",
    "    csv_file_labels=csv_file_labels,\n",
    "    metadata_folder=metadata_folder,\n",
    "    wr_metadata_csv=wr_metadata_csv,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=record_txt,\n",
    "    benchmark_dataset_csv=benchmark_dataset_csv\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57304e-8925-4b4d-a32b-155d09c473da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a los resultados procesados\n",
    "processed_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948e9eb-b23a-4d53-a775-ee29e31f1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets['monthly_gdp_benchmark']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb74e8-7f22-4756-96ea-eb86a2aa400e",
   "metadata": {},
   "source": [
    "## 6. Releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b4c9c-f988-44f1-8c94-8ae09a791ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_labels = [\n",
    "    \"monthly_gdp_rtd\",\n",
    "    \"quarterly_annual_gdp_rtd\",\n",
    "    \"by_adjusted_monthly_gdp_rtd\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_rtd\",\n",
    "    \"monthly_gdp_benchmark\",\n",
    "    \"quarterly_annual_gdp_benchmark\",\n",
    "    \"by_adjusted_monthly_gdp_benchmark\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_benchmark\"\n",
    "]\n",
    "releases_dataset_csv = [\n",
    "    \"monthly_gdp_releases\",\n",
    "    \"quarterly_annual_gdp_releases\",\n",
    "    \"by_adjusted_monthly_gdp_releases\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_releases\",\n",
    "    \"monthly_gdp_benchmark_releases\",\n",
    "    \"quarterly_annual_gdp_benchmark_releases\",\n",
    "    \"by_adjusted_monthly_gdp_benchmark_releases\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_benchmark_releases\"\n",
    "]\n",
    "record_txt = \"5_converted_to_releases.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d86a426-4e03-48b3-98a4-26f8f7f16395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the conversion function\n",
    "releases_df = convert_to_releases_dataset(\n",
    "    output_data_subfolder=output_data_subfolder,\n",
    "    csv_file_labels=csv_file_labels,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=record_txt,\n",
    "    releases_dataset_csv=releases_dataset_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c124a3-8746-4936-ad91-2484ecc8b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the converted releases dataset for \"monthly_gdp_releases\"\n",
    "releases_df[\"by_adjusted_monthly_gdp_releases\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c0cc0-7d08-4399-8470-1746d6a169d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def11acf-f107-4238-bd60-002bbe016972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
