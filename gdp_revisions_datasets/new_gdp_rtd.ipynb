{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127505dd-d5cc-4829-9190-6314ae54b3ca",
   "metadata": {},
   "source": [
    "# New GDP Real-Time Dataset\n",
    "\n",
    "> **Author:** Jason Cruz  \n",
    "  **Last updated:** 11/13/2025  \n",
    "  **Python version:** 3.12  \n",
    "  **Project:** Rationality and Nowcasting on Peruvian GDP Revisions  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96357866-58f8-4d8b-b25a-b9b145465322",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìå Summary\n",
    "Welcome to the **Peruvian GDP Real-Time Dataset (RTD)** construction notebook! This notebook will guide you through the **step-by-step process** of creating your own RTD using GDP revisions from the **Central Reserve Bank of Peru** (BCRP). Whether you are a researcher, policymaker, or analyst, this notebook helps you construct real-time data of monthly GDP growth for Peru, starting from scratch.\n",
    "\n",
    "### What will this notebook help you achieve?\n",
    "1. **Downloading PDFs** from the BCRP Weekly Reports (WR).\n",
    "2. **Generating PDF inputs** by shortening them to focus on key pages containing GDP growth rate tables.\n",
    "3. **Cleaning-up extracted data** to ensure it's usable and building RTD.\n",
    "4. **Concatenating RTD** from different years and frequencies (monthly, quarterly, annual).\n",
    "5. **Updating metadata** for storing base years changes and other revisions-based information.\n",
    "6. **Converting RTD** to releases dataset for econometric analysis.\n",
    "\n",
    "üåê **Main Data Source:** [BCRP Weekly Report](https://www.bcrp.gob.pe/publicaciones/nota-semanal.html) (üì∞ WR, from here on)  \n",
    "For any questions or issues, feel free to reach out via email: [Jason üì®](mailto:jj.cruza@up.edu.pe)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a552ce7a-bbdb-4ff2-b798-3bb3b1fcc33e",
   "metadata": {},
   "source": [
    "### ‚öôÔ∏è Initial Set-up\n",
    "\n",
    "Before preprocessing the new GDP releases data, we need to perform some initial set-up steps:\n",
    "\n",
    "1. üß∞ **Import helper functions** from `gdp_rtd_pipeline.py` that are required for this notebook.\n",
    "2. üõ¢Ô∏è **Connect to the PostgreSQL database** that will contain GDP revisions datasets. _(This step is pending: direct access will be provided via ODBC or other methods, allowing users to connect from any software or programming language.)_\n",
    "3. üìÇ **Create necessary folders** to store inputs, outputs, logs, and screenshots.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73d9656-700e-461b-99c5-5ad2557ac8e1",
   "metadata": {},
   "source": [
    "> üöß Although the second step (database connection) is pending, the notebook currently works using **flat files (CSV)**. These CSV files will **not be saved in GitHub** as they are included in the `.gitignore` to ensure no data is stored publicly. Users can be confident that no data will be stored on GitHub. The notebook **automatically generates the CSV files**, giving users direct access to the dataset on their own systems. The data is created on the fly and can be saved locally for further use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e7f538-dada-47a6-977d-d420aaf3cb22",
   "metadata": {},
   "source": [
    "### üß∞ Import helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476c34e4-662e-43f6-890e-cc307da4da36",
   "metadata": {},
   "source": [
    "This notebook relies on a set of helper functions found in the script `gdp_rtd_pipeline.py`. These functions will be used throughout the notebook, so please ensure you have them ready by running the line of code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b7cb8e-8405-457d-a329-2a6cefa17844",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from gdp_rtd_pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4907046a",
   "metadata": {},
   "source": [
    "> üõ†Ô∏è **Libraries:** Before you begin, please ensure that you have the required libraries installed and imported. See all the libraries you need section by section in `gdp_rtd_pipeline.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7c73193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42d47b8-5873-426b-b739-e1fc05dcf8e5",
   "metadata": {},
   "source": [
    "**Check out Python information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55588d8e-8df5-406a-8644-e67ff1dcbc65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üêç Python Information\n",
      "  Version  : 3.12.1\n",
      "  Compiler : MSC v.1916 64 bit (AMD64)\n",
      "  Build    : ('main', 'Jan 19 2024 15:44:08')\n",
      "  OS       : Windows 10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"üêç Python Information\")\n",
    "print(f\"  Version  : {sys.version.split()[0]}\")\n",
    "print(f\"  Compiler : {platform.python_compiler()}\")\n",
    "print(f\"  Build    : {platform.python_build()}\")\n",
    "print(f\"  OS       : {platform.system()} {platform.release()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b9cd4-2433-4fcd-9da2-05d533b33fd5",
   "metadata": {},
   "source": [
    "### üìÇ Create necessary folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ef8f8",
   "metadata": {},
   "source": [
    "We will start by creating the necessary folders to store the data at various stages of processing. The following code ensures all required directories exist, and if not, it creates them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51762441-7a80-4c30-ac06-0be260372738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter relative path (default='.'):  .\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using path: C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\RA\\CIUP\\GDP Revisions\\GitHub\\peru_gdp_revisions\\gdp_revisions_datasets\n",
      "üìÇ new_wr created\n",
      "üìÇ new_wr\\raw created\n",
      "üìÇ new_wr\\input created\n",
      "üìÇ data created\n",
      "üìÇ data\\input created\n",
      "üìÇ data\\output created\n",
      "üìÇ metadata created\n",
      "üìÇ new_wr created\n",
      "üìÇ new_wr\\input created\n",
      "üìÇ record created\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path  # Importing Path module from pathlib to handle file and directory paths in a cross-platform way.\n",
    "\n",
    "# Get current working directory\n",
    "PROJECT_ROOT = Path.cwd()  # Get the current working directory where the notebook is being executed.\n",
    "\n",
    "# User input for folder location\n",
    "user_input = input(\"Enter relative path (default='.'): \").strip() or \".\"  # Prompt user to input the folder path or use the default value \".\"\n",
    "target_path = (PROJECT_ROOT / user_input).resolve()  # Combine the project root directory with user input to get the full target path.\n",
    "\n",
    "# Create the necessary directories if they don't already exist\n",
    "target_path.mkdir(parents=True, exist_ok=True)  # Creates the target folder and any necessary parent directories.\n",
    "print(f\"Using path: {target_path}\")  # Print out the path being used for confirmation.\n",
    "\n",
    "# Define paths for saving data and PDFs\n",
    "pdf_folder = 'new_weekly_reports'  # This folder will store the new Weekly Reports (post-2013), which are in PDF format.\n",
    "raw_pdf_subfolder = os.path.join(pdf_folder, 'raw')  # Subfolder for saving the raw PDFs exactly as downloaded from the BCRP website.\n",
    "input_pdf_subfolder = os.path.join(pdf_folder, 'input')  # Subfolder for saving reduced PDFs that contain only the selected pages with GDP growth tables.\n",
    "\n",
    "data_folder = 'data'  # Main folder for storing all data files.\n",
    "input_data_subfolder = os.path.join(data_folder, 'input')  # Folder for storing preprocessed data throughout all periods (NEW+OLD data).\n",
    "output_data_subfolder = os.path.join(data_folder, 'output')  # Folder for storing final RTD datasets and releases after processing.\n",
    "\n",
    "# Create all folders if they don't exist yet\n",
    "for folder in [pdf_folder, raw_pdf_subfolder, input_pdf_subfolder, data_folder, input_data_subfolder, output_data_subfolder]:\n",
    "    os.makedirs(folder, exist_ok=True)  # Create each folder in the list if it doesn't already exist.\n",
    "    print(f\"üìÇ {folder} created\")  # Print confirmation for each folder created.\n",
    "\n",
    "# Additional folders for metadata, records, and alert tracking\n",
    "metadata_folder = 'metadata'  # Folder for storing metadata files like wr_metadata.csv.\n",
    "record_folder = 'record'  # Folder for storing .txt files that track the files already processed to avoid reprocessing them.\n",
    "alert_track_folder = 'alert_track'  # Folder for saving download notifications and alerts.\n",
    "\n",
    "# Create additional required folders\n",
    "for folder in [metadata_folder, pdf_folder, input_pdf_subfolder, record_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)  # Create the additional folders if they don't exist.\n",
    "    print(f\"üìÇ {folder} created\")  # Print confirmation for each of these additional folders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41289f95-c398-4c99-843f-e7ba43229f7b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622f3192",
   "metadata": {},
   "source": [
    "## 1. Downloading PDFs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32d3c8-b2d6-4494-9c5f-6e764ab2bbd8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98250a64",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "The **BCRP Weekly Report** is our primary source of data collection for constructing the Peruvian GDP Real-Time Dataset (RTD). This report, published weekly by the **Central Reserve Bank of Peru (BCRP)**, is an official document that contains critical macroeconomic statistics, including GDP growth rates.\n",
    "\n",
    "The two main tables we focus on in this project are:\n",
    "- **Table 1:** Monthly GDP growth rates (real GDP, 12-month percentage changes)\n",
    "- **Table 2:** Quarterly/Annual GDP growth rates (real GDP, 12-month percentage changes)\n",
    "\n",
    "This section automates the process of downloading the **BCRP Weekly Report PDFs** directly from the official BCRP website, ensuring that we can collect the most up-to-date data for our analysis.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è What the Scraper Bot Does:\n",
    "\n",
    "1. **Opens the official BCRP Weekly Report page** at [this link](https://www.bcrp.gob.pe/publicaciones/nota-semanal.html).\n",
    "2. **Finds and collects all PDF links** for the reports.\n",
    "3. **Downloads the PDFs** in chronological order (from newest to oldest).\n",
    "4. Optionally, plays a **notification sound** after every batch of downloads.\n",
    "5. **Organizes** the downloaded PDFs into year-based folders.\n",
    "\n",
    "---\n",
    "\n",
    "#### ‚ö†Ô∏è Important Notes:\n",
    "\n",
    "- **CAPTCHA Handling**: If a CAPTCHA appears during the download process, you'll need to manually solve it in the browser window and then **re-run the Scraper Bot**. The Scraper Bot cannot bypass CAPTCHA verification.\n",
    "  \n",
    "- **Automatic WebDriver Management**: This script uses `webdriver-manager` to automatically handle browser drivers (by default, it uses Chrome). **No need to manually download ChromeDriver or GeckoDriver**. If you wish to use a different browser, you can modify the `browser` parameter in the `init_driver()` function.\n",
    "  \n",
    "- **Custom Notification Sound**: If you'd like to receive notifications when each batch of downloads finishes, you can place your own MP3 file in the `alert_track` folder. We provide a warning track (in .mp3 format on GitHub). However, here are some free sources of .mp3 files so you can choose the ones you prefer:\n",
    "  - [Pixabay Audio](https://pixabay.com/music/) üéµ\n",
    "  - [FreeSound](https://freesound.org/) üé∂\n",
    "  - [FreePD](https://freepd.com/) üéº\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d95c04",
   "metadata": {},
   "source": [
    "### üì• Scraper Bot for BCRP Weekly Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0199bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the function to start the scraper bot\n",
    "pdf_downloader(\n",
    "    bcrp_url = \"https://www.bcrp.gob.pe/publicaciones/nota-semanal.html\",  # URL of the BCRP Weekly Report\n",
    "    raw_pdf_folder = raw_pdf_subfolder,  # Folder to save the raw downloaded PDFs\n",
    "    download_record_folder = record_folder,  # Folder to store download logs\n",
    "    download_record_txt = '1_downloaded_pdfs.txt',  # Record of downloaded PDFs\n",
    "    alert_track_folder = alert_track_folder,  # Folder for MP3 alert sound\n",
    "    max_downloads = 60,  # Maximum number of PDFs to download\n",
    "    downloads_per_batch = 6,  # Number of PDFs to download per batch\n",
    "    headless = False  # Run in browser window (set to True for headless mode)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa2d8bb-3b90-489b-9008-c5a8d9a21935",
   "metadata": {},
   "source": [
    "### üóÇÔ∏è Organize Downloaded PDFs\n",
    "\n",
    "After downloading the PDFs, it is essential to organize them into year-based folders to keep everything structured. This will help in later stages of data extraction and cleaning.\n",
    "\n",
    "Run the following code to organize the downloaded PDFs. It'll happen in the blink of an eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee016a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the directory\n",
    "files = os.listdir(raw_pdf_subfolder)\n",
    "\n",
    "# Call the function to organize files by year\n",
    "organize_files_by_year(raw_pdf_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ada7da1-58d3-47f0-a2b0-a069d14e810a",
   "metadata": {},
   "source": [
    "### üîß Handling Defective PDFs\n",
    "\n",
    "Occasionally, you may encounter defective PDFs (e.g., corrupted files, incomplete downloads, etc.). In such cases, you can replace the defective PDFs with new, valid ones. The following function allows you to replace defective PDFs.\n",
    "\n",
    "üîÑ Replace Defective PDFs:\n",
    "\n",
    "Use this function to replace any defective PDFs that were downloaded. Just specify the year, the defective PDF name, and the new PDF that you want to use as a replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e956de-ead1-4439-a3c5-bab8aeb75a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace specific defective PDFs (friendly outputs with icons)\n",
    "replace_defective_pdfs(\n",
    "    items=[\n",
    "        (\"2017\", \"ns-08-2017.pdf\", \"ns-07-2017\"), # Replace a defective PDF in 2017 folder\n",
    "        (\"2019\", \"ns-23-2019.pdf\", \"ns-22-2019\"), # Replace a defective PDF in 2019 folder\n",
    "    ],\n",
    "    root_folder=input_pdf_subfolder,  # Base folder containing year-based folders\n",
    "    record_folder=record_folder,  # Folder where downloaded PDF logs are stored\n",
    "    download_record_txt = '1_downloaded_pdfs.txt',  # Log of downloaded PDFs\n",
    "    quarantine=os.path.join(input_pdf_subfolder, \"_quarantine\")  # Folder to store defective PDFs (set to None to delete them)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4002384-8551-444e-ad82-e320b5d26314",
   "metadata": {},
   "source": [
    "> ‚ö° **Troubleshooting Tip:** If you encounter any issues during the data cleansing step (section 3), and suspect that the problem lies with defective PDFs, you can replace those PDFs using the above function. This will help avoid errors in the following sections. In case you encounter a problem with any particular defective PDF, you can also download alternative versions of the Weekly Reports for the same month, and replace the faulty ones as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da2a6b-01f1-419c-88ce-301220bc68bc",
   "metadata": {},
   "source": [
    "> üöÄ **Next Steps**: With the PDFs downloaded, organized, and ready for use, we can move on to the data cleaning and extraction steps. This will be covered in the next section of the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9d24d2",
   "metadata": {},
   "source": [
    "## 2. Generating PDF Inputs\n",
    "\n",
    "Now that we have successfully downloaded the **BCRP Weekly Reports (WR)**, it is important to note that each PDF file contains over 100 pages. However, not all pages are relevant to this project.\n",
    "\n",
    "For this analysis, we only need a **few key pages** from each WR:\n",
    "- **Table 1**: Monthly real GDP growth (12-month percentage changes)\n",
    "- **Table 2**: Annual and quarterly real GDP growth\n",
    "\n",
    "The goal of this section is to **trim the PDFs**, retaining just the necessary pages for analysis: the key tables and the cover page that provides the publication date and serial number for identification.\n",
    "\n",
    "The following steps will guide you through the process of generating these trimmed PDF files.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ†Ô∏è What This Step Does:\n",
    "\n",
    "1. **Extracts key pages** from each WR, focusing on the pages that contain **Table 1** and **Table 2**.\n",
    "2. **Retains the cover page** that provides metadata, such as publication date and serial number.\n",
    "3. **Creates new PDFs** containing only the relevant pages, ensuring efficiency by reducing file sizes.\n",
    "4. Organizes these **trimmed PDFs** into year-based subfolders for easy access.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d6af50-3b5b-44f2-859a-3b37d4b57495",
   "metadata": {},
   "source": [
    "_quarentine will be discard of the input PDF generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae30e931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the function to generate trimmed PDFs for input\n",
    "pdf_input_generator(\n",
    "    raw_pdf_folder = raw_pdf_subfolder,\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    input_pdf_record_folder = record_folder,\n",
    "    input_pdf_record_txt = '2_generated_input_pdfs.txt',\n",
    "    keywords = [\"ECONOMIC SECTORS\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c643079a",
   "metadata": {},
   "source": [
    "Again, probably the WR (PDF files, now of few pages) were stored in disorder in the `input_pdf_folder` folder. The following code sorts the PDFs into subfolders (years) by placing each WR (which now includes only the key tables) according to the year of its publication. This happens in the **\"blink of an eye\"**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae87395c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of files in the directory\n",
    "files = os.listdir(input_pdf_subfolder)\n",
    "\n",
    "# Call the function to organize files\n",
    "organize_files_by_year(input_pdf_subfolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430e1e92",
   "metadata": {},
   "source": [
    "## 3. Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100857d4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "Since we already have the PDFs <span style=\"font-size: 24px;\">&#128462;</span> with just the tables required for this project, we can start extracting them. Then we can proceed with data cleaning.\n",
    "</p>  \n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357318e8",
   "metadata": {},
   "source": [
    "### 3.2 Extracting tables and data cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea58b1c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The main library used for extracting tables from PDFs <span style=\"font-size: 24px;\">&#128462;</span> is <code>pdfplumber</code>. You can review the official documentation by clicking <a href=\"https://github.com/jsvine/pdfplumber\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">here</a>.\n",
    "</p>\n",
    "    \n",
    "<p>     \n",
    "    The functions in <b>Section 3</b> of the <code>\"new_gdp_datasets_functions.py\"</code> script were built to deal with each of these issues. An interesting exercise is to compare the original tables (the ones in the PDF <span style=\"font-size: 24px;\">&#128462;</span>) and the cleaned tables (by the cleanup codes below). Thus, the cleanup codes for <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a> and <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a> generates two dictionaries, the first one stores the raw tables; that is, the original tables from the PDF <span style=\"font-size: 24px;\">&#128462;</span> extracted by the <code>pdfplumber</code> library, while the second dictionary stores the fully cleaned tables.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6070fb47",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    The code iterates through each PDF <span style=\"font-size: 24px;\">&#128462;</span> and extracts the two required tables from each. The extracted information is then transformed into dataframes and the columns and values are cleaned up to conform to Python conventions (pythonic).\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8436c2d1",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.2.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 1.</span> Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65139cc2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "The basic criterion to start extracting tables is to use keywords (sufficient condition). I mean, tables containing the following keywords meet the requirements to be extracted.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bffcd08-7763-4eed-ad99-d3bce3644f90",
   "metadata": {},
   "source": [
    "Si por alguna raz√≥n ejecutas el c√≥digo de la secci√≥n 3 y no continuas ejecutando la secci√≥n subsecuente, puedes estar tranquilo de que un registro los guard√≥. La pr√≥xima vez que visite este script basta con empezar desde esta secci√≥n 3 (eliminando el txt) para generar los dataframes que no se guardaron en ningun lado, estos son insumos esenciales para la secci√≥n 4. Alternativamente puede guardar todos los dataframes generados en una carpeta como respaldo y empezar desde la secci√≥n 4 carg√°ndolos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4aabed-81df-4d47-af89-ab1fc70f6f0c",
   "metadata": {},
   "source": [
    "\n",
    "If you want the runners to *also* write the cleaned dicts out to a single combined Parquet/CSV per table (alongside the per-WR files), I can add that as an optional flag (`persist_combined=True`) without changing the defaults.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7075989-80c9-42f6-8a9e-df0728e67ace",
   "metadata": {},
   "source": [
    "# If you will run until this section and you are planning to go back and retake from section 4, enter \"True\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e021e356-54c3-4b4e-8e2e-666578a86b54",
   "metadata": {},
   "source": [
    "# Table 1 data into *row-based* vintage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6659e030-643c-4894-87a8-b85b1cfbf408",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base folder for saving vintages data (.csv)\n",
    "data_folder = 'data'\n",
    "\n",
    "# Define subfolder for saving \n",
    "input_data_subfolder = os.path.join(data_folder, 'input')\n",
    "\n",
    "# Define subfolder for saving \n",
    "output_data_subfolder = os.path.join(data_folder, 'output')\n",
    "\n",
    "# Create all required folders (if they do not already exist) and confirm creation\n",
    "for folder in [data_folder, input_data_subfolder, output_data_subfolder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"üìÇ {folder} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a2388f-faa2-4eb7-abce-8b61e8d7b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1, clean_1, vintages_1 = new_table_1_cleaner(\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = 'new_created_rtd_tab_1.txt',\n",
    "    persist = True,\n",
    "    persist_folder = input_data_subfolder,\n",
    "    pipeline_version = \"s3.0.0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f0a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8329629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3004d-e825-41a2-8247-81fa5cceec89",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cc13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084ecc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1392888-be8b-4b95-98cf-ebd71d34dbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1['ns_11_2024_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446a4fe9-54cc-48b6-901c-b0b5396fe68d",
   "metadata": {},
   "source": [
    "# Checking the cleaning version out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba88e1dd-8c85-481b-9a42-3d3b8174cbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df100 = vintages_1[\"ns_04_2022_1\"]\n",
    "print(df100.attrs)\n",
    "# {'pipeline_version': 's3.0.0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb48b6ed-b2ce-44cd-b19e-930ff305f8e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8229f-e230-494f-97b1-bcf4e6a9ddaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_1[\"ns_04_2022_1\"].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef214918-2835-4738-8ec0-5ea98e3e2d8d",
   "metadata": {},
   "source": [
    "# Table 2 data into *row-based* vintage format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fcfe1b-9f63-4850-937f-ca582be3ba33",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_2, clean_2, vintages_2 = new_table_2_cleaner(\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = 'new_created_rtd_tab_2.txt',\n",
    "    persist = True,\n",
    "    persist_folder = input_data_subfolder,\n",
    "    pipeline_version = \"s3.0.0\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcfed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb0dd4-9e7e-4255-95dd-5fe8175be6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_2['ns_04_2022_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2386c0-bf54-4d0a-b67d-97352ad8203e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df200 = vintages_2[\"ns_04_2022_2\"]\n",
    "print(df200.attrs)\n",
    "# {'pipeline_version': 's3.0.0'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24d77e3-f8f3-4c31-a25e-cf3af14adae1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a2c580-8454-45c8-902f-11f4bfda68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vintages_2[\"ns_04_2022_1\"].attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8989d65",
   "metadata": {},
   "source": [
    "## 4. Concatenating RTD across years by frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcfeae0-b5b0-4629-855a-a5556a43465a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ebedad3-c21c-4d63-85d5-b0c3bcfeba7a",
   "metadata": {},
   "source": [
    "**Connect to the PostgreSQL database**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30582cc-ab70-4aba-b054-02fb48757b40",
   "metadata": {},
   "source": [
    "The following function will establish a connection to the `gdp_revisions_datasets` database in `PostgreSQL`. The **input data** used in this jupyter notebook will be loaded from this `PostgreSQL` database, and similarly, all **output data** generated by this jupyter notebook will be stored in that database. Ensure that you set the necessary parameters to access the server once you have obtained the required permissions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dad90ec-db3c-4e20-a1d2-6d09c0779170",
   "metadata": {},
   "source": [
    "> üí° **Tip:** To request permissions, please email [Jason üì®](mailto:jj.cruza@alum.up.edu.pe)  \n",
    "> ‚ö†Ô∏è **Warning:** Make sure you have set your SQL credentials as environment variables before proceeding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da345bbe-0d12-4340-9275-938bfef26fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b60634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlalchemy_engine(database=\"gdp_revisions_datasets\", port=5432):\n",
    "    \"\"\"\n",
    "    Create an SQLAlchemy engine to connect to the PostgreSQL database.\n",
    "    \n",
    "    Environment Variables Required:\n",
    "        CIUP_SQL_USER: SQL username\n",
    "        CIUP_SQL_PASS: SQL password\n",
    "        CIUP_SQL_HOST: SQL host address\n",
    "\n",
    "    Args:\n",
    "        database (str): Name of the database. Default is 'gdp_revisions_datasets'.\n",
    "        port (int): Port number. Default is 5432.\n",
    "\n",
    "    Returns:\n",
    "        engine (sqlalchemy.engine.Engine): SQLAlchemy engine object.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If required environment variables are missing.\n",
    "\n",
    "    Example:\n",
    "        engine = create_sqlalchemy_engine()\n",
    "    \"\"\"\n",
    "    user = os.environ.get('CIUP_SQL_USER')\n",
    "    password = os.environ.get('CIUP_SQL_PASS')\n",
    "    host = os.environ.get('CIUP_SQL_HOST')\n",
    "\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"‚ùå Missing environment variables: CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS\")\n",
    "\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    print(f\"üîó Connected to PostgreSQL database: {database} at {host}:{port}\")\n",
    "    return engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a76e853-8dc9-45e6-9f30-cde33dd3966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_sqlalchemy_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d958b6af-25e7-4ec3-9d1d-c436bed32709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e4426-8320-4dfe-bf4e-fb3ca1d211c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1 = concatenate_table_1(\n",
    "    input_data_subfolder=input_data_subfolder,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=\"4_concatenated_rtd_tab_1.txt\",\n",
    "    persist=True,\n",
    "    persist_folder=output_data_subfolder,\n",
    "    csv_file_label=\"monthly_gdp_rtd.csv\",   # your custom name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c00c29-942f-49a9-9c44-96a80b9f6587",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a63583-7b4f-4d38-9128-227128066754",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfcc1c0-c027-4084-af58-91d042df0cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c411a38-f585-4c9d-83d6-19c5bcff89ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_2 = concatenate_table_2(\n",
    "    input_data_subfolder=input_data_subfolder,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=\"4_concatenated_rtd_tab_2.txt\",\n",
    "    persist=True,\n",
    "    persist_folder=output_data_subfolder,\n",
    "    csv_file_label=\"quarterly_annual_gdp_rtd.csv\",  # your custom name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2d6f6a-a5e7-431d-a512-4eb4fb7a1dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "concatenated_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb546a-6b80-4c88-a3d1-672c972aabcc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ecce1c-ffee-4f3b-9723-91f85a2ae9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f57c55f-4ffd-4402-b06e-3c7c3c407191",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6552a123-c9f8-4bee-a035-72fa78b73dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38c5741-7555-4fa0-b4b0-22596446ff6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5155fa2-5dc2-41fc-afce-aaed1a104f76",
   "metadata": {},
   "source": [
    "## 5. Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b2503-e10e-4aef-ad23-5f48235e6293",
   "metadata": {},
   "source": [
    "### Revision Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e210bbb1-dae3-4daa-84b8-4596a9017013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base folder for saving all digital PDFs\n",
    "metadata_folder = 'metadata'\n",
    "\n",
    "# Define base folder for saving all digital PDFs\n",
    "pdf_folder = 'pdf'\n",
    "\n",
    "# Define subfolder for saving reduced PDFs containing only selected pages with GDP growth tables (monthly, quarterly, and annual frequencies)\n",
    "input_pdf_subfolder = os.path.join(pdf_folder, 'input')\n",
    "\n",
    "# Define folder for saving .txt files with download and dataframe record\n",
    "record_folder = 'record'\n",
    "\n",
    "# Create all required folders (if they do not already exist) and confirm creation\n",
    "for folder in [metadata_folder, pdf_folder, input_pdf_subfolder, record_folder]:\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    print(f\"üìÇ {folder} created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35972c04-3b3d-434d-8ae2-718b460a5dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the base_year_list for mapping base years (modify or extend this list as needed)\n",
    "base_year_list = [\n",
    "    {\"year\": 1994, \"wr\": 1, \"base_year\": 1990},\n",
    "    {\"year\": 2000, \"wr\": 28, \"base_year\": 1994},\n",
    "    {\"year\": 2014, \"wr\": 11, \"base_year\": 2007},\n",
    "    {\"year\": 2022, \"wr\": 20, \"base_year\": 2019},\n",
    "    # Add more mappings if needed\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dba404-f4e5-495c-adf1-7714fb3ab43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to update the metadata\n",
    "updated_df = update_metadata(\n",
    "    metadata_folder = metadata_folder,\n",
    "    input_pdf_folder = input_pdf_subfolder,\n",
    "    record_folder = record_folder,\n",
    "    record_txt = \"wr_metadata.txt\",\n",
    "    wr_metadata_csv = \"wr_metadata.csv\",\n",
    "    base_year_list = base_year_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6730862b-944b-47fa-b4a3-9ef75c43607e",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_df.iloc[-30:]   # last 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caed0066-cbbc-467d-b5c3-f55faf8c68eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_df[\"benchmark_revision\"].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656f17c6-aa9e-4453-860a-5e9f6169778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(updated_df[\"base_year\"].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23fd435-5ae3-4018-b80d-1ca3d32aa378",
   "metadata": {},
   "source": [
    "### 5.1 Generating adjusted RTDs by removing revisions affected by base years (based on metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13eabb9-af86-41e9-a3f4-ab9cb9183660",
   "metadata": {},
   "source": [
    "# Drop base year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc92104-cfd4-4466-9d9f-2b1886d014b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_year_list_2 = [\n",
    "    \"2000m7\",   # 1990 -> 1994\n",
    "    \"2014m3\",   # 1994 -> 2007\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d1cbc5-64b0-45e1-952e-37642dabd95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process both monthly and quarterly GDP files and save them with new names\n",
    "adjusted_rtd = apply_base_year_sentinel(\n",
    "    base_year_list=base_year_list_2,\n",
    "    sentinel=-999999.0,\n",
    "    output_data_subfolder=output_data_subfolder,\n",
    "    csv_file_labels=[\"monthly_gdp_rtd.csv\", \"quarterly_annual_gdp_rtd.csv\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161e3ccf-dd44-48f5-97e5-61d7b9605efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the processed data (adjusted CSV files)\n",
    "adjusted_monthly_rtd = adjusted_rtd[\"by_adjusted_monthly_gdp_rtd.csv\"]\n",
    "adjusted_quarterly_rtd = adjusted_rtd[\"by_adjusted_quarterly_annual_gdp_rtd.csv\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5779bf6b-ef41-43dd-aeb1-6775ed332462",
   "metadata": {},
   "source": [
    "### 5.2 Generating benchmark RTD for revisions affected by benchmarking procedures (based on metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f884c94-dd2b-4a5d-b2f8-745bda1c43f3",
   "metadata": {},
   "source": [
    "# Bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3784e9-9c97-4157-8d97-334c6cdb27f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv_file_labels = [\n",
    "    \"monthly_gdp_rtd\",\n",
    "    \"quarterly_annual_gdp_rtd\",\n",
    "    \"by_adjusted_monthly_gdp_rtd\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_rtd\"\n",
    "]\n",
    "benchmark_dataset_csv = [\n",
    "    \"monthly_gdp_benchmark\",\n",
    "    \"quarterly_annual_gdp_benchmark\",\n",
    "    \"by_adjusted_monthly_gdp_benchmark\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_benchmark\"\n",
    "]\n",
    "record_txt = \"_converted_to_benchmark.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6177506c-ac9e-4ccb-967d-9bda6e786dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr_metadata_csv = \"wr_metadata.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e6e45-5a0e-4c58-9fb8-0e3c9da96b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets = convert_to_benchmark_dataset(\n",
    "    output_data_subfolder=output_data_subfolder,\n",
    "    csv_file_labels=csv_file_labels,\n",
    "    metadata_folder=metadata_folder,\n",
    "    wr_metadata_csv=wr_metadata_csv,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=record_txt,\n",
    "    benchmark_dataset_csv=benchmark_dataset_csv\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed57304e-8925-4b4d-a32b-155d09c473da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acceder a los resultados procesados\n",
    "processed_datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6948e9eb-b23a-4d53-a775-ee29e31f1c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_datasets['monthly_gdp_benchmark']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fb74e8-7f22-4756-96ea-eb86a2aa400e",
   "metadata": {},
   "source": [
    "## 6. Releases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b4c9c-f988-44f1-8c94-8ae09a791ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_labels = [\n",
    "    \"monthly_gdp_rtd\",\n",
    "    \"quarterly_annual_gdp_rtd\",\n",
    "    \"by_adjusted_monthly_gdp_rtd\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_rtd\",\n",
    "    \"monthly_gdp_benchmark\",\n",
    "    \"quarterly_annual_gdp_benchmark\",\n",
    "    \"by_adjusted_monthly_gdp_benchmark\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_benchmark\"\n",
    "]\n",
    "releases_dataset_csv = [\n",
    "    \"monthly_gdp_releases\",\n",
    "    \"quarterly_annual_gdp_releases\",\n",
    "    \"by_adjusted_monthly_gdp_releases\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_releases\",\n",
    "    \"monthly_gdp_benchmark_releases\",\n",
    "    \"quarterly_annual_gdp_benchmark_releases\",\n",
    "    \"by_adjusted_monthly_gdp_benchmark_releases\",\n",
    "    \"by_adjusted_quarterly_annual_gdp_benchmark_releases\"\n",
    "]\n",
    "record_txt = \"5_converted_to_releases.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d86a426-4e03-48b3-98a4-26f8f7f16395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the conversion function\n",
    "releases_df = convert_to_releases_dataset(\n",
    "    output_data_subfolder=output_data_subfolder,\n",
    "    csv_file_labels=csv_file_labels,\n",
    "    record_folder=record_folder,\n",
    "    record_txt=record_txt,\n",
    "    releases_dataset_csv=releases_dataset_csv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c124a3-8746-4936-ad91-2484ecc8b59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the converted releases dataset for \"monthly_gdp_releases\"\n",
    "releases_df[\"by_adjusted_monthly_gdp_releases\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c0cc0-7d08-4399-8470-1746d6a169d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def11acf-f107-4238-bd60-002bbe016972",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
