{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0ee00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0953333",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter bt pro roman'; color: rgb(0, 65, 75);\">\n",
    "<h1>\n",
    "Old GDP Revisions Datasets\n",
    "</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323e5f0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter bt pro roman'; color: rgb(0, 65, 75);\">\n",
    "<h3>\n",
    "Documentation\n",
    "<br>\n",
    "____________________\n",
    "<br>\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc075bd7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'PT Serif Pro Book'; color: rgb(0, 65, 75); font-size: 16px;\">\n",
    "    Jason Cruz\n",
    "    <br>\n",
    "    <a href=\"mailto:jj.cruza@up.edu.pe\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">\n",
    "        jj.cruza@up.edu.pe\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0f23d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "This <span style=\"color: rgb(0, 65, 75);\">jupyter notebook</span> documents step-by-step the <b>construction of old datasets</b> for the project <b>'Revisions and Biases in Preliminary GDP Estimates in Peru'</b>.\n",
    "\n",
    "This jupyter notebook goes from the cleaning of the tables (Weekly Reports, WR) provided confidentially by the Central Bank to the construction of the <b>vintages</b> and <b>revisions</b> datasets from 1994-2024.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addcdf2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;line-height: 1.5;\">\n",
    "<span style=\"font-size: 24px;\">&#128196;</span> The Weekly Report/<i>Nota Semanal</i> (WR/<i>NS</i>) of the Central Bank.\n",
    "    <br>\n",
    "    <span style=\"font-size: 24px;\">&#8987;</span> Available since <b>1994-2012</b> (Table 1) and since <b>1997-2012</b> (Table 2). \n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516ae6c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Amaya; text-align: left; color: rgb(0, 65, 75); font-size:16px\">The following <b>outline is functional</b>. By utilising the provided buttons, users are able to enhance their experience by browsing this script.<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d69587",
   "metadata": {},
   "source": [
    "<div id=\"outilne\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15589700",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #292929; padding: 10px; line-height: 1.5; font-family: 'PT Serif Pro Book';\">\n",
    "    <h2 style=\"text-align: left; color: #E0E0E0;\">\n",
    "        Outline\n",
    "    </h2>\n",
    "    <br>\n",
    "    <a href=\"#libraries\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        Libraries</a>\n",
    "    <br>\n",
    "    <a href=\"#setup\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        Initial set-up</a>\n",
    "    <br>\n",
    "    <a href=\"#1\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        1. Duplicate tables for all other NS ids</a>\n",
    "    <br>\n",
    "    <a href=\"#1-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        1.1. Table 1.</a>\n",
    "    <br>\n",
    "    <a href=\"#1-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        1.2. Table 2.</a>\n",
    "    <br>\n",
    "    <a href=\"#2\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        2. Data cleaning</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        2.1. Extracting tables and data cleanup.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1-1\" style=\"color: #94FFD8; font-size: 14px; margin-left: 40px;\">\n",
    "        2.1.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1-2\" style=\"color: #94FFD8; font-size: 14px; margin-left: 40px;\">\n",
    "        2.1.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.</a>\n",
    "    <br>\n",
    "    <a href=\"#3\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">3. Real-time data of Peru's GDP growth rates</a>\n",
    "    <br>\n",
    "    <a href=\"#3-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.1. Growth rates datasets concatenation for all frequencies.</a>\n",
    "    <br>\n",
    "    <a href=\"#4\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">4. Uploading data to SQL</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7c4d6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    Any questions or issues regarding the coding, please email Jason Cruz <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123); text-decoration: none;\"><span style=\"font-size: 24px;\">&#x2709;</span>\n",
    "    </a>.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff8772",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    If you don't have the libraries below, please use the following code (as example) to install the required libraries.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f517f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21974a",
   "metadata": {},
   "source": [
    "<div id=\"libraries\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a752d8fe",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    <h2>\n",
    "    Libraries\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00415459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Duplicate tables for all other NS ids\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# 1.1. Table 1\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# 2. Data cleaning\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2.2. Extracting tables and data cleanup\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import unicodedata  # For manipulating Unicode data\n",
    "import re  # For regular expressions operations\n",
    "from datetime import datetime  # For working with dates and times\n",
    "import locale  # For locale-specific formatting of numbers, dates, and currencies\n",
    "import numpy as np\n",
    "import unidecode\n",
    "\n",
    "# 2.2.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "\n",
    "import tabula  # Used to extract tables from PDF files into pandas DataFrames\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO  # Used for creating graphical user interfaces\n",
    "from sqlalchemy import create_engine  # Used for connecting to and interacting with SQL databases\n",
    "\n",
    "# 2.2.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "\n",
    "import roman\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# 3. Real-time data of Peru's GDP growth rates\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import psycopg2  # For interacting with PostgreSQL databases\n",
    "from sqlalchemy import create_engine, text  # For creating and executing SQL queries using SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8167e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d73758",
   "metadata": {},
   "source": [
    "<div id=\"setup\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fbf38",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark;\">\n",
    "    <h2>\n",
    "    Initial set-up\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8675b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> Setting the base path. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f382fef7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ask the user for the base path\n",
    "base_path = input(\"Please enter your base path to set your main working directory, then press enter: \\n\")\n",
    "\n",
    "# Check if the path is valid\n",
    "if os.path.isdir(base_path):\n",
    "    print(f\"Correctly defined base path.\")\n",
    "    os.chdir(base_path)\n",
    "else:\n",
    "    print(\"The entered path is not valid. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16931de9",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    Request the <code>.zip</code> files of <code>table_1</code> and <code>table_2</code> and paste them into <code>raw_data</code> and <code>input_data</code> paths set below. \n",
    "    <p>\n",
    "     Please note that missing tables will be completed in the <a href=\"#1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Section 1</a> under the <code>input_data</code> directory. While changes will be applied directly in <code>input_data</code>, we have created the <code>raw_data</code> directory to retain a backup of the tables as originally extracted, either via OCR or manually, with no transformations. This serves as a backup of the raw data.\n",
    "       </p>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651a1eb",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2b2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank \n",
    "raw_data = 'raw_data' # to save raw data (.csv).\n",
    "if not os.path.exists(raw_data):\n",
    "    os.mkdir(raw_data) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aab459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank as inputs (duplicated for all NS id) \n",
    "input_data = 'input_data' # to save input data (.csv).\n",
    "if not os.path.exists(input_data):\n",
    "    os.mkdir(input_data) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7bc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank (Table 1)\n",
    "table_1_folder = os.path.join(input_data, 'table_1') # to save raw data (.csv).\n",
    "if not os.path.exists(table_1_folder):\n",
    "    os.mkdir(table_1_folder) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank (Table 2)\n",
    "table_2_folder = os.path.join(input_data, 'table_2') # to save raw data (.csv).\n",
    "if not os.path.exists(table_2_folder):\n",
    "    os.mkdir(table_2_folder) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save dataframes generated record by year\n",
    "\n",
    "dataframes_record = 'dataframes_record'\n",
    "if not os.path.exists(dataframes_record):\n",
    "    os.makedirs(dataframes_record) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41a493",
   "metadata": {},
   "source": [
    "<p style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following function will establish a connection to the <code>gdp_revisions_datasets</code> database in <code>PostgreSQL</code>. The <b>input data</b> used in this jupyter notebook will be loaded from this <code>PostgreSQL</code> database, and similarly, all <b>output data</b> generated by this jupyter notebook will be stored in that database. Ensure that you set the necessary parameters to access the server once you have obtained the required permissions.<p/>\n",
    "    \n",
    "<p style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "To request permissions, please email Jason Cruz <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123); text-decoration: none;\"> <span style=\"font-size: 24px;\">&#x2709;</span>\n",
    "    </a>.\n",
    "<p/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa0789",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    <span style=\"font-size: 24px; color: #FFA823; font-weight: bold;\">&#9888;</span>\n",
    "    Enter your user credentials to acces to SQL.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4457bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlalchemy_engine():\n",
    "    \"\"\"\n",
    "    Function to create an SQLAlchemy engine using environment variables.\n",
    "    \n",
    "    Returns:\n",
    "        engine: SQLAlchemy engine object.\n",
    "    \"\"\"\n",
    "    # Get environment variables\n",
    "    user = os.environ.get('CIUP_SQL_USER')  # Get the SQL user from environment variables\n",
    "    password = os.environ.get('CIUP_SQL_PASS')  # Get the SQL password from environment variables\n",
    "    host = os.environ.get('CIUP_SQL_HOST')  # Get the SQL host from environment variables\n",
    "    port = 5432  # Set the SQL port to 5432\n",
    "    database = 'gdp_revisions_datasets'  # Set the database name 'gdp_revisions_datasets' from SQL\n",
    "\n",
    "    # Check if all environment variables are defined\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"Some environment variables are missing (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "    # Create connection string\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8fa3d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Import all other functions required by this jupyter notebook.\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ecd38",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> Please, check the script <code>old_gdp_datasets_functions.py</code> and <code>new_gdp_datasets_functions.py</code> which contains all the functions required by this jupyter notebook. The functions there are ordered according to the <a href=\"#outilne\" style=\"color: #3d30a2;\">sections</a> of this jupyter notebok.<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cda8404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from old_gdp_datasets_functions import *\n",
    "from new_gdp_datasets_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e10d5d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bedbd",
   "metadata": {},
   "source": [
    "<div id=\"1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54b25f",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;; color: dark;\">1.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Duplicate tables for all other NS ids</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd1034",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    <p>By means of an encoding or optical character recognition (OCR) process, <code>.csv</code> files have been generated with tables corresponding to certain Weekly Notes (WN), in those where revisions were identified, according to the information at the bottom of each table (within each WN).</p>\n",
    "    \n",
    "   <p>So, we will duplicate these tables to cover the total number of NS in each year, which equals approximately 50, given the number of weeks per year.</p>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9443ed",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "The following code imports from SQL data that includes a dummy variable, which indicates the availability of specific tables in <code>.csv</code> files for each Weekly Note (1 if the table is available and 0 if it is not).\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb719841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgresSQL\n",
    "engine = create_sqlalchemy_engine()\n",
    "\n",
    "# Define SQL query to import data\n",
    "query = f\"SELECT * FROM old_raw_data_delivered\"\n",
    "\n",
    "# Importing data into a pandas DataFrame\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d5875",
   "metadata": {},
   "source": [
    "<div id=\"1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5b4f6",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">1.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Table 1\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbfbbf",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please change your preferred year range\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1686bc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process each year\n",
    "for year in range(1994, 2013): # Please change your preferred year range (the last year + 1)\n",
    "    df_year = df[df['year'] == year]\n",
    "    duplicate_files_table_1(year, df_year, table_1_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bcdef",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a9694",
   "metadata": {},
   "source": [
    "<div id=\"1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff12be5",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">1.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Table 2\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cd6d0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please change your preferred year range\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e87957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process each year\n",
    "for year in range(1997, 2013): # Please change your preferred year range (the last year + 1)\n",
    "    df_year = df[df['year'] == year]\n",
    "    duplicate_files_table_2(year, df_year, table_2_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710b388",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baf20e",
   "metadata": {},
   "source": [
    "<div id=\"2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86728175",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;; color: dark;\">2.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Data cleaning</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56e8cc",
   "metadata": {},
   "source": [
    "<div id=\"2-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9f258",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Extracting tables and data cleanup\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84b6a7",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "PENDING\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbde93",
   "metadata": {},
   "source": [
    "<div id=\"2-1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c9908",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 1.</span> Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245d93f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <b>\"ns_dates\"</b> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ffb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Dictionary to store generated DataFrames\n",
    "old_dataframes_dict_1 = {}\n",
    "\n",
    "# Path for the processed folders log file\n",
    "record_path = 'dataframes_record/old_processed_folders_1.txt'\n",
    "\n",
    "# Function to correct month names\n",
    "def correct_month_name(month):\n",
    "    months_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Add more mappings as needed for other month names\n",
    "    }\n",
    "    return months_mapping.get(month, month)\n",
    "\n",
    "# Function to register processed folder\n",
    "def register_processed_folder(folder, num_processed_files):\n",
    "    with open(record_path, 'a') as file:\n",
    "        file.write(f\"{folder}:{num_processed_files}\\n\")\n",
    "\n",
    "# Function to check if folder has been processed\n",
    "def folder_processed(folder):\n",
    "    if not os.path.exists(record_path):\n",
    "        return False\n",
    "    with open(record_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(folder):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to fetch date from database\n",
    "def get_date(df, engine):\n",
    "    id_ns = df['id_ns'].iloc[0]\n",
    "    year = df['year'].iloc[0]\n",
    "    query = f\"SELECT date FROM dates_growth_rates WHERE id_ns = '{id_ns}' AND year = '{year}';\"\n",
    "    date_result = pd.read_sql(query, engine)\n",
    "    return date_result.iloc[0, 0] if not date_result.empty else None\n",
    "\n",
    "def process_csv(csv_path, engine):\n",
    "    old_tables_dict_1 = {}  # Local dictionary for each CSV\n",
    "    table_counter = 1\n",
    "\n",
    "    filename = os.path.basename(csv_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None # Return None for tables_dict_1 as well\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(csv_path))[0].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(csv_path, delimiter=';')\n",
    "    \n",
    "    dataframe_name = f\"{new_filename}_{table_counter}\"\n",
    "    old_tables_dict_1[dataframe_name] = df.copy()\n",
    "\n",
    "    # Apply cleanup functions to a copy of the DataFrame\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Conditional cleaning based on the first column\n",
    "    if df_clean.columns[1] == 'economic_sectors':\n",
    "        df_clean = drop_nan_rows(df_clean)\n",
    "        df_clean = drop_nan_columns(df_clean)\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_mineria(df_clean)\n",
    "        df_clean = replace_mining(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "    else:\n",
    "        # Cleaning functions (set as required)\n",
    "        df_clean = clean_column_names(df_clean)\n",
    "        df_clean = adjust_column_names(df_clean)\n",
    "        df_clean = drop_rare_caracter_row(df_clean)\n",
    "        df_clean = drop_nan_rows(df_clean)\n",
    "        df_clean = drop_nan_columns(df_clean)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = remove_digit_slash(df_clean)\n",
    "        df_clean = replace_var_perc_first_column(df_clean)\n",
    "        df_clean = replace_var_perc_last_columns(df_clean)\n",
    "        df_clean = replace_number_moving_average(df_clean)\n",
    "        df_clean = relocate_last_column(df_clean)\n",
    "        df_clean = clean_first_row(df_clean)\n",
    "        df_clean = find_year_column(df_clean)\n",
    "        year_columns = extract_years(df_clean)\n",
    "        df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "        df_clean = first_row_columns(df_clean)\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_mineria(df_clean)\n",
    "        df_clean = replace_mining(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "    # Add the column 'year' to the clean DataFrame\n",
    "    df_clean.insert(0, 'year', year)\n",
    "    \n",
    "    # Add the column 'id_ns' to the clean DataFrame\n",
    "    df_clean.insert(1, 'id_ns', id_ns)\n",
    "    \n",
    "    # Get corresponding date from database\n",
    "    date = get_date(df_clean, engine)\n",
    "    if date:\n",
    "        # Add 'date' column to cleaned DataFrame\n",
    "        df_clean.insert(2, 'date', date)\n",
    "    else:\n",
    "        print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "    # Store cleaned DataFrame in old_dataframes_dict_1\n",
    "    old_dataframes_dict_1[dataframe_name] = df_clean\n",
    "\n",
    "    return id_ns, year, old_tables_dict_1\n",
    "\n",
    "# Function to process folder\n",
    "def process_folder(folder, engine):\n",
    "    print(f\"Processing folder {os.path.basename(folder)}\")\n",
    "    csv_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\n",
    "    num_csv_processed = 0\n",
    "    num_dataframes_generated = 0\n",
    "\n",
    "    table_counter = 1  # Initialize table counter here\n",
    "    old_tables_dict_1 = {}  # Declare old_tables_dict_1 outside main loop\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        id_ns, year, tables_dict_temp = process_csv(csv_file, engine)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for dataframe_name, df in tables_dict_temp.items():\n",
    "                file_name = os.path.splitext(os.path.basename(csv_file))[0].replace('-', '_')\n",
    "                dataframe_name = f\"{file_name}_1\"\n",
    "                \n",
    "                # Store raw DataFrame in old_tables_dict_1\n",
    "                old_tables_dict_1[dataframe_name] = df.copy()\n",
    "                \n",
    "                # Apply cleanup functions to a copy of the DataFrame\n",
    "                df_clean = df.copy()\n",
    "\n",
    "                # Conditional cleaning based on the first column\n",
    "                if df_clean.columns[1] == 'economic_sectors':\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                else:\n",
    "                    # Cleaning functions (set as required)\n",
    "                    df_clean = clean_column_names(df_clean)\n",
    "                    df_clean = adjust_column_names(df_clean)\n",
    "                    df_clean = drop_rare_caracter_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = remove_digit_slash(df_clean)\n",
    "                    df_clean = replace_var_perc_first_column(df_clean)\n",
    "                    df_clean = replace_var_perc_last_columns(df_clean)\n",
    "                    df_clean = replace_number_moving_average(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = find_year_column(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "                # Add the column 'year' to the clean DataFrame\n",
    "                df_clean.insert(0, 'year', year)\n",
    "\n",
    "                # Add the column 'id_ns' to the clean DataFrame\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "\n",
    "                # Get corresponding date from database\n",
    "                date = get_date(df_clean, engine)\n",
    "                if date:\n",
    "                    # Add 'date' column to cleaned DataFrame\n",
    "                    df_clean.insert(2, 'date', date)\n",
    "                else:\n",
    "                    print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "                # Store cleaned DataFrame in old_dataframes_dict_1\n",
    "                old_dataframes_dict_1[dataframe_name] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. The dataframe generated for the {csv_file} file is: {dataframe_name}')\n",
    "                num_dataframes_generated += 1\n",
    "                table_counter += 1  # Increment table counter here\n",
    "        \n",
    "        num_csv_processed += 1  # Increment number of processed CSV for each CSV in folder\n",
    "\n",
    "    return num_csv_processed, num_dataframes_generated, old_tables_dict_1\n",
    "\n",
    "def process_folders():\n",
    "    csv_folder = table_1_folder\n",
    "    folders = [os.path.join(csv_folder, d) for d in os.listdir(csv_folder) if os.path.isdir(os.path.join(csv_folder, d)) and re.match(r'\\d{4}', d)]\n",
    "    \n",
    "    old_tables_dict_1 = {}  # Initialize old_tables_dict_1 here\n",
    "    \n",
    "    for folder in folders:\n",
    "        if folder_processed(folder):\n",
    "            print(f\"Folder {folder} has already been processed.\")\n",
    "            continue\n",
    "        \n",
    "        num_csv_processed, num_dataframes_generated, tables_dict_temp = process_folder(folder, engine)\n",
    "        \n",
    "        # Update old_tables_dict_1 with values returned from process_folder()\n",
    "        old_tables_dict_1.update(tables_dict_temp)\n",
    "        \n",
    "        register_processed_folder(folder, num_csv_processed)\n",
    "\n",
    "        # Ask user if they want to continue with next folder\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Ensure the messagebox is in front\n",
    "        message = f\"Process {folder} complete. Processed {num_csv_processed} CSV(s) and generated {num_dataframes_generated} DataFrame(s). Continue with next folder?\"\n",
    "        if not messagebox.askyesno(\"Continue?\", message):\n",
    "            break\n",
    "            \n",
    "    print(\"Processing completed for all folders.\")  # Add a message to indicate completion\n",
    "    \n",
    "    return old_tables_dict_1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    engine = create_sqlalchemy_engine()\n",
    "    old_tables_dict_1 = process_folders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda07520",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_tables_dict_1['ns_13_1997_1'].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataframes_dict_1['ns_13_1997_1'].head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c511633",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb917b",
   "metadata": {},
   "source": [
    "<div id=\"2-1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d489b",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 2.</span> Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21687b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <b>\"ns_dates\"</b> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab041892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Dictionary to store generated DataFrames\n",
    "old_dataframes_dict_2 = {}\n",
    "\n",
    "# Path for the processed folders log file\n",
    "record_path = 'dataframes_record/old_processed_folders_2.txt'\n",
    "\n",
    "# Function to correct month names\n",
    "def correct_month_name(month):\n",
    "    months_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Add more mappings as needed for other month names\n",
    "    }\n",
    "    return months_mapping.get(month, month)\n",
    "\n",
    "# Function to register processed folder\n",
    "def register_processed_folder(folder, num_processed_files):\n",
    "    with open(record_path, 'a') as file:\n",
    "        file.write(f\"{folder}:{num_processed_files}\\n\")\n",
    "\n",
    "# Function to check if folder has been processed\n",
    "def folder_processed(folder):\n",
    "    if not os.path.exists(record_path):\n",
    "        return False\n",
    "    with open(record_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(folder):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to fetch date from database\n",
    "def get_date(df, engine):\n",
    "    id_ns = df['id_ns'].iloc[0]\n",
    "    year = df['year'].iloc[0]\n",
    "    query = f\"SELECT date FROM dates_growth_rates WHERE id_ns = '{id_ns}' AND year = '{year}';\"\n",
    "    date_result = pd.read_sql(query, engine)\n",
    "    return date_result.iloc[0, 0] if not date_result.empty else None\n",
    "\n",
    "def process_csv(csv_path, engine):\n",
    "    old_tables_dict_2 = {}  # Local dictionary for each CSV\n",
    "    table_counter = 2\n",
    "\n",
    "    filename = os.path.basename(csv_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None # Return None for tables_dict_1 as well\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(csv_path))[0].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(csv_path, delimiter=';')\n",
    "    \n",
    "    dataframe_name = f\"{new_filename}_{table_counter}\"\n",
    "    old_tables_dict_2[dataframe_name] = df.copy()\n",
    "\n",
    "    # Apply cleanup functions to a copy of the DataFrame\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Conditional cleaning based on the first column\n",
    "    if df_clean.columns[1] == 'economic_sectors':\n",
    "        df_clean = drop_nan_rows(df_clean)\n",
    "        df_clean = drop_nan_columns(df_clean)\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_mineria(df_clean)\n",
    "        df_clean = replace_mining(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "    else:\n",
    "        # Cleaning functions (set as required)\n",
    "        df_clean = replace_total_with_year(df_clean)\n",
    "        df_clean = drop_nan_rows(df_clean)\n",
    "        df_clean = drop_nan_columns(df_clean)\n",
    "        year_columns = extract_years(df_clean)\n",
    "        df_clean = roman_arabic(df_clean)\n",
    "        df_clean = fix_duplicates(df_clean)\n",
    "        df_clean = relocate_last_column(df_clean)\n",
    "        df_clean = replace_first_row_nan(df_clean)\n",
    "        df_clean = clean_first_row(df_clean)\n",
    "        df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = first_row_columns(df_clean)\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_mineria(df_clean)\n",
    "        df_clean = replace_mining(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "    # Add the column 'year' to the clean DataFrame\n",
    "    df_clean.insert(0, 'year', year)\n",
    "    \n",
    "    # Add the column 'id_ns' to the clean DataFrame\n",
    "    df_clean.insert(1, 'id_ns', id_ns)\n",
    "    \n",
    "    # Get corresponding date from database\n",
    "    date = get_date(df_clean, engine)\n",
    "    if date:\n",
    "        # Add 'date' column to cleaned DataFrame\n",
    "        df_clean.insert(2, 'date', date)\n",
    "    else:\n",
    "        print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "    # Store cleaned DataFrame in old_dataframes_dict_2\n",
    "    old_dataframes_dict_2[dataframe_name] = df_clean\n",
    "\n",
    "    return id_ns, year, old_tables_dict_2\n",
    "\n",
    "# Function to process folder\n",
    "def process_folder(folder, engine):\n",
    "    print(f\"Processing folder {os.path.basename(folder)}\")\n",
    "    csv_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\n",
    "    num_csv_processed = 0\n",
    "    num_dataframes_generated = 0\n",
    "\n",
    "    table_counter = 1  # Initialize table counter here\n",
    "    old_tables_dict_2 = {}  # Declare old_tables_dict_1 outside main loop\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        id_ns, year, tables_dict_temp = process_csv(csv_file, engine)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for dataframe_name, df in tables_dict_temp.items():\n",
    "                file_name = os.path.splitext(os.path.basename(csv_file))[0].replace('-', '_')\n",
    "                dataframe_name = f\"{file_name}_2\"\n",
    "                \n",
    "                # Store raw DataFrame in old_tables_dict_2\n",
    "                old_tables_dict_2[dataframe_name] = df.copy()\n",
    "                \n",
    "                # Procesar y limpiar el DataFrame\n",
    "                df_clean = df.copy()\n",
    "                \n",
    "                # Conditional cleaning based on the first column\n",
    "                if df_clean.columns[1] == 'economic_sectors':\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                else:\n",
    "                    # Cleaning functions (set as required)\n",
    "                    df_clean = replace_total_with_year(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = replace_first_row_nan(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                \n",
    "                # Add the column 'year' to the clean DataFrame\n",
    "                df_clean.insert(0, 'year', year)\n",
    "\n",
    "                # Add the column 'id_ns' to the clean DataFrame\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "\n",
    "                # Get corresponding date from database\n",
    "                date = get_date(df_clean, engine)\n",
    "                if date:\n",
    "                    # Add 'date' column to cleaned DataFrame\n",
    "                    df_clean.insert(2, 'date', date)\n",
    "                else:\n",
    "                    print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "                # Store cleaned DataFrame in old_dataframes_dict_2\n",
    "                old_dataframes_dict_2[dataframe_name] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. The dataframe generated for the {csv_file} file is: {dataframe_name}')\n",
    "                num_dataframes_generated += 1\n",
    "                table_counter += 1  # Increment table counter here\n",
    "        \n",
    "        num_csv_processed += 1  # Increment number of processed CSV for each CSV in folder\n",
    "\n",
    "    return num_csv_processed, num_dataframes_generated, old_tables_dict_2\n",
    "\n",
    "def process_folders():\n",
    "    csv_folder = table_2_folder\n",
    "    folders = [os.path.join(csv_folder, d) for d in os.listdir(csv_folder) if os.path.isdir(os.path.join(csv_folder, d)) and re.match(r'\\d{4}', d)]\n",
    "    \n",
    "    old_tables_dict_2 = {}  # Initialize old_tables_dict_1 here\n",
    "    \n",
    "    for folder in folders:\n",
    "        if folder_processed(folder):\n",
    "            print(f\"Folder {folder} has already been processed.\")\n",
    "            continue\n",
    "        \n",
    "        num_csv_processed, num_dataframes_generated, tables_dict_temp = process_folder(folder, engine)\n",
    "        \n",
    "        # Update old_tables_dict_2 with values returned from process_folder()\n",
    "        old_tables_dict_2.update(tables_dict_temp)\n",
    "        \n",
    "        register_processed_folder(folder, num_csv_processed)\n",
    "    \n",
    "        # Ask user if they want to continue with next folder\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Ensure the messagebox is in front\n",
    "        message = f\"Process {folder} complete. Processed {num_csv_processed} CSV(s) and generated {num_dataframes_generated} DataFrame(s). Continue with next folder?\"\n",
    "        if not messagebox.askyesno(\"Continue?\", message):\n",
    "            break\n",
    "\n",
    "    print(\"Processing completed for all folders.\")  # Add a message to indicate completion\n",
    "\n",
    "    return old_tables_dict_2\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    engine = create_sqlalchemy_engine()\n",
    "    old_tables_dict_2 = process_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c7917",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_tables_dict_2['ns_44_2004_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b05cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataframes_dict_2['ns_44_2004_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6942ad4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec8677",
   "metadata": {},
   "source": [
    "<div id=\"3\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7663f10",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Real-time data of Peru's GDP growth rates</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320f965",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "This section creates the GDP growth rate vintages for Peru using <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a> and <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a>, which were extracted and cleaned in the previous section. Each table from each WR (CSV <span style=\"font-size: 24px;\">&#128452;</span>) was extracted and cleaned individually in the previous section. Here, we will concatenate all the tables for a specific economic sector, thus creating a vintage dataset of (real) GDP growth by economic sector from <b>1994</b> to <b>2012</b> (<a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a>) and <b>1997</b> to <b>2012</b> (<a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a>).\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008d4721",
   "metadata": {},
   "source": [
    "<div id=\"select_sector\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc80591",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Select <code>sector_economico</code> and <code>economic_sector</code></span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eaa05b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "When executing the following code, a window will be displayed with options in <b>Spanish</b> and <b>English</b> to select <b>economic sectors</b>. Choose them to concatenate Peru GDP growth rates (annual, quarterly or monthly) by sector.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7156504",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected sector = manufacturing, selected_spanish = manufactura, and selected_english = manufacturing.\n"
     ]
    }
   ],
   "source": [
    "# Call the function to display the window and capture the selected values\n",
    "selected_spanish, selected_english, sector = show_option_window()\n",
    "\n",
    "# Display the selected values\n",
    "print(f\"You have selected sector = {sector}, selected_spanish = {selected_spanish}, and selected_english = {selected_english}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e90ece",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Select the dataset name prefix</span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca98fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call the function to show the popup window\n",
    "sector = show_option_window()\n",
    "print(\"Selected economic sector:\", sector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd201bef",
   "metadata": {},
   "source": [
    "<div id=\"select_freq\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108dcd38",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Select <code>frequency</code></span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to show the popup window\n",
    "frequency = show_frequency_window()\n",
    "print(\"Selected frequency:\", frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced3aee5",
   "metadata": {},
   "source": [
    "<div id=\"counter\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6390e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Set counter (dataframe name suffix)</span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1ae2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to set the counter\n",
    "if frequency == \"monthly\":\n",
    "    counter = 1\n",
    "elif frequency == \"quarterly\":\n",
    "    counter = 2\n",
    "elif frequency == \"annual\":\n",
    "    counter = 2\n",
    "else:\n",
    "    counter = None \n",
    "\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197ccc0",
   "metadata": {},
   "source": [
    "<div id=\"3-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d2a3e",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Growth rates datasets concatenation for all frequencies\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically construct the function name and dictionary name\n",
    "function_name = f\"concatenate_{frequency}_df\"\n",
    "dataframe_dict_name = f\"old_dataframes_dict_{counter}\"\n",
    "\n",
    "# Check that both the function and dictionary exist in the global scope\n",
    "if function_name in globals() and dataframe_dict_name in globals():\n",
    "    # Call the function using its reference from globals()\n",
    "    globals()[f\"old_{sector}_{frequency}_growth_rates\"] = globals()[function_name](\n",
    "        globals()[dataframe_dict_name], selected_spanish, selected_english\n",
    "    )\n",
    "else:\n",
    "    print(f\"Error: {function_name} or {dataframe_dict_name} does not exist in the global scope.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "globals()[f\"old_{sector}_{frequency}_growth_rates\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0c329",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548303d",
   "metadata": {},
   "source": [
    "<div id=\"4\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed7094",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Uploading data to SQL</span></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c749c49",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Finally, we upload all the datasets generated in this jupyter notebook to the <code>'gdp_revisions_datasets'</code> database of <code>PostgresSQL</code>.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_sqlalchemy_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e80998",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Loading\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1de733",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"old_{sector}_{frequency}_growth_rates\"].to_sql(f'old_{sector}_{frequency}_growth_rates', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e09cf",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 20px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#select_sector\" style=\"color: rgb(255, 32, 78); text-decoration: none;\"></a>\n",
    "    </span> \n",
    "    <a href=\"#select_sector\" style=\"color: rgb(255, 32, 78); text-decoration: none;\">Back to select sectors.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ebd64b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 20px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#select_freq\" style=\"color: rgb(255, 32, 78); text-decoration: none;\"></a>\n",
    "    </span> \n",
    "    <a href=\"#select_freq\" style=\"color: rgb(255, 32, 78); text-decoration: none;\">Back to select frequency.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d2a2e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4ef74",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcf35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad395983",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
