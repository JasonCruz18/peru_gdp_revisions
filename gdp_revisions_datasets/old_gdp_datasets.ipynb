{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0ee00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0953333",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter bt pro roman'; color: rgb(0, 65, 75);\">\n",
    "<h1>\n",
    "Old GDP Revisions Datasets\n",
    "</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323e5f0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter bt pro roman'; color: rgb(0, 65, 75);\">\n",
    "<h3>\n",
    "Documentation\n",
    "<br>\n",
    "____________________\n",
    "<br>\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc075bd7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'PT Serif Pro Book'; color: rgb(0, 65, 75); font-size: 16px;\">\n",
    "    Jason Cruz\n",
    "    <br>\n",
    "    <a href=\"mailto:jj.cruza@up.edu.pe\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">\n",
    "        jj.cruza@up.edu.pe\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0f23d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "This <span style=\"color: rgb(0, 65, 75);\">jupyter notebook</span> documents step-by-step the <b>construction of old datasets</b> for the project <b>'Revisions and Biases in Preliminary GDP Estimates in Peru'</b>.\n",
    "\n",
    "This jupyter notebook goes from the cleaning of the tables (Weekly Reports, WR) provided confidentially by the Central Bank to the construction of the <b>vintages</b> and <b>revisions</b> datasets from 1994-2024.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addcdf2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;line-height: 1.5;\">\n",
    "<span style=\"font-size: 24px;\">&#128196;</span> The Weekly Report/<i>Nota Semanal</i> (WR/<i>NS</i>) of the Central Bank.\n",
    "    <br>\n",
    "    <span style=\"font-size: 24px;\">&#8987;</span> Available since <b>1994-2012</b> (Table 1) and since <b>1997-2012</b> (Table 2). \n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516ae6c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Amaya; text-align: left; color: rgb(0, 65, 75); font-size:16px\">The following <b>outline is functional</b>. By utilising the provided buttons, users are able to enhance their experience by browsing this script.<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d69587",
   "metadata": {},
   "source": [
    "<div id=\"outilne\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15589700",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #292929; padding: 10px; line-height: 1.5; font-family: 'PT Serif Pro Book';\">\n",
    "    <h2 style=\"text-align: left; color: #E0E0E0;\">\n",
    "        Outline\n",
    "    </h2>\n",
    "    <br>\n",
    "    <a href=\"#libraries\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        Libraries</a>\n",
    "    <br>\n",
    "    <a href=\"#setup\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        Initial set-up</a>\n",
    "    <br>\n",
    "    <a href=\"#1\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        1. Duplicate tables for all other NS ids</a>\n",
    "    <br>\n",
    "    <a href=\"#1-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        1.1. Table 1.</a>\n",
    "    <br>\n",
    "    <a href=\"#1-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        1.2. Table 2.</a>\n",
    "    <br>\n",
    "    <a href=\"#2\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        2. Data cleaning</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        2.1. Extracting tables and data cleanup.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1-1\" style=\"color: #94FFD8; font-size: 14px; margin-left: 40px;\">\n",
    "        2.1.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1-2\" style=\"color: #94FFD8; font-size: 14px; margin-left: 40px;\">\n",
    "        2.1.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.</a>\n",
    "    <br>\n",
    "    <a href=\"#3\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">3. Real-time data of Peru's GDP growth rates</a>\n",
    "    <br>\n",
    "    <a href=\"#3-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.1. Annual vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.2. Quarterly vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-3\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.3. Monthly vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#4\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">4. GDP final revision dataset</a>\n",
    "    <br>\n",
    "    <a href=\"#4-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.1. Annual revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#4-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.2. Quarterly revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#4-3\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.3. Monthly revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#5\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">5. Uploading data to SQL</a>\n",
    "    <br>\n",
    "    <a href=\"#5-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        5.1. Vintages.</a>\n",
    "    <br>\n",
    "    <a href=\"#5-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        5.2. Revisions.</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7c4d6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    Any questions or issues regarding the coding, please email Jason Cruz <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123); text-decoration: none;\"><span style=\"font-size: 24px;\">&#x2709;</span>\n",
    "    </a>.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff8772",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    If you don't have the libraries below, please use the following code (as example) to install the required libraries.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f517f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21974a",
   "metadata": {},
   "source": [
    "<div id=\"libraries\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a752d8fe",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    <h2>\n",
    "    Libraries\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00415459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Duplicate tables for all other NS ids\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# 1.1. Table 1\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# 2. Data cleaning\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2.2. Extracting tables and data cleanup\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import unicodedata  # For manipulating Unicode data\n",
    "import re  # For regular expressions operations\n",
    "from datetime import datetime  # For working with dates and times\n",
    "import locale  # For locale-specific formatting of numbers, dates, and currencies\n",
    "import numpy as np\n",
    "import unidecode\n",
    "\n",
    "# 2.2.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "\n",
    "import tabula  # Used to extract tables from PDF files into pandas DataFrames\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO  # Used for creating graphical user interfaces\n",
    "from sqlalchemy import create_engine  # Used for connecting to and interacting with SQL databases\n",
    "\n",
    "# 2.2.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "\n",
    "import roman\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# 3. Real-time data of Peru's GDP growth rates\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import psycopg2  # For interacting with PostgreSQL databases\n",
    "from sqlalchemy import create_engine, text  # For creating and executing SQL queries using SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8167e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d73758",
   "metadata": {},
   "source": [
    "<div id=\"setup\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fbf38",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark;\">\n",
    "    <h2>\n",
    "    Initial set-up\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8675b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> Setting the base path. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f382fef7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your base path to set your main working directory, then press enter: \n",
      "C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\Research Assistant\\CIUP\\GDP Revisions\\gdp_revisions\\old_database\n",
      "Correctly defined base path.\n"
     ]
    }
   ],
   "source": [
    "# Ask the user for the base path\n",
    "base_path = input(\"Please enter your base path to set your main working directory, then press enter: \\n\")\n",
    "\n",
    "# Check if the path is valid\n",
    "if os.path.isdir(base_path):\n",
    "    print(f\"Correctly defined base path.\")\n",
    "    os.chdir(base_path)\n",
    "else:\n",
    "    print(\"The entered path is not valid. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16931de9",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    Download the <code>.zip</code> files of <code>table_1</code> and <code>table_2</code> and paste them into <code>raw_data</code> and <code>input_data</code> paths set below. \n",
    "    <p>\n",
    "     Note that the missing data will be filled in <code>input_data</code> in <a href=\"#1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Section 1</a>. Then the changes will actually occur in the <code>input_data</code> folder. However, we created <code>raw_data</code> to map the tables as they were delivered by the Central Bank, i.e. the raw data delivered (without any transformation).\n",
    "       </p>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651a1eb",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2b2ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank \n",
    "raw_data = 'raw_data' # to save raw data (.csv).\n",
    "if not os.path.exists(raw_data):\n",
    "    os.mkdir(raw_data) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31aab459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank as inputs (duplicated for all NS id) \n",
    "input_data = 'input_data' # to save input data (.csv).\n",
    "if not os.path.exists(input_data):\n",
    "    os.mkdir(input_data) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7bc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank (Table 1)\n",
    "table_1_folder = os.path.join(input_data, 'table_1') # to save raw data (.csv).\n",
    "if not os.path.exists(table_1_folder):\n",
    "    os.mkdir(table_1_folder) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cbf5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank (Table 2)\n",
    "table_2_folder = os.path.join(input_data, 'table_2') # to save raw data (.csv).\n",
    "if not os.path.exists(table_2_folder):\n",
    "    os.mkdir(table_2_folder) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6f7c71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save dataframes generated record by year\n",
    "\n",
    "dataframes_record = 'dataframes_record'\n",
    "if not os.path.exists(dataframes_record):\n",
    "    os.makedirs(dataframes_record) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb31bc",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41a493",
   "metadata": {},
   "source": [
    "<p style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following function will establish a connection to the <code>gdp_revisions_datasets</code> database in <code>PostgreSQL</code>. The <b>input data</b> used in this jupyter notebook will be loaded from this <code>PostgreSQL</code> database, and similarly, all <b>output data</b> generated by this jupyter notebook will be stored in that database. Ensure that you set the necessary parameters to access the server once you have obtained the required permissions.<p/>\n",
    "    \n",
    "<p style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "To request permissions, please email Jason Cruz <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123); text-decoration: none;\"> <span style=\"font-size: 24px;\">&#x2709;</span>\n",
    "    </a>.\n",
    "<p/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fa0789",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    <span style=\"font-size: 24px; color: #FFA823; font-weight: bold;\">&#9888;</span>\n",
    "    Enter your user credentials to acces to SQL.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c4457bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlalchemy_engine():\n",
    "    \"\"\"\n",
    "    Function to create an SQLAlchemy engine using environment variables.\n",
    "    \n",
    "    Returns:\n",
    "        engine: SQLAlchemy engine object.\n",
    "    \"\"\"\n",
    "    # Get environment variables\n",
    "    user = os.environ.get('CIUP_SQL_USER')  # Get the SQL user from environment variables\n",
    "    password = os.environ.get('CIUP_SQL_PASS')  # Get the SQL password from environment variables\n",
    "    host = os.environ.get('CIUP_SQL_HOST')  # Get the SQL host from environment variables\n",
    "    port = 5432  # Set the SQL port to 5432\n",
    "    database = 'gdp_revisions_datasets'  # Set the database name 'gdp_revisions_datasets' from SQL\n",
    "\n",
    "    # Check if all environment variables are defined\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"Some environment variables are missing (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "    # Create connection string\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8fa3d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Import all other functions required by this jupyter notebook.\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ecd38",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> Please, check the script <code>old_gdp_datasets_functions.py</code> and <code>new_gdp_datasets_functions.py</code> which contains all the functions required by this jupyter notebook. The functions there are ordered according to the <a href=\"#outilne\" style=\"color: #3d30a2;\">sections</a> of this jupyter notebok.<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3cda8404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from old_gdp_datasets_functions import *\n",
    "from new_gdp_datasets_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e10d5d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bedbd",
   "metadata": {},
   "source": [
    "<div id=\"1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54b25f",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;; color: dark;\">1.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Duplicate tables for all other NS ids</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd1034",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    <p>The Central Bank has provided us with confidential data for Table 1 (1994-2012) and Table 2 (1997-2012). However, in each year we have been provided from the tables where the revisions occurred or, more generally, where the Central Bank has received from INEI the updated information of all NS tables.</p>\n",
    "    \n",
    "   <p>So, we will duplicate these tables to complete the total NS per year (50 approximately due to the number of weeks per year).</p>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9443ed",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "The following code imports the data containing the dummies of the tables that were delivered by the Central Bank (1 if the table was delivered and 0 if it was not) from SQL \n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb719841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgresSQL\n",
    "engine = create_sqlalchemy_engine()\n",
    "\n",
    "# Define SQL query to import data\n",
    "query = f\"SELECT * FROM old_raw_data_delivered\"\n",
    "\n",
    "# Importing data into a pandas DataFrame\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d5875",
   "metadata": {},
   "source": [
    "<div id=\"1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5b4f6",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">1.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Table 1\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24dbfbbf",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please change your preferred year range\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1686bc9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing files for year 1994: {3: 'ns-03-1994.csv', 6: 'ns-06-1994.csv', 9: 'ns-09-1994.csv', 13: 'ns-13-1994.csv', 20: 'ns-20-1994.csv', 22: 'ns-22-1994.csv', 25: 'ns-25-1994.csv', 31: 'ns-31-1994.csv', 33: 'ns-33-1994.csv', 37: 'ns-37-1994.csv', 43: 'ns-43-1994.csv', 49: 'ns-49-1994.csv'}\n",
      "No existing file to duplicate for ns-01-1994.csv\n",
      "No existing file to duplicate for ns-02-1994.csv\n",
      "Using existing file ns-03-1994.csv for id_ns 3 in year 1994\n",
      "Duplicated ns-03-1994.csv to ns-04-1994.csv\n",
      "Duplicated ns-03-1994.csv to ns-05-1994.csv\n",
      "Using existing file ns-06-1994.csv for id_ns 6 in year 1994\n",
      "Duplicated ns-06-1994.csv to ns-07-1994.csv\n",
      "Duplicated ns-06-1994.csv to ns-08-1994.csv\n",
      "Using existing file ns-09-1994.csv for id_ns 9 in year 1994\n",
      "Duplicated ns-09-1994.csv to ns-10-1994.csv\n",
      "Duplicated ns-09-1994.csv to ns-11-1994.csv\n",
      "Duplicated ns-09-1994.csv to ns-12-1994.csv\n",
      "Using existing file ns-13-1994.csv for id_ns 13 in year 1994\n",
      "Duplicated ns-13-1994.csv to ns-14-1994.csv\n",
      "Duplicated ns-13-1994.csv to ns-15-1994.csv\n",
      "Duplicated ns-13-1994.csv to ns-16-1994.csv\n",
      "Duplicated ns-13-1994.csv to ns-17-1994.csv\n",
      "Duplicated ns-13-1994.csv to ns-18-1994.csv\n",
      "Duplicated ns-13-1994.csv to ns-19-1994.csv\n",
      "Using existing file ns-20-1994.csv for id_ns 20 in year 1994\n",
      "Duplicated ns-20-1994.csv to ns-21-1994.csv\n",
      "Using existing file ns-22-1994.csv for id_ns 22 in year 1994\n",
      "Duplicated ns-22-1994.csv to ns-23-1994.csv\n",
      "Duplicated ns-22-1994.csv to ns-24-1994.csv\n",
      "Using existing file ns-25-1994.csv for id_ns 25 in year 1994\n",
      "Duplicated ns-25-1994.csv to ns-26-1994.csv\n",
      "Duplicated ns-25-1994.csv to ns-27-1994.csv\n",
      "Duplicated ns-25-1994.csv to ns-28-1994.csv\n",
      "Duplicated ns-25-1994.csv to ns-29-1994.csv\n",
      "Duplicated ns-25-1994.csv to ns-30-1994.csv\n",
      "Using existing file ns-31-1994.csv for id_ns 31 in year 1994\n",
      "Duplicated ns-31-1994.csv to ns-32-1994.csv\n",
      "Using existing file ns-33-1994.csv for id_ns 33 in year 1994\n",
      "Duplicated ns-33-1994.csv to ns-34-1994.csv\n",
      "Duplicated ns-33-1994.csv to ns-35-1994.csv\n",
      "Duplicated ns-33-1994.csv to ns-36-1994.csv\n",
      "Using existing file ns-37-1994.csv for id_ns 37 in year 1994\n",
      "Duplicated ns-37-1994.csv to ns-38-1994.csv\n",
      "Duplicated ns-37-1994.csv to ns-39-1994.csv\n",
      "Duplicated ns-37-1994.csv to ns-40-1994.csv\n",
      "Duplicated ns-37-1994.csv to ns-41-1994.csv\n",
      "Duplicated ns-37-1994.csv to ns-42-1994.csv\n",
      "Using existing file ns-43-1994.csv for id_ns 43 in year 1994\n",
      "Duplicated ns-43-1994.csv to ns-44-1994.csv\n",
      "Duplicated ns-43-1994.csv to ns-45-1994.csv\n",
      "Duplicated ns-43-1994.csv to ns-46-1994.csv\n",
      "Duplicated ns-43-1994.csv to ns-47-1994.csv\n",
      "Duplicated ns-43-1994.csv to ns-48-1994.csv\n",
      "Using existing file ns-49-1994.csv for id_ns 49 in year 1994\n",
      "Existing files for year 1995: {1: 'ns-01-1995.csv', 7: 'ns-07-1995.csv', 13: 'ns-13-1995.csv', 16: 'ns-16-1995.csv', 20: 'ns-20-1995.csv', 25: 'ns-25-1995.csv', 27: 'ns-27-1995.csv', 31: 'ns-31-1995.csv', 38: 'ns-38-1995.csv', 43: 'ns-43-1995.csv', 44: 'ns-44-1995.csv', 48: 'ns-48-1995.csv'}\n",
      "Using existing file ns-01-1995.csv for id_ns 1 in year 1995\n",
      "Duplicated ns-01-1995.csv to ns-02-1995.csv\n",
      "Duplicated ns-01-1995.csv to ns-03-1995.csv\n",
      "Duplicated ns-01-1995.csv to ns-04-1995.csv\n",
      "Duplicated ns-01-1995.csv to ns-05-1995.csv\n",
      "Duplicated ns-01-1995.csv to ns-06-1995.csv\n",
      "Using existing file ns-07-1995.csv for id_ns 7 in year 1995\n",
      "Duplicated ns-07-1995.csv to ns-08-1995.csv\n",
      "Duplicated ns-07-1995.csv to ns-09-1995.csv\n",
      "Duplicated ns-07-1995.csv to ns-10-1995.csv\n",
      "Duplicated ns-07-1995.csv to ns-11-1995.csv\n",
      "Duplicated ns-07-1995.csv to ns-12-1995.csv\n",
      "Using existing file ns-13-1995.csv for id_ns 13 in year 1995\n",
      "Duplicated ns-13-1995.csv to ns-14-1995.csv\n",
      "Duplicated ns-13-1995.csv to ns-15-1995.csv\n",
      "Using existing file ns-16-1995.csv for id_ns 16 in year 1995\n",
      "Duplicated ns-16-1995.csv to ns-17-1995.csv\n",
      "Duplicated ns-16-1995.csv to ns-18-1995.csv\n",
      "Duplicated ns-16-1995.csv to ns-19-1995.csv\n",
      "Using existing file ns-20-1995.csv for id_ns 20 in year 1995\n",
      "Duplicated ns-20-1995.csv to ns-21-1995.csv\n",
      "Duplicated ns-20-1995.csv to ns-22-1995.csv\n",
      "Duplicated ns-20-1995.csv to ns-23-1995.csv\n",
      "Duplicated ns-20-1995.csv to ns-24-1995.csv\n",
      "Using existing file ns-25-1995.csv for id_ns 25 in year 1995\n",
      "Duplicated ns-25-1995.csv to ns-26-1995.csv\n",
      "Using existing file ns-27-1995.csv for id_ns 27 in year 1995\n",
      "Duplicated ns-27-1995.csv to ns-28-1995.csv\n",
      "Duplicated ns-27-1995.csv to ns-29-1995.csv\n",
      "Duplicated ns-27-1995.csv to ns-30-1995.csv\n",
      "Using existing file ns-31-1995.csv for id_ns 31 in year 1995\n",
      "Duplicated ns-31-1995.csv to ns-32-1995.csv\n",
      "Duplicated ns-31-1995.csv to ns-33-1995.csv\n",
      "Duplicated ns-31-1995.csv to ns-34-1995.csv\n",
      "Duplicated ns-31-1995.csv to ns-35-1995.csv\n",
      "Duplicated ns-31-1995.csv to ns-36-1995.csv\n",
      "Duplicated ns-31-1995.csv to ns-37-1995.csv\n",
      "Using existing file ns-38-1995.csv for id_ns 38 in year 1995\n",
      "Duplicated ns-38-1995.csv to ns-39-1995.csv\n",
      "Duplicated ns-38-1995.csv to ns-40-1995.csv\n",
      "Duplicated ns-38-1995.csv to ns-41-1995.csv\n",
      "Duplicated ns-38-1995.csv to ns-42-1995.csv\n",
      "Using existing file ns-43-1995.csv for id_ns 43 in year 1995\n",
      "Using existing file ns-44-1995.csv for id_ns 44 in year 1995\n",
      "Duplicated ns-44-1995.csv to ns-45-1995.csv\n",
      "Duplicated ns-44-1995.csv to ns-46-1995.csv\n",
      "Duplicated ns-44-1995.csv to ns-47-1995.csv\n",
      "Using existing file ns-48-1995.csv for id_ns 48 in year 1995\n",
      "Duplicated ns-48-1995.csv to ns-49-1995.csv\n",
      "Duplicated ns-48-1995.csv to ns-50-1995.csv\n",
      "Duplicated ns-48-1995.csv to ns-51-1995.csv\n",
      "Existing files for year 1996: {5: 'ns-05-1996.csv', 9: 'ns-09-1996.csv', 10: 'ns-10-1996.csv', 15: 'ns-15-1996.csv', 18: 'ns-18-1996.csv', 22: 'ns-22-1996.csv', 27: 'ns-27-1996.csv', 35: 'ns-35-1996.csv', 39: 'ns-39-1996.csv', 41: 'ns-41-1996.csv', 44: 'ns-44-1996.csv', 49: 'ns-49-1996.csv'}\n",
      "Duplicated ns-51-1995.csv to ns-01-1996.csv\n",
      "Duplicated ns-51-1995.csv to ns-02-1996.csv\n",
      "Duplicated ns-51-1995.csv to ns-03-1996.csv\n",
      "Duplicated ns-51-1995.csv to ns-04-1996.csv\n",
      "Using existing file ns-05-1996.csv for id_ns 5 in year 1996\n",
      "Duplicated ns-05-1996.csv to ns-06-1996.csv\n",
      "Duplicated ns-05-1996.csv to ns-07-1996.csv\n",
      "Duplicated ns-05-1996.csv to ns-08-1996.csv\n",
      "Using existing file ns-09-1996.csv for id_ns 9 in year 1996\n",
      "Using existing file ns-10-1996.csv for id_ns 10 in year 1996\n",
      "Duplicated ns-10-1996.csv to ns-11-1996.csv\n",
      "Duplicated ns-10-1996.csv to ns-12-1996.csv\n",
      "Duplicated ns-10-1996.csv to ns-13-1996.csv\n",
      "Duplicated ns-10-1996.csv to ns-14-1996.csv\n",
      "Using existing file ns-15-1996.csv for id_ns 15 in year 1996\n",
      "Duplicated ns-15-1996.csv to ns-16-1996.csv\n",
      "Duplicated ns-15-1996.csv to ns-17-1996.csv\n",
      "Using existing file ns-18-1996.csv for id_ns 18 in year 1996\n",
      "Duplicated ns-18-1996.csv to ns-19-1996.csv\n",
      "Duplicated ns-18-1996.csv to ns-20-1996.csv\n",
      "Duplicated ns-18-1996.csv to ns-21-1996.csv\n",
      "Using existing file ns-22-1996.csv for id_ns 22 in year 1996\n",
      "Duplicated ns-22-1996.csv to ns-23-1996.csv\n",
      "Duplicated ns-22-1996.csv to ns-24-1996.csv\n",
      "Duplicated ns-22-1996.csv to ns-25-1996.csv\n",
      "Duplicated ns-22-1996.csv to ns-26-1996.csv\n",
      "Using existing file ns-27-1996.csv for id_ns 27 in year 1996\n",
      "Duplicated ns-27-1996.csv to ns-28-1996.csv\n",
      "Duplicated ns-27-1996.csv to ns-29-1996.csv\n",
      "Duplicated ns-27-1996.csv to ns-30-1996.csv\n",
      "Duplicated ns-27-1996.csv to ns-31-1996.csv\n",
      "Duplicated ns-27-1996.csv to ns-32-1996.csv\n",
      "Duplicated ns-27-1996.csv to ns-33-1996.csv\n",
      "Duplicated ns-27-1996.csv to ns-34-1996.csv\n",
      "Using existing file ns-35-1996.csv for id_ns 35 in year 1996\n",
      "Duplicated ns-35-1996.csv to ns-36-1996.csv\n",
      "Duplicated ns-35-1996.csv to ns-37-1996.csv\n",
      "Duplicated ns-35-1996.csv to ns-38-1996.csv\n",
      "Using existing file ns-39-1996.csv for id_ns 39 in year 1996\n",
      "Duplicated ns-39-1996.csv to ns-40-1996.csv\n",
      "Using existing file ns-41-1996.csv for id_ns 41 in year 1996\n",
      "Duplicated ns-41-1996.csv to ns-42-1996.csv\n",
      "Duplicated ns-41-1996.csv to ns-43-1996.csv\n",
      "Using existing file ns-44-1996.csv for id_ns 44 in year 1996\n",
      "Duplicated ns-44-1996.csv to ns-45-1996.csv\n",
      "Duplicated ns-44-1996.csv to ns-46-1996.csv\n",
      "Duplicated ns-44-1996.csv to ns-47-1996.csv\n",
      "Duplicated ns-44-1996.csv to ns-48-1996.csv\n",
      "Using existing file ns-49-1996.csv for id_ns 49 in year 1996\n",
      "Duplicated ns-49-1996.csv to ns-50-1996.csv\n",
      "Duplicated ns-49-1996.csv to ns-51-1996.csv\n",
      "Duplicated ns-49-1996.csv to ns-52-1996.csv\n",
      "Existing files for year 1997: {2: 'ns-02-1997.csv', 6: 'ns-06-1997.csv', 10: 'ns-10-1997.csv', 11: 'ns-11-1997.csv', 15: 'ns-15-1997.csv', 19: 'ns-19-1997.csv', 25: 'ns-25-1997.csv', 26: 'ns-26-1997.csv', 32: 'ns-32-1997.csv', 37: 'ns-37-1997.csv', 38: 'ns-38-1997.csv', 42: 'ns-42-1997.csv', 48: 'ns-48-1997.csv'}\n",
      "Duplicated ns-52-1996.csv to ns-01-1997.csv\n",
      "Using existing file ns-02-1997.csv for id_ns 2 in year 1997\n",
      "Duplicated ns-02-1997.csv to ns-03-1997.csv\n",
      "Duplicated ns-02-1997.csv to ns-04-1997.csv\n",
      "Duplicated ns-02-1997.csv to ns-05-1997.csv\n",
      "Using existing file ns-06-1997.csv for id_ns 6 in year 1997\n",
      "Duplicated ns-06-1997.csv to ns-07-1997.csv\n",
      "Duplicated ns-06-1997.csv to ns-08-1997.csv\n",
      "Duplicated ns-06-1997.csv to ns-09-1997.csv\n",
      "Using existing file ns-10-1997.csv for id_ns 10 in year 1997\n",
      "Using existing file ns-11-1997.csv for id_ns 11 in year 1997\n",
      "Duplicated ns-11-1997.csv to ns-12-1997.csv\n",
      "Duplicated ns-11-1997.csv to ns-13-1997.csv\n",
      "Duplicated ns-11-1997.csv to ns-14-1997.csv\n",
      "Using existing file ns-15-1997.csv for id_ns 15 in year 1997\n",
      "Duplicated ns-15-1997.csv to ns-16-1997.csv\n",
      "Duplicated ns-15-1997.csv to ns-17-1997.csv\n",
      "Duplicated ns-15-1997.csv to ns-18-1997.csv\n",
      "Using existing file ns-19-1997.csv for id_ns 19 in year 1997\n",
      "Duplicated ns-19-1997.csv to ns-20-1997.csv\n",
      "Duplicated ns-19-1997.csv to ns-21-1997.csv\n",
      "Duplicated ns-19-1997.csv to ns-22-1997.csv\n",
      "Duplicated ns-19-1997.csv to ns-23-1997.csv\n",
      "Duplicated ns-19-1997.csv to ns-24-1997.csv\n",
      "Using existing file ns-25-1997.csv for id_ns 25 in year 1997\n",
      "Using existing file ns-26-1997.csv for id_ns 26 in year 1997\n",
      "Duplicated ns-26-1997.csv to ns-27-1997.csv\n",
      "Duplicated ns-26-1997.csv to ns-28-1997.csv\n",
      "Duplicated ns-26-1997.csv to ns-29-1997.csv\n",
      "Duplicated ns-26-1997.csv to ns-30-1997.csv\n",
      "Duplicated ns-26-1997.csv to ns-31-1997.csv\n",
      "Using existing file ns-32-1997.csv for id_ns 32 in year 1997\n",
      "Duplicated ns-32-1997.csv to ns-33-1997.csv\n",
      "Duplicated ns-32-1997.csv to ns-34-1997.csv\n",
      "Duplicated ns-32-1997.csv to ns-35-1997.csv\n",
      "Duplicated ns-32-1997.csv to ns-36-1997.csv\n",
      "Using existing file ns-37-1997.csv for id_ns 37 in year 1997\n",
      "Using existing file ns-38-1997.csv for id_ns 38 in year 1997\n",
      "Duplicated ns-38-1997.csv to ns-39-1997.csv\n",
      "Duplicated ns-38-1997.csv to ns-40-1997.csv\n",
      "Duplicated ns-38-1997.csv to ns-41-1997.csv\n",
      "Using existing file ns-42-1997.csv for id_ns 42 in year 1997\n",
      "Duplicated ns-42-1997.csv to ns-43-1997.csv\n",
      "Duplicated ns-42-1997.csv to ns-44-1997.csv\n",
      "Duplicated ns-42-1997.csv to ns-45-1997.csv\n",
      "Duplicated ns-42-1997.csv to ns-46-1997.csv\n",
      "Duplicated ns-42-1997.csv to ns-47-1997.csv\n",
      "Using existing file ns-48-1997.csv for id_ns 48 in year 1997\n",
      "Duplicated ns-48-1997.csv to ns-49-1997.csv\n",
      "Existing files for year 1998: {4: 'ns-04-1998.csv', 6: 'ns-06-1998.csv', 13: 'ns-13-1998.csv', 14: 'ns-14-1998.csv', 20: 'ns-20-1998.csv', 24: 'ns-24-1998.csv', 29: 'ns-29-1998.csv', 31: 'ns-31-1998.csv', 35: 'ns-35-1998.csv', 42: 'ns-42-1998.csv', 45: 'ns-45-1998.csv', 47: 'ns-47-1998.csv'}\n",
      "Duplicated ns-49-1997.csv to ns-01-1998.csv\n",
      "Duplicated ns-49-1997.csv to ns-02-1998.csv\n",
      "Duplicated ns-49-1997.csv to ns-03-1998.csv\n",
      "Using existing file ns-04-1998.csv for id_ns 4 in year 1998\n",
      "Duplicated ns-04-1998.csv to ns-05-1998.csv\n",
      "Using existing file ns-06-1998.csv for id_ns 6 in year 1998\n",
      "Duplicated ns-06-1998.csv to ns-07-1998.csv\n",
      "Duplicated ns-06-1998.csv to ns-08-1998.csv\n",
      "Duplicated ns-06-1998.csv to ns-09-1998.csv\n",
      "Duplicated ns-06-1998.csv to ns-10-1998.csv\n",
      "Duplicated ns-06-1998.csv to ns-11-1998.csv\n",
      "Duplicated ns-06-1998.csv to ns-12-1998.csv\n",
      "Using existing file ns-13-1998.csv for id_ns 13 in year 1998\n",
      "Using existing file ns-14-1998.csv for id_ns 14 in year 1998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated ns-14-1998.csv to ns-15-1998.csv\n",
      "Duplicated ns-14-1998.csv to ns-16-1998.csv\n",
      "Duplicated ns-14-1998.csv to ns-17-1998.csv\n",
      "Duplicated ns-14-1998.csv to ns-18-1998.csv\n",
      "Duplicated ns-14-1998.csv to ns-19-1998.csv\n",
      "Using existing file ns-20-1998.csv for id_ns 20 in year 1998\n",
      "Duplicated ns-20-1998.csv to ns-21-1998.csv\n",
      "Duplicated ns-20-1998.csv to ns-22-1998.csv\n",
      "Duplicated ns-20-1998.csv to ns-23-1998.csv\n",
      "Using existing file ns-24-1998.csv for id_ns 24 in year 1998\n",
      "Duplicated ns-24-1998.csv to ns-25-1998.csv\n",
      "Duplicated ns-24-1998.csv to ns-26-1998.csv\n",
      "Duplicated ns-24-1998.csv to ns-27-1998.csv\n",
      "Duplicated ns-24-1998.csv to ns-28-1998.csv\n",
      "Using existing file ns-29-1998.csv for id_ns 29 in year 1998\n",
      "Duplicated ns-29-1998.csv to ns-30-1998.csv\n",
      "Using existing file ns-31-1998.csv for id_ns 31 in year 1998\n",
      "Duplicated ns-31-1998.csv to ns-32-1998.csv\n",
      "Duplicated ns-31-1998.csv to ns-33-1998.csv\n",
      "Duplicated ns-31-1998.csv to ns-34-1998.csv\n",
      "Using existing file ns-35-1998.csv for id_ns 35 in year 1998\n",
      "Duplicated ns-35-1998.csv to ns-36-1998.csv\n",
      "Duplicated ns-35-1998.csv to ns-37-1998.csv\n",
      "Duplicated ns-35-1998.csv to ns-38-1998.csv\n",
      "Duplicated ns-35-1998.csv to ns-39-1998.csv\n",
      "Duplicated ns-35-1998.csv to ns-40-1998.csv\n",
      "Duplicated ns-35-1998.csv to ns-41-1998.csv\n",
      "Using existing file ns-42-1998.csv for id_ns 42 in year 1998\n",
      "Duplicated ns-42-1998.csv to ns-43-1998.csv\n",
      "Duplicated ns-42-1998.csv to ns-44-1998.csv\n",
      "Using existing file ns-45-1998.csv for id_ns 45 in year 1998\n",
      "Duplicated ns-45-1998.csv to ns-46-1998.csv\n",
      "Using existing file ns-47-1998.csv for id_ns 47 in year 1998\n",
      "Duplicated ns-47-1998.csv to ns-48-1998.csv\n",
      "Duplicated ns-47-1998.csv to ns-49-1998.csv\n",
      "Existing files for year 1999: {5: 'ns-05-1999.csv', 9: 'ns-09-1999.csv', 13: 'ns-13-1999.csv', 17: 'ns-17-1999.csv', 18: 'ns-18-1999.csv', 25: 'ns-25-1999.csv', 29: 'ns-29-1999.csv', 30: 'ns-30-1999.csv', 37: 'ns-37-1999.csv', 38: 'ns-38-1999.csv', 39: 'ns-39-1999.csv', 44: 'ns-44-1999.csv', 46: 'ns-46-1999.csv', 47: 'ns-47-1999.csv', 48: 'ns-48-1999.csv'}\n",
      "Duplicated ns-49-1998.csv to ns-01-1999.csv\n",
      "Duplicated ns-49-1998.csv to ns-02-1999.csv\n",
      "Duplicated ns-49-1998.csv to ns-03-1999.csv\n",
      "Duplicated ns-49-1998.csv to ns-04-1999.csv\n",
      "Using existing file ns-05-1999.csv for id_ns 5 in year 1999\n",
      "Duplicated ns-05-1999.csv to ns-06-1999.csv\n",
      "Duplicated ns-05-1999.csv to ns-07-1999.csv\n",
      "Duplicated ns-05-1999.csv to ns-08-1999.csv\n",
      "Using existing file ns-09-1999.csv for id_ns 9 in year 1999\n",
      "Duplicated ns-09-1999.csv to ns-10-1999.csv\n",
      "Duplicated ns-09-1999.csv to ns-11-1999.csv\n",
      "Duplicated ns-09-1999.csv to ns-12-1999.csv\n",
      "Using existing file ns-13-1999.csv for id_ns 13 in year 1999\n",
      "Duplicated ns-13-1999.csv to ns-14-1999.csv\n",
      "Duplicated ns-13-1999.csv to ns-15-1999.csv\n",
      "Duplicated ns-13-1999.csv to ns-16-1999.csv\n",
      "Using existing file ns-17-1999.csv for id_ns 17 in year 1999\n",
      "Using existing file ns-18-1999.csv for id_ns 18 in year 1999\n",
      "Duplicated ns-18-1999.csv to ns-19-1999.csv\n",
      "Duplicated ns-18-1999.csv to ns-20-1999.csv\n",
      "Duplicated ns-18-1999.csv to ns-21-1999.csv\n",
      "Duplicated ns-18-1999.csv to ns-22-1999.csv\n",
      "Duplicated ns-18-1999.csv to ns-23-1999.csv\n",
      "Duplicated ns-18-1999.csv to ns-24-1999.csv\n",
      "Using existing file ns-25-1999.csv for id_ns 25 in year 1999\n",
      "Duplicated ns-25-1999.csv to ns-26-1999.csv\n",
      "Duplicated ns-25-1999.csv to ns-27-1999.csv\n",
      "Duplicated ns-25-1999.csv to ns-28-1999.csv\n",
      "Using existing file ns-29-1999.csv for id_ns 29 in year 1999\n",
      "Using existing file ns-30-1999.csv for id_ns 30 in year 1999\n",
      "Duplicated ns-30-1999.csv to ns-31-1999.csv\n",
      "Duplicated ns-30-1999.csv to ns-32-1999.csv\n",
      "Duplicated ns-30-1999.csv to ns-33-1999.csv\n",
      "Duplicated ns-30-1999.csv to ns-34-1999.csv\n",
      "Duplicated ns-30-1999.csv to ns-35-1999.csv\n",
      "Duplicated ns-30-1999.csv to ns-36-1999.csv\n",
      "Using existing file ns-37-1999.csv for id_ns 37 in year 1999\n",
      "Using existing file ns-38-1999.csv for id_ns 38 in year 1999\n",
      "Using existing file ns-39-1999.csv for id_ns 39 in year 1999\n",
      "Duplicated ns-39-1999.csv to ns-40-1999.csv\n",
      "Duplicated ns-39-1999.csv to ns-41-1999.csv\n",
      "Duplicated ns-39-1999.csv to ns-42-1999.csv\n",
      "Duplicated ns-39-1999.csv to ns-43-1999.csv\n",
      "Using existing file ns-44-1999.csv for id_ns 44 in year 1999\n",
      "Duplicated ns-44-1999.csv to ns-45-1999.csv\n",
      "Using existing file ns-46-1999.csv for id_ns 46 in year 1999\n",
      "Using existing file ns-47-1999.csv for id_ns 47 in year 1999\n",
      "Using existing file ns-48-1999.csv for id_ns 48 in year 1999\n",
      "Duplicated ns-48-1999.csv to ns-49-1999.csv\n",
      "Duplicated ns-48-1999.csv to ns-50-1999.csv\n",
      "Existing files for year 2000: {1: 'ns-01-2000.csv', 4: 'ns-04-2000.csv', 7: 'ns-07-2000.csv', 11: 'ns-11-2000.csv', 14: 'ns-14-2000.csv', 19: 'ns-19-2000.csv', 22: 'ns-22-2000.csv', 28: 'ns-28-2000.csv', 32: 'ns-32-2000.csv', 38: 'ns-38-2000.csv', 42: 'ns-42-2000.csv', 46: 'ns-46-2000.csv', 49: 'ns-49-2000.csv'}\n",
      "Using existing file ns-01-2000.csv for id_ns 1 in year 2000\n",
      "Duplicated ns-01-2000.csv to ns-02-2000.csv\n",
      "Duplicated ns-01-2000.csv to ns-03-2000.csv\n",
      "Using existing file ns-04-2000.csv for id_ns 4 in year 2000\n",
      "Duplicated ns-04-2000.csv to ns-05-2000.csv\n",
      "Duplicated ns-04-2000.csv to ns-06-2000.csv\n",
      "Using existing file ns-07-2000.csv for id_ns 7 in year 2000\n",
      "Duplicated ns-07-2000.csv to ns-08-2000.csv\n",
      "Duplicated ns-07-2000.csv to ns-09-2000.csv\n",
      "Duplicated ns-07-2000.csv to ns-10-2000.csv\n",
      "Using existing file ns-11-2000.csv for id_ns 11 in year 2000\n",
      "Duplicated ns-11-2000.csv to ns-12-2000.csv\n",
      "Duplicated ns-11-2000.csv to ns-13-2000.csv\n",
      "Using existing file ns-14-2000.csv for id_ns 14 in year 2000\n",
      "Duplicated ns-14-2000.csv to ns-15-2000.csv\n",
      "Duplicated ns-14-2000.csv to ns-16-2000.csv\n",
      "Duplicated ns-14-2000.csv to ns-17-2000.csv\n",
      "Duplicated ns-14-2000.csv to ns-18-2000.csv\n",
      "Using existing file ns-19-2000.csv for id_ns 19 in year 2000\n",
      "Duplicated ns-19-2000.csv to ns-20-2000.csv\n",
      "Duplicated ns-19-2000.csv to ns-21-2000.csv\n",
      "Using existing file ns-22-2000.csv for id_ns 22 in year 2000\n",
      "Duplicated ns-22-2000.csv to ns-23-2000.csv\n",
      "Duplicated ns-22-2000.csv to ns-24-2000.csv\n",
      "Duplicated ns-22-2000.csv to ns-25-2000.csv\n",
      "Duplicated ns-22-2000.csv to ns-26-2000.csv\n",
      "Duplicated ns-22-2000.csv to ns-27-2000.csv\n",
      "Using existing file ns-28-2000.csv for id_ns 28 in year 2000\n",
      "Duplicated ns-28-2000.csv to ns-29-2000.csv\n",
      "Duplicated ns-28-2000.csv to ns-30-2000.csv\n",
      "Duplicated ns-28-2000.csv to ns-31-2000.csv\n",
      "Using existing file ns-32-2000.csv for id_ns 32 in year 2000\n",
      "Duplicated ns-32-2000.csv to ns-33-2000.csv\n",
      "Duplicated ns-32-2000.csv to ns-34-2000.csv\n",
      "Duplicated ns-32-2000.csv to ns-35-2000.csv\n",
      "Duplicated ns-32-2000.csv to ns-36-2000.csv\n",
      "Duplicated ns-32-2000.csv to ns-37-2000.csv\n",
      "Using existing file ns-38-2000.csv for id_ns 38 in year 2000\n",
      "Duplicated ns-38-2000.csv to ns-39-2000.csv\n",
      "Duplicated ns-38-2000.csv to ns-40-2000.csv\n",
      "Duplicated ns-38-2000.csv to ns-41-2000.csv\n",
      "Using existing file ns-42-2000.csv for id_ns 42 in year 2000\n",
      "Duplicated ns-42-2000.csv to ns-43-2000.csv\n",
      "Duplicated ns-42-2000.csv to ns-44-2000.csv\n",
      "Duplicated ns-42-2000.csv to ns-45-2000.csv\n",
      "Using existing file ns-46-2000.csv for id_ns 46 in year 2000\n",
      "Duplicated ns-46-2000.csv to ns-47-2000.csv\n",
      "Duplicated ns-46-2000.csv to ns-48-2000.csv\n",
      "Using existing file ns-49-2000.csv for id_ns 49 in year 2000\n",
      "Existing files for year 2001: {1: 'ns-01-2001.csv', 5: 'ns-05-2001.csv', 8: 'ns-08-2001.csv', 10: 'ns-10-2001.csv', 16: 'ns-16-2001.csv', 18: 'ns-18-2001.csv', 25: 'ns-25-2001.csv', 26: 'ns-26-2001.csv', 32: 'ns-32-2001.csv', 34: 'ns-34-2001.csv', 39: 'ns-39-2001.csv', 43: 'ns-43-2001.csv', 48: 'ns-48-2001.csv'}\n",
      "Using existing file ns-01-2001.csv for id_ns 1 in year 2001\n",
      "Duplicated ns-01-2001.csv to ns-02-2001.csv\n",
      "Duplicated ns-01-2001.csv to ns-03-2001.csv\n",
      "Duplicated ns-01-2001.csv to ns-04-2001.csv\n",
      "Using existing file ns-05-2001.csv for id_ns 5 in year 2001\n",
      "Duplicated ns-05-2001.csv to ns-06-2001.csv\n",
      "Duplicated ns-05-2001.csv to ns-07-2001.csv\n",
      "Using existing file ns-08-2001.csv for id_ns 8 in year 2001\n",
      "Duplicated ns-08-2001.csv to ns-09-2001.csv\n",
      "Using existing file ns-10-2001.csv for id_ns 10 in year 2001\n",
      "Duplicated ns-10-2001.csv to ns-11-2001.csv\n",
      "Duplicated ns-10-2001.csv to ns-12-2001.csv\n",
      "Duplicated ns-10-2001.csv to ns-13-2001.csv\n",
      "Duplicated ns-10-2001.csv to ns-14-2001.csv\n",
      "Duplicated ns-10-2001.csv to ns-15-2001.csv\n",
      "Using existing file ns-16-2001.csv for id_ns 16 in year 2001\n",
      "Duplicated ns-16-2001.csv to ns-17-2001.csv\n",
      "Using existing file ns-18-2001.csv for id_ns 18 in year 2001\n",
      "Duplicated ns-18-2001.csv to ns-19-2001.csv\n",
      "Duplicated ns-18-2001.csv to ns-20-2001.csv\n",
      "Duplicated ns-18-2001.csv to ns-21-2001.csv\n",
      "Duplicated ns-18-2001.csv to ns-22-2001.csv\n",
      "Duplicated ns-18-2001.csv to ns-23-2001.csv\n",
      "Duplicated ns-18-2001.csv to ns-24-2001.csv\n",
      "Using existing file ns-25-2001.csv for id_ns 25 in year 2001\n",
      "Using existing file ns-26-2001.csv for id_ns 26 in year 2001\n",
      "Duplicated ns-26-2001.csv to ns-27-2001.csv\n",
      "Duplicated ns-26-2001.csv to ns-28-2001.csv\n",
      "Duplicated ns-26-2001.csv to ns-29-2001.csv\n",
      "Duplicated ns-26-2001.csv to ns-30-2001.csv\n",
      "Duplicated ns-26-2001.csv to ns-31-2001.csv\n",
      "Using existing file ns-32-2001.csv for id_ns 32 in year 2001\n",
      "Duplicated ns-32-2001.csv to ns-33-2001.csv\n",
      "Using existing file ns-34-2001.csv for id_ns 34 in year 2001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated ns-34-2001.csv to ns-35-2001.csv\n",
      "Duplicated ns-34-2001.csv to ns-36-2001.csv\n",
      "Duplicated ns-34-2001.csv to ns-37-2001.csv\n",
      "Duplicated ns-34-2001.csv to ns-38-2001.csv\n",
      "Using existing file ns-39-2001.csv for id_ns 39 in year 2001\n",
      "Duplicated ns-39-2001.csv to ns-40-2001.csv\n",
      "Duplicated ns-39-2001.csv to ns-41-2001.csv\n",
      "Duplicated ns-39-2001.csv to ns-42-2001.csv\n",
      "Using existing file ns-43-2001.csv for id_ns 43 in year 2001\n",
      "Duplicated ns-43-2001.csv to ns-44-2001.csv\n",
      "Duplicated ns-43-2001.csv to ns-45-2001.csv\n",
      "Duplicated ns-43-2001.csv to ns-46-2001.csv\n",
      "Duplicated ns-43-2001.csv to ns-47-2001.csv\n",
      "Using existing file ns-48-2001.csv for id_ns 48 in year 2001\n",
      "Existing files for year 2002: {2: 'ns-02-2002.csv', 7: 'ns-07-2002.csv', 8: 'ns-08-2002.csv', 11: 'ns-11-2002.csv', 14: 'ns-14-2002.csv', 18: 'ns-18-2002.csv', 23: 'ns-23-2002.csv', 27: 'ns-27-2002.csv', 31: 'ns-31-2002.csv', 33: 'ns-33-2002.csv', 36: 'ns-36-2002.csv', 40: 'ns-40-2002.csv', 46: 'ns-46-2002.csv', 49: 'ns-49-2002.csv'}\n",
      "Duplicated ns-48-2001.csv to ns-01-2002.csv\n",
      "Using existing file ns-02-2002.csv for id_ns 2 in year 2002\n",
      "Duplicated ns-02-2002.csv to ns-03-2002.csv\n",
      "Duplicated ns-02-2002.csv to ns-04-2002.csv\n",
      "Duplicated ns-02-2002.csv to ns-05-2002.csv\n",
      "Duplicated ns-02-2002.csv to ns-06-2002.csv\n",
      "Using existing file ns-07-2002.csv for id_ns 7 in year 2002\n",
      "Using existing file ns-08-2002.csv for id_ns 8 in year 2002\n",
      "Duplicated ns-08-2002.csv to ns-09-2002.csv\n",
      "Duplicated ns-08-2002.csv to ns-10-2002.csv\n",
      "Using existing file ns-11-2002.csv for id_ns 11 in year 2002\n",
      "Duplicated ns-11-2002.csv to ns-12-2002.csv\n",
      "Duplicated ns-11-2002.csv to ns-13-2002.csv\n",
      "Using existing file ns-14-2002.csv for id_ns 14 in year 2002\n",
      "Duplicated ns-14-2002.csv to ns-15-2002.csv\n",
      "Duplicated ns-14-2002.csv to ns-16-2002.csv\n",
      "Duplicated ns-14-2002.csv to ns-17-2002.csv\n",
      "Using existing file ns-18-2002.csv for id_ns 18 in year 2002\n",
      "Duplicated ns-18-2002.csv to ns-19-2002.csv\n",
      "Duplicated ns-18-2002.csv to ns-20-2002.csv\n",
      "Duplicated ns-18-2002.csv to ns-21-2002.csv\n",
      "Duplicated ns-18-2002.csv to ns-22-2002.csv\n",
      "Using existing file ns-23-2002.csv for id_ns 23 in year 2002\n",
      "Duplicated ns-23-2002.csv to ns-24-2002.csv\n",
      "Duplicated ns-23-2002.csv to ns-25-2002.csv\n",
      "Duplicated ns-23-2002.csv to ns-26-2002.csv\n",
      "Using existing file ns-27-2002.csv for id_ns 27 in year 2002\n",
      "Duplicated ns-27-2002.csv to ns-28-2002.csv\n",
      "Duplicated ns-27-2002.csv to ns-29-2002.csv\n",
      "Duplicated ns-27-2002.csv to ns-30-2002.csv\n",
      "Using existing file ns-31-2002.csv for id_ns 31 in year 2002\n",
      "Duplicated ns-31-2002.csv to ns-32-2002.csv\n",
      "Using existing file ns-33-2002.csv for id_ns 33 in year 2002\n",
      "Duplicated ns-33-2002.csv to ns-34-2002.csv\n",
      "Duplicated ns-33-2002.csv to ns-35-2002.csv\n",
      "Using existing file ns-36-2002.csv for id_ns 36 in year 2002\n",
      "Duplicated ns-36-2002.csv to ns-37-2002.csv\n",
      "Duplicated ns-36-2002.csv to ns-38-2002.csv\n",
      "Duplicated ns-36-2002.csv to ns-39-2002.csv\n",
      "Using existing file ns-40-2002.csv for id_ns 40 in year 2002\n",
      "Duplicated ns-40-2002.csv to ns-41-2002.csv\n",
      "Duplicated ns-40-2002.csv to ns-42-2002.csv\n",
      "Duplicated ns-40-2002.csv to ns-43-2002.csv\n",
      "Duplicated ns-40-2002.csv to ns-44-2002.csv\n",
      "Duplicated ns-40-2002.csv to ns-45-2002.csv\n",
      "Using existing file ns-46-2002.csv for id_ns 46 in year 2002\n",
      "Duplicated ns-46-2002.csv to ns-47-2002.csv\n",
      "Duplicated ns-46-2002.csv to ns-48-2002.csv\n",
      "Using existing file ns-49-2002.csv for id_ns 49 in year 2002\n",
      "Duplicated ns-49-2002.csv to ns-50-2002.csv\n",
      "Duplicated ns-49-2002.csv to ns-51-2002.csv\n",
      "Existing files for year 2003: {2: 'ns-02-2003.csv', 7: 'ns-07-2003.csv', 8: 'ns-08-2003.csv', 11: 'ns-11-2003.csv', 15: 'ns-15-2003.csv', 19: 'ns-19-2003.csv', 23: 'ns-23-2003.csv', 24: 'ns-24-2003.csv', 27: 'ns-27-2003.csv', 31: 'ns-31-2003.csv', 35: 'ns-35-2003.csv', 39: 'ns-39-2003.csv', 44: 'ns-44-2003.csv', 48: 'ns-48-2003.csv'}\n",
      "Duplicated ns-51-2002.csv to ns-01-2003.csv\n",
      "Using existing file ns-02-2003.csv for id_ns 2 in year 2003\n",
      "Duplicated ns-02-2003.csv to ns-03-2003.csv\n",
      "Duplicated ns-02-2003.csv to ns-04-2003.csv\n",
      "Duplicated ns-02-2003.csv to ns-05-2003.csv\n",
      "Duplicated ns-02-2003.csv to ns-06-2003.csv\n",
      "Using existing file ns-07-2003.csv for id_ns 7 in year 2003\n",
      "Using existing file ns-08-2003.csv for id_ns 8 in year 2003\n",
      "Duplicated ns-08-2003.csv to ns-09-2003.csv\n",
      "Duplicated ns-08-2003.csv to ns-10-2003.csv\n",
      "Using existing file ns-11-2003.csv for id_ns 11 in year 2003\n",
      "Duplicated ns-11-2003.csv to ns-12-2003.csv\n",
      "Duplicated ns-11-2003.csv to ns-13-2003.csv\n",
      "Duplicated ns-11-2003.csv to ns-14-2003.csv\n",
      "Using existing file ns-15-2003.csv for id_ns 15 in year 2003\n",
      "Duplicated ns-15-2003.csv to ns-16-2003.csv\n",
      "Duplicated ns-15-2003.csv to ns-17-2003.csv\n",
      "Duplicated ns-15-2003.csv to ns-18-2003.csv\n",
      "Using existing file ns-19-2003.csv for id_ns 19 in year 2003\n",
      "Duplicated ns-19-2003.csv to ns-20-2003.csv\n",
      "Duplicated ns-19-2003.csv to ns-21-2003.csv\n",
      "Duplicated ns-19-2003.csv to ns-22-2003.csv\n",
      "Using existing file ns-23-2003.csv for id_ns 23 in year 2003\n",
      "Using existing file ns-24-2003.csv for id_ns 24 in year 2003\n",
      "Duplicated ns-24-2003.csv to ns-25-2003.csv\n",
      "Duplicated ns-24-2003.csv to ns-26-2003.csv\n",
      "Using existing file ns-27-2003.csv for id_ns 27 in year 2003\n",
      "Duplicated ns-27-2003.csv to ns-28-2003.csv\n",
      "Duplicated ns-27-2003.csv to ns-29-2003.csv\n",
      "Duplicated ns-27-2003.csv to ns-30-2003.csv\n",
      "Using existing file ns-31-2003.csv for id_ns 31 in year 2003\n",
      "Duplicated ns-31-2003.csv to ns-32-2003.csv\n",
      "Duplicated ns-31-2003.csv to ns-33-2003.csv\n",
      "Duplicated ns-31-2003.csv to ns-34-2003.csv\n",
      "Using existing file ns-35-2003.csv for id_ns 35 in year 2003\n",
      "Duplicated ns-35-2003.csv to ns-36-2003.csv\n",
      "Duplicated ns-35-2003.csv to ns-37-2003.csv\n",
      "Duplicated ns-35-2003.csv to ns-38-2003.csv\n",
      "Using existing file ns-39-2003.csv for id_ns 39 in year 2003\n",
      "Duplicated ns-39-2003.csv to ns-40-2003.csv\n",
      "Duplicated ns-39-2003.csv to ns-41-2003.csv\n",
      "Duplicated ns-39-2003.csv to ns-42-2003.csv\n",
      "Duplicated ns-39-2003.csv to ns-43-2003.csv\n",
      "Using existing file ns-44-2003.csv for id_ns 44 in year 2003\n",
      "Duplicated ns-44-2003.csv to ns-45-2003.csv\n",
      "Duplicated ns-44-2003.csv to ns-46-2003.csv\n",
      "Duplicated ns-44-2003.csv to ns-47-2003.csv\n",
      "Using existing file ns-48-2003.csv for id_ns 48 in year 2003\n",
      "Duplicated ns-48-2003.csv to ns-49-2003.csv\n",
      "Existing files for year 2004: {3: 'ns-03-2004.csv', 7: 'ns-07-2004.csv', 11: 'ns-11-2004.csv', 15: 'ns-15-2004.csv', 19: 'ns-19-2004.csv', 23: 'ns-23-2004.csv', 28: 'ns-28-2004.csv', 31: 'ns-31-2004.csv', 36: 'ns-36-2004.csv', 40: 'ns-40-2004.csv', 44: 'ns-44-2004.csv', 49: 'ns-49-2004.csv'}\n",
      "Duplicated ns-49-2003.csv to ns-01-2004.csv\n",
      "Duplicated ns-49-2003.csv to ns-02-2004.csv\n",
      "Using existing file ns-03-2004.csv for id_ns 3 in year 2004\n",
      "Duplicated ns-03-2004.csv to ns-04-2004.csv\n",
      "Duplicated ns-03-2004.csv to ns-05-2004.csv\n",
      "Duplicated ns-03-2004.csv to ns-06-2004.csv\n",
      "Using existing file ns-07-2004.csv for id_ns 7 in year 2004\n",
      "Duplicated ns-07-2004.csv to ns-08-2004.csv\n",
      "Duplicated ns-07-2004.csv to ns-09-2004.csv\n",
      "Duplicated ns-07-2004.csv to ns-10-2004.csv\n",
      "Using existing file ns-11-2004.csv for id_ns 11 in year 2004\n",
      "Duplicated ns-11-2004.csv to ns-12-2004.csv\n",
      "Duplicated ns-11-2004.csv to ns-13-2004.csv\n",
      "Duplicated ns-11-2004.csv to ns-14-2004.csv\n",
      "Using existing file ns-15-2004.csv for id_ns 15 in year 2004\n",
      "Duplicated ns-15-2004.csv to ns-16-2004.csv\n",
      "Duplicated ns-15-2004.csv to ns-17-2004.csv\n",
      "Duplicated ns-15-2004.csv to ns-18-2004.csv\n",
      "Using existing file ns-19-2004.csv for id_ns 19 in year 2004\n",
      "Duplicated ns-19-2004.csv to ns-20-2004.csv\n",
      "Duplicated ns-19-2004.csv to ns-21-2004.csv\n",
      "Duplicated ns-19-2004.csv to ns-22-2004.csv\n",
      "Using existing file ns-23-2004.csv for id_ns 23 in year 2004\n",
      "Duplicated ns-23-2004.csv to ns-24-2004.csv\n",
      "Duplicated ns-23-2004.csv to ns-25-2004.csv\n",
      "Duplicated ns-23-2004.csv to ns-26-2004.csv\n",
      "Duplicated ns-23-2004.csv to ns-27-2004.csv\n",
      "Using existing file ns-28-2004.csv for id_ns 28 in year 2004\n",
      "Duplicated ns-28-2004.csv to ns-29-2004.csv\n",
      "Duplicated ns-28-2004.csv to ns-30-2004.csv\n",
      "Using existing file ns-31-2004.csv for id_ns 31 in year 2004\n",
      "Duplicated ns-31-2004.csv to ns-32-2004.csv\n",
      "Duplicated ns-31-2004.csv to ns-33-2004.csv\n",
      "Duplicated ns-31-2004.csv to ns-34-2004.csv\n",
      "Duplicated ns-31-2004.csv to ns-35-2004.csv\n",
      "Using existing file ns-36-2004.csv for id_ns 36 in year 2004\n",
      "Duplicated ns-36-2004.csv to ns-37-2004.csv\n",
      "Duplicated ns-36-2004.csv to ns-38-2004.csv\n",
      "Duplicated ns-36-2004.csv to ns-39-2004.csv\n",
      "Using existing file ns-40-2004.csv for id_ns 40 in year 2004\n",
      "Duplicated ns-40-2004.csv to ns-41-2004.csv\n",
      "Duplicated ns-40-2004.csv to ns-42-2004.csv\n",
      "Duplicated ns-40-2004.csv to ns-43-2004.csv\n",
      "Using existing file ns-44-2004.csv for id_ns 44 in year 2004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated ns-44-2004.csv to ns-45-2004.csv\n",
      "Duplicated ns-44-2004.csv to ns-46-2004.csv\n",
      "Duplicated ns-44-2004.csv to ns-47-2004.csv\n",
      "Duplicated ns-44-2004.csv to ns-48-2004.csv\n",
      "Using existing file ns-49-2004.csv for id_ns 49 in year 2004\n",
      "Existing files for year 2005: {3: 'ns-03-2005.csv', 7: 'ns-07-2005.csv', 11: 'ns-11-2005.csv', 15: 'ns-15-2005.csv', 19: 'ns-19-2005.csv', 23: 'ns-23-2005.csv', 26: 'ns-26-2005.csv', 28: 'ns-28-2005.csv', 31: 'ns-31-2005.csv', 36: 'ns-36-2005.csv', 40: 'ns-40-2005.csv', 44: 'ns-44-2005.csv', 49: 'ns-49-2005.csv'}\n",
      "Duplicated ns-49-2004.csv to ns-01-2005.csv\n",
      "Duplicated ns-49-2004.csv to ns-02-2005.csv\n",
      "Using existing file ns-03-2005.csv for id_ns 3 in year 2005\n",
      "Duplicated ns-03-2005.csv to ns-04-2005.csv\n",
      "Duplicated ns-03-2005.csv to ns-05-2005.csv\n",
      "Duplicated ns-03-2005.csv to ns-06-2005.csv\n",
      "Using existing file ns-07-2005.csv for id_ns 7 in year 2005\n",
      "Duplicated ns-07-2005.csv to ns-08-2005.csv\n",
      "Duplicated ns-07-2005.csv to ns-09-2005.csv\n",
      "Duplicated ns-07-2005.csv to ns-10-2005.csv\n",
      "Using existing file ns-11-2005.csv for id_ns 11 in year 2005\n",
      "Duplicated ns-11-2005.csv to ns-12-2005.csv\n",
      "Duplicated ns-11-2005.csv to ns-13-2005.csv\n",
      "Duplicated ns-11-2005.csv to ns-14-2005.csv\n",
      "Using existing file ns-15-2005.csv for id_ns 15 in year 2005\n",
      "Duplicated ns-15-2005.csv to ns-16-2005.csv\n",
      "Duplicated ns-15-2005.csv to ns-17-2005.csv\n",
      "Duplicated ns-15-2005.csv to ns-18-2005.csv\n",
      "Using existing file ns-19-2005.csv for id_ns 19 in year 2005\n",
      "Duplicated ns-19-2005.csv to ns-20-2005.csv\n",
      "Duplicated ns-19-2005.csv to ns-21-2005.csv\n",
      "Duplicated ns-19-2005.csv to ns-22-2005.csv\n",
      "Using existing file ns-23-2005.csv for id_ns 23 in year 2005\n",
      "Duplicated ns-23-2005.csv to ns-24-2005.csv\n",
      "Duplicated ns-23-2005.csv to ns-25-2005.csv\n",
      "Using existing file ns-26-2005.csv for id_ns 26 in year 2005\n",
      "Duplicated ns-26-2005.csv to ns-27-2005.csv\n",
      "Using existing file ns-28-2005.csv for id_ns 28 in year 2005\n",
      "Duplicated ns-28-2005.csv to ns-29-2005.csv\n",
      "Duplicated ns-28-2005.csv to ns-30-2005.csv\n",
      "Using existing file ns-31-2005.csv for id_ns 31 in year 2005\n",
      "Duplicated ns-31-2005.csv to ns-32-2005.csv\n",
      "Duplicated ns-31-2005.csv to ns-33-2005.csv\n",
      "Duplicated ns-31-2005.csv to ns-34-2005.csv\n",
      "Duplicated ns-31-2005.csv to ns-35-2005.csv\n",
      "Using existing file ns-36-2005.csv for id_ns 36 in year 2005\n",
      "Duplicated ns-36-2005.csv to ns-37-2005.csv\n",
      "Duplicated ns-36-2005.csv to ns-38-2005.csv\n",
      "Duplicated ns-36-2005.csv to ns-39-2005.csv\n",
      "Using existing file ns-40-2005.csv for id_ns 40 in year 2005\n",
      "Duplicated ns-40-2005.csv to ns-41-2005.csv\n",
      "Duplicated ns-40-2005.csv to ns-42-2005.csv\n",
      "Duplicated ns-40-2005.csv to ns-43-2005.csv\n",
      "Using existing file ns-44-2005.csv for id_ns 44 in year 2005\n",
      "Duplicated ns-44-2005.csv to ns-45-2005.csv\n",
      "Duplicated ns-44-2005.csv to ns-46-2005.csv\n",
      "Duplicated ns-44-2005.csv to ns-47-2005.csv\n",
      "Duplicated ns-44-2005.csv to ns-48-2005.csv\n",
      "Using existing file ns-49-2005.csv for id_ns 49 in year 2005\n",
      "Existing files for year 2006: {3: 'ns-03-2006.csv', 8: 'ns-08-2006.csv', 12: 'ns-12-2006.csv', 15: 'ns-15-2006.csv', 19: 'ns-19-2006.csv', 24: 'ns-24-2006.csv', 26: 'ns-26-2006.csv', 28: 'ns-28-2006.csv', 31: 'ns-31-2006.csv', 36: 'ns-36-2006.csv', 40: 'ns-40-2006.csv', 45: 'ns-45-2006.csv', 49: 'ns-49-2006.csv'}\n",
      "Duplicated ns-49-2005.csv to ns-01-2006.csv\n",
      "Duplicated ns-49-2005.csv to ns-02-2006.csv\n",
      "Using existing file ns-03-2006.csv for id_ns 3 in year 2006\n",
      "Duplicated ns-03-2006.csv to ns-04-2006.csv\n",
      "Duplicated ns-03-2006.csv to ns-05-2006.csv\n",
      "Duplicated ns-03-2006.csv to ns-06-2006.csv\n",
      "Duplicated ns-03-2006.csv to ns-07-2006.csv\n",
      "Using existing file ns-08-2006.csv for id_ns 8 in year 2006\n",
      "Duplicated ns-08-2006.csv to ns-09-2006.csv\n",
      "Duplicated ns-08-2006.csv to ns-10-2006.csv\n",
      "Duplicated ns-08-2006.csv to ns-11-2006.csv\n",
      "Using existing file ns-12-2006.csv for id_ns 12 in year 2006\n",
      "Duplicated ns-12-2006.csv to ns-13-2006.csv\n",
      "Duplicated ns-12-2006.csv to ns-14-2006.csv\n",
      "Using existing file ns-15-2006.csv for id_ns 15 in year 2006\n",
      "Duplicated ns-15-2006.csv to ns-16-2006.csv\n",
      "Duplicated ns-15-2006.csv to ns-17-2006.csv\n",
      "Duplicated ns-15-2006.csv to ns-18-2006.csv\n",
      "Using existing file ns-19-2006.csv for id_ns 19 in year 2006\n",
      "Duplicated ns-19-2006.csv to ns-20-2006.csv\n",
      "Duplicated ns-19-2006.csv to ns-21-2006.csv\n",
      "Duplicated ns-19-2006.csv to ns-22-2006.csv\n",
      "Duplicated ns-19-2006.csv to ns-23-2006.csv\n",
      "Using existing file ns-24-2006.csv for id_ns 24 in year 2006\n",
      "Duplicated ns-24-2006.csv to ns-25-2006.csv\n",
      "Using existing file ns-26-2006.csv for id_ns 26 in year 2006\n",
      "Duplicated ns-26-2006.csv to ns-27-2006.csv\n",
      "Using existing file ns-28-2006.csv for id_ns 28 in year 2006\n",
      "Duplicated ns-28-2006.csv to ns-29-2006.csv\n",
      "Duplicated ns-28-2006.csv to ns-30-2006.csv\n",
      "Using existing file ns-31-2006.csv for id_ns 31 in year 2006\n",
      "Duplicated ns-31-2006.csv to ns-32-2006.csv\n",
      "Duplicated ns-31-2006.csv to ns-33-2006.csv\n",
      "Duplicated ns-31-2006.csv to ns-34-2006.csv\n",
      "Duplicated ns-31-2006.csv to ns-35-2006.csv\n",
      "Using existing file ns-36-2006.csv for id_ns 36 in year 2006\n",
      "Duplicated ns-36-2006.csv to ns-37-2006.csv\n",
      "Duplicated ns-36-2006.csv to ns-38-2006.csv\n",
      "Duplicated ns-36-2006.csv to ns-39-2006.csv\n",
      "Using existing file ns-40-2006.csv for id_ns 40 in year 2006\n",
      "Duplicated ns-40-2006.csv to ns-41-2006.csv\n",
      "Duplicated ns-40-2006.csv to ns-42-2006.csv\n",
      "Duplicated ns-40-2006.csv to ns-43-2006.csv\n",
      "Duplicated ns-40-2006.csv to ns-44-2006.csv\n",
      "Using existing file ns-45-2006.csv for id_ns 45 in year 2006\n",
      "Duplicated ns-45-2006.csv to ns-46-2006.csv\n",
      "Duplicated ns-45-2006.csv to ns-47-2006.csv\n",
      "Duplicated ns-45-2006.csv to ns-48-2006.csv\n",
      "Using existing file ns-49-2006.csv for id_ns 49 in year 2006\n",
      "Existing files for year 2007: {3: 'ns-03-2007.csv', 8: 'ns-08-2007.csv', 12: 'ns-12-2007.csv', 15: 'ns-15-2007.csv', 19: 'ns-19-2007.csv', 23: 'ns-23-2007.csv', 24: 'ns-24-2007.csv', 28: 'ns-28-2007.csv', 32: 'ns-32-2007.csv', 36: 'ns-36-2007.csv', 40: 'ns-40-2007.csv', 45: 'ns-45-2007.csv', 49: 'ns-49-2007.csv'}\n",
      "Duplicated ns-49-2006.csv to ns-01-2007.csv\n",
      "Duplicated ns-49-2006.csv to ns-02-2007.csv\n",
      "Using existing file ns-03-2007.csv for id_ns 3 in year 2007\n",
      "Duplicated ns-03-2007.csv to ns-04-2007.csv\n",
      "Duplicated ns-03-2007.csv to ns-05-2007.csv\n",
      "Duplicated ns-03-2007.csv to ns-06-2007.csv\n",
      "Duplicated ns-03-2007.csv to ns-07-2007.csv\n",
      "Using existing file ns-08-2007.csv for id_ns 8 in year 2007\n",
      "Duplicated ns-08-2007.csv to ns-09-2007.csv\n",
      "Duplicated ns-08-2007.csv to ns-10-2007.csv\n",
      "Duplicated ns-08-2007.csv to ns-11-2007.csv\n",
      "Using existing file ns-12-2007.csv for id_ns 12 in year 2007\n",
      "Duplicated ns-12-2007.csv to ns-13-2007.csv\n",
      "Duplicated ns-12-2007.csv to ns-14-2007.csv\n",
      "Using existing file ns-15-2007.csv for id_ns 15 in year 2007\n",
      "Duplicated ns-15-2007.csv to ns-16-2007.csv\n",
      "Duplicated ns-15-2007.csv to ns-17-2007.csv\n",
      "Duplicated ns-15-2007.csv to ns-18-2007.csv\n",
      "Using existing file ns-19-2007.csv for id_ns 19 in year 2007\n",
      "Duplicated ns-19-2007.csv to ns-20-2007.csv\n",
      "Duplicated ns-19-2007.csv to ns-21-2007.csv\n",
      "Duplicated ns-19-2007.csv to ns-22-2007.csv\n",
      "Using existing file ns-23-2007.csv for id_ns 23 in year 2007\n",
      "Using existing file ns-24-2007.csv for id_ns 24 in year 2007\n",
      "Duplicated ns-24-2007.csv to ns-25-2007.csv\n",
      "Duplicated ns-24-2007.csv to ns-26-2007.csv\n",
      "Duplicated ns-24-2007.csv to ns-27-2007.csv\n",
      "Using existing file ns-28-2007.csv for id_ns 28 in year 2007\n",
      "Duplicated ns-28-2007.csv to ns-29-2007.csv\n",
      "Duplicated ns-28-2007.csv to ns-30-2007.csv\n",
      "Duplicated ns-28-2007.csv to ns-31-2007.csv\n",
      "Using existing file ns-32-2007.csv for id_ns 32 in year 2007\n",
      "Duplicated ns-32-2007.csv to ns-33-2007.csv\n",
      "Duplicated ns-32-2007.csv to ns-34-2007.csv\n",
      "Duplicated ns-32-2007.csv to ns-35-2007.csv\n",
      "Using existing file ns-36-2007.csv for id_ns 36 in year 2007\n",
      "Duplicated ns-36-2007.csv to ns-37-2007.csv\n",
      "Duplicated ns-36-2007.csv to ns-38-2007.csv\n",
      "Duplicated ns-36-2007.csv to ns-39-2007.csv\n",
      "Using existing file ns-40-2007.csv for id_ns 40 in year 2007\n",
      "Duplicated ns-40-2007.csv to ns-41-2007.csv\n",
      "Duplicated ns-40-2007.csv to ns-42-2007.csv\n",
      "Duplicated ns-40-2007.csv to ns-43-2007.csv\n",
      "Duplicated ns-40-2007.csv to ns-44-2007.csv\n",
      "Using existing file ns-45-2007.csv for id_ns 45 in year 2007\n",
      "Duplicated ns-45-2007.csv to ns-46-2007.csv\n",
      "Duplicated ns-45-2007.csv to ns-47-2007.csv\n",
      "Duplicated ns-45-2007.csv to ns-48-2007.csv\n",
      "Using existing file ns-49-2007.csv for id_ns 49 in year 2007\n",
      "Existing files for year 2008: {3: 'ns-03-2008.csv', 8: 'ns-08-2008.csv', 9: 'ns-09-2008.csv', 12: 'ns-12-2008.csv', 15: 'ns-15-2008.csv', 20: 'ns-20-2008.csv', 24: 'ns-24-2008.csv', 28: 'ns-28-2008.csv', 32: 'ns-32-2008.csv', 36: 'ns-36-2008.csv', 41: 'ns-41-2008.csv', 45: 'ns-45-2008.csv', 49: 'ns-49-2008.csv'}\n",
      "Duplicated ns-49-2007.csv to ns-01-2008.csv\n",
      "Duplicated ns-49-2007.csv to ns-02-2008.csv\n",
      "Using existing file ns-03-2008.csv for id_ns 3 in year 2008\n",
      "Duplicated ns-03-2008.csv to ns-04-2008.csv\n",
      "Duplicated ns-03-2008.csv to ns-05-2008.csv\n",
      "Duplicated ns-03-2008.csv to ns-06-2008.csv\n",
      "Duplicated ns-03-2008.csv to ns-07-2008.csv\n",
      "Using existing file ns-08-2008.csv for id_ns 8 in year 2008\n",
      "Using existing file ns-09-2008.csv for id_ns 9 in year 2008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated ns-09-2008.csv to ns-10-2008.csv\n",
      "Duplicated ns-09-2008.csv to ns-11-2008.csv\n",
      "Using existing file ns-12-2008.csv for id_ns 12 in year 2008\n",
      "Duplicated ns-12-2008.csv to ns-13-2008.csv\n",
      "Duplicated ns-12-2008.csv to ns-14-2008.csv\n",
      "Using existing file ns-15-2008.csv for id_ns 15 in year 2008\n",
      "Duplicated ns-15-2008.csv to ns-16-2008.csv\n",
      "Duplicated ns-15-2008.csv to ns-17-2008.csv\n",
      "Duplicated ns-15-2008.csv to ns-18-2008.csv\n",
      "Duplicated ns-15-2008.csv to ns-19-2008.csv\n",
      "Using existing file ns-20-2008.csv for id_ns 20 in year 2008\n",
      "Duplicated ns-20-2008.csv to ns-21-2008.csv\n",
      "Duplicated ns-20-2008.csv to ns-22-2008.csv\n",
      "Duplicated ns-20-2008.csv to ns-23-2008.csv\n",
      "Using existing file ns-24-2008.csv for id_ns 24 in year 2008\n",
      "Duplicated ns-24-2008.csv to ns-25-2008.csv\n",
      "Duplicated ns-24-2008.csv to ns-26-2008.csv\n",
      "Duplicated ns-24-2008.csv to ns-27-2008.csv\n",
      "Using existing file ns-28-2008.csv for id_ns 28 in year 2008\n",
      "Duplicated ns-28-2008.csv to ns-29-2008.csv\n",
      "Duplicated ns-28-2008.csv to ns-30-2008.csv\n",
      "Duplicated ns-28-2008.csv to ns-31-2008.csv\n",
      "Using existing file ns-32-2008.csv for id_ns 32 in year 2008\n",
      "Duplicated ns-32-2008.csv to ns-33-2008.csv\n",
      "Duplicated ns-32-2008.csv to ns-34-2008.csv\n",
      "Duplicated ns-32-2008.csv to ns-35-2008.csv\n",
      "Using existing file ns-36-2008.csv for id_ns 36 in year 2008\n",
      "Duplicated ns-36-2008.csv to ns-37-2008.csv\n",
      "Duplicated ns-36-2008.csv to ns-38-2008.csv\n",
      "Duplicated ns-36-2008.csv to ns-39-2008.csv\n",
      "Duplicated ns-36-2008.csv to ns-40-2008.csv\n",
      "Using existing file ns-41-2008.csv for id_ns 41 in year 2008\n",
      "Duplicated ns-41-2008.csv to ns-42-2008.csv\n",
      "Duplicated ns-41-2008.csv to ns-43-2008.csv\n",
      "Duplicated ns-41-2008.csv to ns-44-2008.csv\n",
      "Using existing file ns-45-2008.csv for id_ns 45 in year 2008\n",
      "Duplicated ns-45-2008.csv to ns-46-2008.csv\n",
      "Duplicated ns-45-2008.csv to ns-47-2008.csv\n",
      "Duplicated ns-45-2008.csv to ns-48-2008.csv\n",
      "Using existing file ns-49-2008.csv for id_ns 49 in year 2008\n",
      "Duplicated ns-49-2008.csv to ns-50-2008.csv\n",
      "Existing files for year 2009: {3: 'ns-03-2009.csv', 7: 'ns-07-2009.csv', 11: 'ns-11-2009.csv', 15: 'ns-15-2009.csv', 19: 'ns-19-2009.csv', 20: 'ns-20-2009.csv', 23: 'ns-23-2009.csv', 28: 'ns-28-2009.csv', 31: 'ns-31-2009.csv', 35: 'ns-35-2009.csv', 40: 'ns-40-2009.csv', 44: 'ns-44-2009.csv', 48: 'ns-48-2009.csv'}\n",
      "Duplicated ns-50-2008.csv to ns-01-2009.csv\n",
      "Duplicated ns-50-2008.csv to ns-02-2009.csv\n",
      "Using existing file ns-03-2009.csv for id_ns 3 in year 2009\n",
      "Duplicated ns-03-2009.csv to ns-04-2009.csv\n",
      "Duplicated ns-03-2009.csv to ns-05-2009.csv\n",
      "Duplicated ns-03-2009.csv to ns-06-2009.csv\n",
      "Using existing file ns-07-2009.csv for id_ns 7 in year 2009\n",
      "Duplicated ns-07-2009.csv to ns-08-2009.csv\n",
      "Duplicated ns-07-2009.csv to ns-09-2009.csv\n",
      "Duplicated ns-07-2009.csv to ns-10-2009.csv\n",
      "Using existing file ns-11-2009.csv for id_ns 11 in year 2009\n",
      "Duplicated ns-11-2009.csv to ns-12-2009.csv\n",
      "Duplicated ns-11-2009.csv to ns-13-2009.csv\n",
      "Duplicated ns-11-2009.csv to ns-14-2009.csv\n",
      "Using existing file ns-15-2009.csv for id_ns 15 in year 2009\n",
      "Duplicated ns-15-2009.csv to ns-16-2009.csv\n",
      "Duplicated ns-15-2009.csv to ns-17-2009.csv\n",
      "Duplicated ns-15-2009.csv to ns-18-2009.csv\n",
      "Using existing file ns-19-2009.csv for id_ns 19 in year 2009\n",
      "Using existing file ns-20-2009.csv for id_ns 20 in year 2009\n",
      "Duplicated ns-20-2009.csv to ns-21-2009.csv\n",
      "Duplicated ns-20-2009.csv to ns-22-2009.csv\n",
      "Using existing file ns-23-2009.csv for id_ns 23 in year 2009\n",
      "Duplicated ns-23-2009.csv to ns-24-2009.csv\n",
      "Duplicated ns-23-2009.csv to ns-25-2009.csv\n",
      "Duplicated ns-23-2009.csv to ns-26-2009.csv\n",
      "Duplicated ns-23-2009.csv to ns-27-2009.csv\n",
      "Using existing file ns-28-2009.csv for id_ns 28 in year 2009\n",
      "Duplicated ns-28-2009.csv to ns-29-2009.csv\n",
      "Duplicated ns-28-2009.csv to ns-30-2009.csv\n",
      "Using existing file ns-31-2009.csv for id_ns 31 in year 2009\n",
      "Duplicated ns-31-2009.csv to ns-32-2009.csv\n",
      "Duplicated ns-31-2009.csv to ns-33-2009.csv\n",
      "Duplicated ns-31-2009.csv to ns-34-2009.csv\n",
      "Using existing file ns-35-2009.csv for id_ns 35 in year 2009\n",
      "Duplicated ns-35-2009.csv to ns-36-2009.csv\n",
      "Duplicated ns-35-2009.csv to ns-37-2009.csv\n",
      "Duplicated ns-35-2009.csv to ns-38-2009.csv\n",
      "Duplicated ns-35-2009.csv to ns-39-2009.csv\n",
      "Using existing file ns-40-2009.csv for id_ns 40 in year 2009\n",
      "Duplicated ns-40-2009.csv to ns-41-2009.csv\n",
      "Duplicated ns-40-2009.csv to ns-42-2009.csv\n",
      "Duplicated ns-40-2009.csv to ns-43-2009.csv\n",
      "Using existing file ns-44-2009.csv for id_ns 44 in year 2009\n",
      "Duplicated ns-44-2009.csv to ns-45-2009.csv\n",
      "Duplicated ns-44-2009.csv to ns-46-2009.csv\n",
      "Duplicated ns-44-2009.csv to ns-47-2009.csv\n",
      "Using existing file ns-48-2009.csv for id_ns 48 in year 2009\n",
      "Duplicated ns-48-2009.csv to ns-49-2009.csv\n",
      "Existing files for year 2010: {3: 'ns-03-2010.csv', 4: 'ns-04-2010.csv', 7: 'ns-07-2010.csv', 8: 'ns-08-2010.csv', 11: 'ns-11-2010.csv', 15: 'ns-15-2010.csv', 19: 'ns-19-2010.csv', 23: 'ns-23-2010.csv', 28: 'ns-28-2010.csv', 31: 'ns-31-2010.csv', 36: 'ns-36-2010.csv', 40: 'ns-40-2010.csv', 44: 'ns-44-2010.csv', 48: 'ns-48-2010.csv'}\n",
      "Duplicated ns-49-2009.csv to ns-01-2010.csv\n",
      "Duplicated ns-49-2009.csv to ns-02-2010.csv\n",
      "Using existing file ns-03-2010.csv for id_ns 3 in year 2010\n",
      "Using existing file ns-04-2010.csv for id_ns 4 in year 2010\n",
      "Duplicated ns-04-2010.csv to ns-05-2010.csv\n",
      "Duplicated ns-04-2010.csv to ns-06-2010.csv\n",
      "Using existing file ns-07-2010.csv for id_ns 7 in year 2010\n",
      "Using existing file ns-08-2010.csv for id_ns 8 in year 2010\n",
      "Duplicated ns-08-2010.csv to ns-09-2010.csv\n",
      "Duplicated ns-08-2010.csv to ns-10-2010.csv\n",
      "Using existing file ns-11-2010.csv for id_ns 11 in year 2010\n",
      "Duplicated ns-11-2010.csv to ns-12-2010.csv\n",
      "Duplicated ns-11-2010.csv to ns-13-2010.csv\n",
      "Duplicated ns-11-2010.csv to ns-14-2010.csv\n",
      "Using existing file ns-15-2010.csv for id_ns 15 in year 2010\n",
      "Duplicated ns-15-2010.csv to ns-16-2010.csv\n",
      "Duplicated ns-15-2010.csv to ns-17-2010.csv\n",
      "Duplicated ns-15-2010.csv to ns-18-2010.csv\n",
      "Using existing file ns-19-2010.csv for id_ns 19 in year 2010\n",
      "Duplicated ns-19-2010.csv to ns-20-2010.csv\n",
      "Duplicated ns-19-2010.csv to ns-21-2010.csv\n",
      "Duplicated ns-19-2010.csv to ns-22-2010.csv\n",
      "Using existing file ns-23-2010.csv for id_ns 23 in year 2010\n",
      "Duplicated ns-23-2010.csv to ns-24-2010.csv\n",
      "Duplicated ns-23-2010.csv to ns-25-2010.csv\n",
      "Duplicated ns-23-2010.csv to ns-26-2010.csv\n",
      "Duplicated ns-23-2010.csv to ns-27-2010.csv\n",
      "Using existing file ns-28-2010.csv for id_ns 28 in year 2010\n",
      "Duplicated ns-28-2010.csv to ns-29-2010.csv\n",
      "Duplicated ns-28-2010.csv to ns-30-2010.csv\n",
      "Using existing file ns-31-2010.csv for id_ns 31 in year 2010\n",
      "Duplicated ns-31-2010.csv to ns-32-2010.csv\n",
      "Duplicated ns-31-2010.csv to ns-33-2010.csv\n",
      "Duplicated ns-31-2010.csv to ns-34-2010.csv\n",
      "Duplicated ns-31-2010.csv to ns-35-2010.csv\n",
      "Using existing file ns-36-2010.csv for id_ns 36 in year 2010\n",
      "Duplicated ns-36-2010.csv to ns-37-2010.csv\n",
      "Duplicated ns-36-2010.csv to ns-38-2010.csv\n",
      "Duplicated ns-36-2010.csv to ns-39-2010.csv\n",
      "Using existing file ns-40-2010.csv for id_ns 40 in year 2010\n",
      "Duplicated ns-40-2010.csv to ns-41-2010.csv\n",
      "Duplicated ns-40-2010.csv to ns-42-2010.csv\n",
      "Duplicated ns-40-2010.csv to ns-43-2010.csv\n",
      "Using existing file ns-44-2010.csv for id_ns 44 in year 2010\n",
      "Duplicated ns-44-2010.csv to ns-45-2010.csv\n",
      "Duplicated ns-44-2010.csv to ns-46-2010.csv\n",
      "Duplicated ns-44-2010.csv to ns-47-2010.csv\n",
      "Using existing file ns-48-2010.csv for id_ns 48 in year 2010\n",
      "Duplicated ns-48-2010.csv to ns-49-2010.csv\n",
      "Existing files for year 2011: {3: 'ns-03-2011.csv', 7: 'ns-07-2011.csv', 8: 'ns-08-2011.csv', 11: 'ns-11-2011.csv', 16: 'ns-16-2011.csv', 19: 'ns-19-2011.csv', 23: 'ns-23-2011.csv', 24: 'ns-24-2011.csv', 28: 'ns-28-2011.csv', 31: 'ns-31-2011.csv', 36: 'ns-36-2011.csv', 40: 'ns-40-2011.csv', 44: 'ns-44-2011.csv', 49: 'ns-49-2011.csv'}\n",
      "Duplicated ns-49-2010.csv to ns-01-2011.csv\n",
      "Duplicated ns-49-2010.csv to ns-02-2011.csv\n",
      "Using existing file ns-03-2011.csv for id_ns 3 in year 2011\n",
      "Duplicated ns-03-2011.csv to ns-04-2011.csv\n",
      "Duplicated ns-03-2011.csv to ns-05-2011.csv\n",
      "Duplicated ns-03-2011.csv to ns-06-2011.csv\n",
      "Using existing file ns-07-2011.csv for id_ns 7 in year 2011\n",
      "Using existing file ns-08-2011.csv for id_ns 8 in year 2011\n",
      "Duplicated ns-08-2011.csv to ns-09-2011.csv\n",
      "Duplicated ns-08-2011.csv to ns-10-2011.csv\n",
      "Using existing file ns-11-2011.csv for id_ns 11 in year 2011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated ns-11-2011.csv to ns-12-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-13-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-14-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-15-2011.csv\n",
      "Using existing file ns-16-2011.csv for id_ns 16 in year 2011\n",
      "Duplicated ns-16-2011.csv to ns-17-2011.csv\n",
      "Duplicated ns-16-2011.csv to ns-18-2011.csv\n",
      "Using existing file ns-19-2011.csv for id_ns 19 in year 2011\n",
      "Duplicated ns-19-2011.csv to ns-20-2011.csv\n",
      "Duplicated ns-19-2011.csv to ns-21-2011.csv\n",
      "Duplicated ns-19-2011.csv to ns-22-2011.csv\n",
      "Using existing file ns-23-2011.csv for id_ns 23 in year 2011\n",
      "Using existing file ns-24-2011.csv for id_ns 24 in year 2011\n",
      "Duplicated ns-24-2011.csv to ns-25-2011.csv\n",
      "Duplicated ns-24-2011.csv to ns-26-2011.csv\n",
      "Duplicated ns-24-2011.csv to ns-27-2011.csv\n",
      "Using existing file ns-28-2011.csv for id_ns 28 in year 2011\n",
      "Duplicated ns-28-2011.csv to ns-29-2011.csv\n",
      "Duplicated ns-28-2011.csv to ns-30-2011.csv\n",
      "Using existing file ns-31-2011.csv for id_ns 31 in year 2011\n",
      "Duplicated ns-31-2011.csv to ns-32-2011.csv\n",
      "Duplicated ns-31-2011.csv to ns-33-2011.csv\n",
      "Duplicated ns-31-2011.csv to ns-34-2011.csv\n",
      "Duplicated ns-31-2011.csv to ns-35-2011.csv\n",
      "Using existing file ns-36-2011.csv for id_ns 36 in year 2011\n",
      "Duplicated ns-36-2011.csv to ns-37-2011.csv\n",
      "Duplicated ns-36-2011.csv to ns-38-2011.csv\n",
      "Duplicated ns-36-2011.csv to ns-39-2011.csv\n",
      "Using existing file ns-40-2011.csv for id_ns 40 in year 2011\n",
      "Duplicated ns-40-2011.csv to ns-41-2011.csv\n",
      "Duplicated ns-40-2011.csv to ns-42-2011.csv\n",
      "Duplicated ns-40-2011.csv to ns-43-2011.csv\n",
      "Using existing file ns-44-2011.csv for id_ns 44 in year 2011\n",
      "Duplicated ns-44-2011.csv to ns-45-2011.csv\n",
      "Duplicated ns-44-2011.csv to ns-46-2011.csv\n",
      "Duplicated ns-44-2011.csv to ns-47-2011.csv\n",
      "Duplicated ns-44-2011.csv to ns-48-2011.csv\n",
      "Using existing file ns-49-2011.csv for id_ns 49 in year 2011\n",
      "Existing files for year 2012: {3: 'ns-03-2012.csv', 8: 'ns-08-2012.csv', 12: 'ns-12-2012.csv', 15: 'ns-15-2012.csv', 19: 'ns-19-2012.csv', 24: 'ns-24-2012.csv', 25: 'ns-25-2012.csv', 28: 'ns-28-2012.csv', 31: 'ns-31-2012.csv', 36: 'ns-36-2012.csv', 40: 'ns-40-2012.csv', 45: 'ns-45-2012.csv', 49: 'ns-49-2012.csv'}\n",
      "Duplicated ns-49-2011.csv to ns-01-2012.csv\n",
      "Duplicated ns-49-2011.csv to ns-02-2012.csv\n",
      "Using existing file ns-03-2012.csv for id_ns 3 in year 2012\n",
      "Duplicated ns-03-2012.csv to ns-04-2012.csv\n",
      "Duplicated ns-03-2012.csv to ns-05-2012.csv\n",
      "Duplicated ns-03-2012.csv to ns-06-2012.csv\n",
      "Duplicated ns-03-2012.csv to ns-07-2012.csv\n",
      "Using existing file ns-08-2012.csv for id_ns 8 in year 2012\n",
      "Duplicated ns-08-2012.csv to ns-09-2012.csv\n",
      "Duplicated ns-08-2012.csv to ns-10-2012.csv\n",
      "Duplicated ns-08-2012.csv to ns-11-2012.csv\n",
      "Using existing file ns-12-2012.csv for id_ns 12 in year 2012\n",
      "Duplicated ns-12-2012.csv to ns-13-2012.csv\n",
      "Duplicated ns-12-2012.csv to ns-14-2012.csv\n",
      "Using existing file ns-15-2012.csv for id_ns 15 in year 2012\n",
      "Duplicated ns-15-2012.csv to ns-16-2012.csv\n",
      "Duplicated ns-15-2012.csv to ns-17-2012.csv\n",
      "Duplicated ns-15-2012.csv to ns-18-2012.csv\n",
      "Using existing file ns-19-2012.csv for id_ns 19 in year 2012\n",
      "Duplicated ns-19-2012.csv to ns-20-2012.csv\n",
      "Duplicated ns-19-2012.csv to ns-21-2012.csv\n",
      "Duplicated ns-19-2012.csv to ns-22-2012.csv\n",
      "Duplicated ns-19-2012.csv to ns-23-2012.csv\n",
      "Using existing file ns-24-2012.csv for id_ns 24 in year 2012\n",
      "Using existing file ns-25-2012.csv for id_ns 25 in year 2012\n",
      "Duplicated ns-25-2012.csv to ns-26-2012.csv\n",
      "Duplicated ns-25-2012.csv to ns-27-2012.csv\n",
      "Using existing file ns-28-2012.csv for id_ns 28 in year 2012\n",
      "Duplicated ns-28-2012.csv to ns-29-2012.csv\n",
      "Duplicated ns-28-2012.csv to ns-30-2012.csv\n",
      "Using existing file ns-31-2012.csv for id_ns 31 in year 2012\n",
      "Duplicated ns-31-2012.csv to ns-32-2012.csv\n",
      "Duplicated ns-31-2012.csv to ns-33-2012.csv\n",
      "Duplicated ns-31-2012.csv to ns-34-2012.csv\n",
      "Duplicated ns-31-2012.csv to ns-35-2012.csv\n",
      "Using existing file ns-36-2012.csv for id_ns 36 in year 2012\n",
      "Duplicated ns-36-2012.csv to ns-37-2012.csv\n",
      "Duplicated ns-36-2012.csv to ns-38-2012.csv\n",
      "Duplicated ns-36-2012.csv to ns-39-2012.csv\n",
      "Using existing file ns-40-2012.csv for id_ns 40 in year 2012\n",
      "Duplicated ns-40-2012.csv to ns-41-2012.csv\n",
      "Duplicated ns-40-2012.csv to ns-42-2012.csv\n",
      "Duplicated ns-40-2012.csv to ns-43-2012.csv\n",
      "Duplicated ns-40-2012.csv to ns-44-2012.csv\n",
      "Using existing file ns-45-2012.csv for id_ns 45 in year 2012\n",
      "Duplicated ns-45-2012.csv to ns-46-2012.csv\n",
      "Duplicated ns-45-2012.csv to ns-47-2012.csv\n",
      "Duplicated ns-45-2012.csv to ns-48-2012.csv\n",
      "Using existing file ns-49-2012.csv for id_ns 49 in year 2012\n"
     ]
    }
   ],
   "source": [
    "# Process each year\n",
    "for year in range(1994, 2013): # Please change your preferred year range (the last year + 1)\n",
    "    df_year = df[df['year'] == year]\n",
    "    duplicate_files_table_1(year, df_year, table_1_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bcdef",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a9694",
   "metadata": {},
   "source": [
    "<div id=\"1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff12be5",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">1.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Table 2\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550cd6d0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please change your preferred year range\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e87957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Process each year\n",
    "for year in range(2011, 2012): # Please change your preferred year range\n",
    "    df_year = df[df['year'] == year]\n",
    "    duplicate_files_table_2(year, df_year, table_2_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710b388",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baf20e",
   "metadata": {},
   "source": [
    "<div id=\"2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86728175",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;; color: dark;\">2.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Data cleaning</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56e8cc",
   "metadata": {},
   "source": [
    "<div id=\"2-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9f258",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Extracting tables and data cleanup\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84b6a7",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "PENDING\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbde93",
   "metadata": {},
   "source": [
    "<div id=\"2-1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c9908",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 1.</span> Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245d93f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <b>\"ns_dates\"</b> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8ffb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Dictionary to store generated DataFrames\n",
    "old_dataframes_dict_1 = {}\n",
    "\n",
    "# Path for the processed folders log file\n",
    "record_path = 'dataframes_record/old_processed_folders_1.txt'\n",
    "\n",
    "# Function to correct month names\n",
    "def correct_month_name(month):\n",
    "    months_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Add more mappings as needed for other month names\n",
    "    }\n",
    "    return months_mapping.get(month, month)\n",
    "\n",
    "# Function to register processed folder\n",
    "def register_processed_folder(folder, num_processed_files):\n",
    "    with open(record_path, 'a') as file:\n",
    "        file.write(f\"{folder}:{num_processed_files}\\n\")\n",
    "\n",
    "# Function to check if folder has been processed\n",
    "def folder_processed(folder):\n",
    "    if not os.path.exists(record_path):\n",
    "        return False\n",
    "    with open(record_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(folder):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to fetch date from database\n",
    "def get_date(df, engine):\n",
    "    id_ns = df['id_ns'].iloc[0]\n",
    "    year = df['year'].iloc[0]\n",
    "    query = f\"SELECT date FROM dates_growth_rates WHERE id_ns = '{id_ns}' AND year = '{year}';\"\n",
    "    date_result = pd.read_sql(query, engine)\n",
    "    return date_result.iloc[0, 0] if not date_result.empty else None\n",
    "\n",
    "def process_csv(csv_path, engine):\n",
    "    old_tables_dict_1 = {}  # Local dictionary for each CSV\n",
    "    table_counter = 1\n",
    "\n",
    "    filename = os.path.basename(csv_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None # Return None for tables_dict_1 as well\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(csv_path))[0].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(csv_path, delimiter=';')\n",
    "    \n",
    "    dataframe_name = f\"{new_filename}_{table_counter}\"\n",
    "    old_tables_dict_1[dataframe_name] = df.copy()\n",
    "\n",
    "    # Apply cleanup functions to a copy of the DataFrame\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Conditional cleaning based on the first column\n",
    "    if df_clean.columns[1] == 'economic_sectors':\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_services(df_clean)\n",
    "        df_clean = replace_mineria(df_clean)\n",
    "        df_clean = replace_mining(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "    else:\n",
    "        # Cleaning functions (set as required)\n",
    "        df_clean = clean_column_names(df_clean)\n",
    "        df_clean = adjust_column_names(df_clean)\n",
    "        df_clean = drop_rare_caracter_row(df_clean)\n",
    "        df_clean = drop_nan_rows(df_clean)\n",
    "        df_clean = drop_nan_columns(df_clean)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = remove_digit_slash(df_clean)\n",
    "        df_clean = replace_var_perc_first_column(df_clean)\n",
    "        df_clean = replace_var_perc_last_columns(df_clean)\n",
    "        df_clean = replace_number_moving_average(df_clean)\n",
    "        df_clean = relocate_last_column(df_clean)\n",
    "        df_clean = clean_first_row(df_clean)\n",
    "        df_clean = find_year_column(df_clean)\n",
    "        year_columns = extract_years(df_clean)\n",
    "        df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "        df_clean = first_row_columns(df_clean)\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_services(df_clean)\n",
    "        df_clean = replace_mineria(df_clean)\n",
    "        df_clean = replace_mining(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "    # Add the column 'year' to the clean DataFrame\n",
    "    df_clean.insert(0, 'year', year)\n",
    "    \n",
    "    # Add the column 'id_ns' to the clean DataFrame\n",
    "    df_clean.insert(1, 'id_ns', id_ns)\n",
    "    \n",
    "    # Get corresponding date from database\n",
    "    date = get_date(df_clean, engine)\n",
    "    if date:\n",
    "        # Add 'date' column to cleaned DataFrame\n",
    "        df_clean.insert(2, 'date', date)\n",
    "    else:\n",
    "        print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "    # Store cleaned DataFrame in old_dataframes_dict_1\n",
    "    old_dataframes_dict_1[dataframe_name] = df_clean\n",
    "\n",
    "    return id_ns, year, old_tables_dict_1\n",
    "\n",
    "# Function to process folder\n",
    "def process_folder(folder, engine):\n",
    "    print(f\"Processing folder {os.path.basename(folder)}\")\n",
    "    csv_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\n",
    "    num_csv_processed = 0\n",
    "    num_dataframes_generated = 0\n",
    "\n",
    "    table_counter = 1  # Initialize table counter here\n",
    "    old_tables_dict_1 = {}  # Declare old_tables_dict_1 outside main loop\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        id_ns, year, tables_dict_temp = process_csv(csv_file, engine)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for dataframe_name, df in tables_dict_temp.items():\n",
    "                file_name = os.path.splitext(os.path.basename(csv_file))[0].replace('-', '_')\n",
    "                dataframe_name = f\"{file_name}_{table_counter}\"\n",
    "                \n",
    "                # Store raw DataFrame in old_tables_dict_1\n",
    "                old_tables_dict_1[dataframe_name] = df.copy()\n",
    "                \n",
    "                # Apply cleanup functions to a copy of the DataFrame\n",
    "                df_clean = df.copy()\n",
    "\n",
    "                # Conditional cleaning based on the first column\n",
    "                if df_clean.columns[1] == 'economic_sectors':\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                else:\n",
    "                    # Cleaning functions (set as required)\n",
    "                    df_clean = clean_column_names(df_clean)\n",
    "                    df_clean = adjust_column_names(df_clean)\n",
    "                    df_clean = drop_rare_caracter_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = remove_digit_slash(df_clean)\n",
    "                    df_clean = replace_var_perc_first_column(df_clean)\n",
    "                    df_clean = replace_var_perc_last_columns(df_clean)\n",
    "                    df_clean = replace_number_moving_average(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = find_year_column(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "                # Add the column 'year' to the clean DataFrame\n",
    "                df_clean.insert(0, 'year', year)\n",
    "\n",
    "                # Add the column 'id_ns' to the clean DataFrame\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "\n",
    "                # Get corresponding date from database\n",
    "                date = get_date(df_clean, engine)\n",
    "                if date:\n",
    "                    # Add 'date' column to cleaned DataFrame\n",
    "                    df_clean.insert(2, 'date', date)\n",
    "                else:\n",
    "                    print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "                # Store cleaned DataFrame in old_dataframes_dict_1\n",
    "                old_dataframes_dict_1[dataframe_name] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. The dataframe generated for the {csv_file} file is: {dataframe_name}')\n",
    "                num_dataframes_generated += 1\n",
    "                table_counter = 1  # Increment table counter here\n",
    "        \n",
    "        num_csv_processed += 1  # Increment number of processed CSV for each CSV in folder\n",
    "\n",
    "    return num_csv_processed, num_dataframes_generated, old_tables_dict_1\n",
    "\n",
    "def process_folders():\n",
    "    csv_folder = table_1_folder\n",
    "    folders = [os.path.join(csv_folder, d) for d in os.listdir(csv_folder) if os.path.isdir(os.path.join(csv_folder, d)) and re.match(r'\\d{4}', d)]\n",
    "    \n",
    "    old_tables_dict_1 = {}  # Initialize old_tables_dict_1 here\n",
    "    \n",
    "    for folder in folders:\n",
    "        if folder_processed(folder):\n",
    "            print(f\"Folder {folder} has already been processed.\")\n",
    "            continue\n",
    "        \n",
    "        num_csv_processed, num_dataframes_generated, tables_dict_temp = process_folder(folder, engine)\n",
    "        \n",
    "        # Update old_tables_dict_1 with values returned from process_folder()\n",
    "        old_tables_dict_1.update(tables_dict_temp)\n",
    "        \n",
    "        register_processed_folder(folder, num_csv_processed)\n",
    "\n",
    "        # Ask user if they want to continue with next folder\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Ensure the messagebox is in front\n",
    "        message = f\"Process {folder} complete. Processed {num_csv_processed} CSV(s) and generated {num_dataframes_generated} DataFrame(s). Continue with next folder?\"\n",
    "        if not messagebox.askyesno(\"Continue?\", message):\n",
    "            break\n",
    "            \n",
    "    print(\"Processing completed for all folders.\")  # Add a message to indicate completion\n",
    "    \n",
    "    return old_tables_dict_1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    engine = create_sqlalchemy_engine()\n",
    "    old_tables_dict_1 = process_folders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda07520",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tables_dict_1['ns_03_1994_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3294767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataframes_dict_1['ns_03_1994_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c511633",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb917b",
   "metadata": {},
   "source": [
    "<div id=\"2-1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d489b",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 2.</span> Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21687b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <b>\"ns_dates\"</b> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab041892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Dictionary to store generated DataFrames\n",
    "old_dataframes_dict_2 = {}\n",
    "\n",
    "# Path for the processed folders log file\n",
    "record_path = 'dataframes_record/old_processed_folders_2.txt'\n",
    "\n",
    "# Function to correct month names\n",
    "def correct_month_name(month):\n",
    "    months_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Add more mappings as needed for other month names\n",
    "    }\n",
    "    return months_mapping.get(month, month)\n",
    "\n",
    "# Function to register processed folder\n",
    "def register_processed_folder(folder, num_processed_files):\n",
    "    with open(record_path, 'a') as file:\n",
    "        file.write(f\"{folder}:{num_processed_files}\\n\")\n",
    "\n",
    "# Function to check if folder has been processed\n",
    "def folder_processed(folder):\n",
    "    if not os.path.exists(record_path):\n",
    "        return False\n",
    "    with open(record_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(folder):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to fetch date from database\n",
    "def get_date(df, engine):\n",
    "    id_ns = df['id_ns'].iloc[0]\n",
    "    year = df['year'].iloc[0]\n",
    "    query = f\"SELECT date FROM dates_growth_rates WHERE id_ns = '{id_ns}' AND year = '{year}';\"\n",
    "    date_result = pd.read_sql(query, engine)\n",
    "    return date_result.iloc[0, 0] if not date_result.empty else None\n",
    "\n",
    "def process_csv(csv_path, engine):\n",
    "    old_tables_dict_2 = {}  # Local dictionary for each CSV\n",
    "    table_counter = 2\n",
    "\n",
    "    filename = os.path.basename(csv_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None # Return None for tables_dict_1 as well\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(csv_path))[0].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(csv_path, delimiter=';')\n",
    "    \n",
    "    dataframe_name = f\"{new_filename}_{table_counter}\"\n",
    "    old_tables_dict_2[dataframe_name] = df.copy()\n",
    "\n",
    "    # Apply cleanup functions to a copy of the DataFrame\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Conditional cleaning based on the first column\n",
    "    if df_clean.columns[1] == 'economic_sectors':\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_services(df_clean)\n",
    "        df_clean = replace_mineria(df_clean)\n",
    "        df_clean = replace_mining(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "    else:\n",
    "        # Cleaning functions (set as required)\n",
    "        df_clean = replace_total_with_year(df_clean)\n",
    "        df_clean = drop_nan_rows(df_clean)\n",
    "        year_columns = extract_years(df_clean)\n",
    "        df_clean = roman_arabic(df_clean)\n",
    "        df_clean = fix_duplicates(df_clean)\n",
    "        df_clean = relocate_last_column(df_clean)\n",
    "        df_clean = replace_first_row_nan(df_clean)\n",
    "        df_clean = clean_first_row(df_clean)\n",
    "        df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = first_row_columns(df_clean)\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_services(df_clean)\n",
    "        df_clean = replace_mineria(df_clean)\n",
    "        df_clean = replace_mining(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "    # Add the column 'year' to the clean DataFrame\n",
    "    df_clean.insert(0, 'year', year)\n",
    "    \n",
    "    # Add the column 'id_ns' to the clean DataFrame\n",
    "    df_clean.insert(1, 'id_ns', id_ns)\n",
    "    \n",
    "    # Get corresponding date from database\n",
    "    date = get_date(df_clean, engine)\n",
    "    if date:\n",
    "        # Add 'date' column to cleaned DataFrame\n",
    "        df_clean.insert(2, 'date', date)\n",
    "    else:\n",
    "        print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "    # Store cleaned DataFrame in old_dataframes_dict_2\n",
    "    old_dataframes_dict_2[dataframe_name] = df_clean\n",
    "\n",
    "    return id_ns, year, old_tables_dict_2\n",
    "\n",
    "# Function to process folder\n",
    "def process_folder(folder, engine):\n",
    "    print(f\"Processing folder {os.path.basename(folder)}\")\n",
    "    csv_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\n",
    "    num_csv_processed = 0\n",
    "    num_dataframes_generated = 0\n",
    "\n",
    "    table_counter = 2  # Initialize table counter here\n",
    "    old_tables_dict_2 = {}  # Declare old_tables_dict_1 outside main loop\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        id_ns, year, tables_dict_temp = process_csv(csv_file, engine)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for dataframe_name, df in tables_dict_temp.items():\n",
    "                file_name = os.path.splitext(os.path.basename(csv_file))[0].replace('-', '_')\n",
    "                dataframe_name = f\"{file_name}_{table_counter}\"\n",
    "                \n",
    "                # Store raw DataFrame in old_tables_dict_2\n",
    "                old_tables_dict_2[dataframe_name] = df.copy()\n",
    "                \n",
    "                # Procesar y limpiar el DataFrame\n",
    "                df_clean = df.copy()\n",
    "                \n",
    "                # Conditional cleaning based on the first column\n",
    "                if df_clean.columns[1] == 'economic_sectors':\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                else:\n",
    "                    # Cleaning functions (set as required)\n",
    "                    df_clean = replace_total_with_year(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = replace_first_row_nan(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = replace_mineria(df_clean)\n",
    "                    df_clean = replace_mining(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                \n",
    "                # Add the column 'year' to the clean DataFrame\n",
    "                df_clean.insert(0, 'year', year)\n",
    "\n",
    "                # Add the column 'id_ns' to the clean DataFrame\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "\n",
    "                # Get corresponding date from database\n",
    "                date = get_date(df_clean, engine)\n",
    "                if date:\n",
    "                    # Add 'date' column to cleaned DataFrame\n",
    "                    df_clean.insert(2, 'date', date)\n",
    "                else:\n",
    "                    print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "                # Store cleaned DataFrame in old_dataframes_dict_2\n",
    "                old_dataframes_dict_2[dataframe_name] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. The dataframe generated for the {csv_file} file is: {dataframe_name}')\n",
    "                num_dataframes_generated += 1\n",
    "                table_counter = 2  # Increment table counter here\n",
    "        \n",
    "        num_csv_processed += 1  # Increment number of processed CSV for each CSV in folder\n",
    "\n",
    "    return num_csv_processed, num_dataframes_generated, old_tables_dict_2\n",
    "\n",
    "def process_folders():\n",
    "    csv_folder = table_2_folder\n",
    "    folders = [os.path.join(csv_folder, d) for d in os.listdir(csv_folder) if os.path.isdir(os.path.join(csv_folder, d)) and re.match(r'\\d{4}', d)]\n",
    "    \n",
    "    old_tables_dict_2 = {}  # Initialize old_tables_dict_1 here\n",
    "    \n",
    "    for folder in folders:\n",
    "        if folder_processed(folder):\n",
    "            print(f\"Folder {folder} has already been processed.\")\n",
    "            continue\n",
    "        \n",
    "        num_csv_processed, num_dataframes_generated, tables_dict_temp = process_folder(folder, engine)\n",
    "        \n",
    "        # Update old_tables_dict_2 with values returned from process_folder()\n",
    "        old_tables_dict_2.update(tables_dict_temp)\n",
    "        \n",
    "        register_processed_folder(folder, num_csv_processed)\n",
    "\n",
    "        # Ask user if they want to continue with next folder\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Ensure the messagebox is in front\n",
    "        message = f\"Process {folder} complete. Processed {num_csv_processed} CSV(s) and generated {num_dataframes_generated} DataFrame(s). Continue with next folder?\"\n",
    "        if not messagebox.askyesno(\"Continue?\", message):\n",
    "            break\n",
    "\n",
    "    print(\"Processing completed for all folders.\")  # Add a message to indicate completion\n",
    "\n",
    "    return old_tables_dict_2\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    engine = create_sqlalchemy_engine()\n",
    "    old_tables_dict_2 = process_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tables_dict_2['ns_02_1997_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b05cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataframes_dict_2['ns_02_1997_2']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6942ad4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ec8677",
   "metadata": {},
   "source": [
    "<div id=\"3\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7663f10",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Real-time data of Peru's GDP growth rates</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d320f965",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "This section creates the GDP growth rate vintages for Peru using <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a> and <a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a>, which were extracted and cleaned in the previous section. Each table from each WR (CSV <span style=\"font-size: 24px;\">&#128452;</span>) was extracted and cleaned individually in the previous section. Here, we will concatenate all the tables for a specific economic sector, thus creating a vintage dataset of (real) GDP growth by economic sector from <b>1994</b> to <b>2012</b> (<a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 1</a>) and <b>1997</b> to <b>2012</b> (<a href=\"#3-2-1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Table 2</a>).\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc80591",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Select <code>sector_economico</code> and <code>economic_sector</code></span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9eaa05b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "When executing the following code, a window will be displayed with options in <b>Spanish</b> and <b>English</b> to select <b>economic sectors</b>. Choose them to concatenate Peru GDP growth rates (annual, quarterly or monthly) by sector.\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7156504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function with the Spanish options list to display the window\n",
    "selected_spanish, selected_english = select_economic_sector(spanish_options, english_options)\n",
    "\n",
    "# Display the values selected by the user\n",
    "print(f\"You have selected sector_economico = {selected_spanish} and economic_sector = {selected_english}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e90ece",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #00414C; color: white; padding: 10px;\">\n",
    "<h1><span style = \"color: #15F5BA; font-family: 'PT Serif Pro Book'; color: dark;\">$\\bullet$</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Select the dataset name prefix</span></h1>\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ca98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to show the popup window\n",
    "sector = show_option_window()\n",
    "print(\"Selected economic sector:\", sector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9197ccc0",
   "metadata": {},
   "source": [
    "<div id=\"3-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3d2a3e",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Annual vintages concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ba8475",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"old_{sector}_annual_growth_rates\"] = concatenate_annual_df(old_dataframes_dict_2, selected_spanish, selected_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcf79a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "globals()[f\"old_{sector}_annual_growth_rates\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861ebeef",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f1fb4",
   "metadata": {},
   "source": [
    "<div id=\"3-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a50fc9",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Quarterly vintages concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4ec16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"old_{sector}_quarterly_growth_rates\"] = concatenate_quarterly_df(old_dataframes_dict_2, selected_spanish, selected_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3361b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "globals()[f\"old_{sector}_quarterly_growth_rates\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967209e3",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349841ab",
   "metadata": {},
   "source": [
    "<div id=\"3-3\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f557eb",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">3.3.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Monthly vintages concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10732c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"old_{sector}_monthly_growth_rates\"] = concatenate_monthly_df(old_dataframes_dict_1, selected_spanish, selected_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dec3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "globals()[f\"old_{sector}_monthly_growth_rates\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e0c329",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548303d",
   "metadata": {},
   "source": [
    "<div id=\"4\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae6b362",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">GDP final revision dataset</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4a21da",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "This section creates the final revisions dataset of Peru's GDP growth.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de96850",
   "metadata": {},
   "source": [
    "<div id=\"4-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7470c38b",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Annual revisions\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c53e29",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "We calculate the <b>final revision</b> as the <b>difference</b> between the <b>last annual release</b> and the <b>first annual release</b> of the GDP growth rate.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b11bffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between the last and the first non-NaN value for each column, except 'year', 'ns_id' and 'date'.\n",
    "revision = globals()[f\"old_{sector}_annual_growth_rates\"].drop(columns=['year', 'id_ns', 'date']).apply(lambda x: x.loc[x.last_valid_index()] - x.loc[x.first_valid_index()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a58ba0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Annual revisions as dataframe\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d63a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the columns name\n",
    "globals()[f\"old_{sector}_annual_revisions\"] = pd.DataFrame({'revision_date': revision.index, f'{sector}_revision': revision.values})\n",
    "globals()[f\"old_{sector}_annual_revisions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b653b0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Clean-up the revision_date column\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d32c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the year from the string and convert it to an integer type\n",
    "globals()[f\"old_{sector}_annual_revisions\"]['year'] = globals()[f\"old_{sector}_annual_revisions\"]['revision_date'].str.extract(r'(\\d+)')\n",
    "\n",
    "# Create an auxiliary column to generate the values extracted from the year\n",
    "globals()[f\"old_{sector}_annual_revisions\"]['year'] = globals()[f\"old_{sector}_annual_revisions\"]['year'].astype(int)\n",
    "\n",
    "# Convert revision_date column values as dates\n",
    "globals()[f\"old_{sector}_annual_revisions\"]['revision_date'] = pd.to_datetime(globals()[f\"old_{sector}_annual_revisions\"]['year'], format='%Y')\n",
    "\n",
    "# Delete the auxiliary column 'year'\n",
    "globals()[f\"old_{sector}_annual_revisions\"].drop(columns=['year'], inplace=True)\n",
    "\n",
    "# Display the result\n",
    "globals()[f\"old_{sector}_annual_revisions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7defe41",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4235a6cd",
   "metadata": {},
   "source": [
    "<div id=\"4-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0d9c84",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Quarterly revisions\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a19bdb2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "We calculate the <b>final revision</b> as the <b>difference</b> between the <b>last quarterly release</b> and the <b>first quarterly release</b> of the GDP growth rate.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b1dba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between the last and the first non-NaN value for each column, except 'year', 'ns_id' and 'date'.\n",
    "revision = globals()[f\"old_{sector}_quarterly_growth_rates\"].drop(columns=['year', 'id_ns', 'date']).apply(lambda x: x.loc[x.last_valid_index()] - x.loc[x.first_valid_index()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36dbe70d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Quarterly revisions as dataframe\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac58e859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the columns name\n",
    "globals()[f\"old_{sector}_quarterly_revisions\"] = pd.DataFrame({'revision_date': revision.index, f'{sector}_revision': revision.values})\n",
    "globals()[f\"old_{sector}_quarterly_revisions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c4d23",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Clean-up the revision_date column\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754ade4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column 'revision_date' to date data type\n",
    "globals()[f\"old_{sector}_quarterly_revisions\"]['revision_date'] = pd.to_datetime(globals()[f\"old_{sector}_quarterly_revisions\"]['revision_date'], format='%Y_%m')\n",
    "\n",
    "# Display the result\n",
    "globals()[f\"old_{sector}_quarterly_revisions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02459636",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecd79dc",
   "metadata": {},
   "source": [
    "<div id=\"4-3\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0d1f4c",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">4.3.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Monthly revisions\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf026af",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "We calculate the <b>final revision</b> as the <b>difference</b> between the <b>last monthly release</b> and the <b>first monthly release</b> of the GDP growth rate.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070e5f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between the last and the first non-NaN value for each column, except 'year', 'ns_id' and 'date'.\n",
    "revision = globals()[f\"old_{sector}_monthly_growth_rates\"].drop(columns=['year', 'id_ns', 'date']).apply(lambda x: x.loc[x.last_valid_index()] - x.loc[x.first_valid_index()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001e7874",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Monthly revisions as dataframe\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the columns name\n",
    "globals()[f\"old_{sector}_monthly_revisions\"] = pd.DataFrame({'revision_date': revision.index, f'{sector}_revision': revision.values})\n",
    "globals()[f\"old_{sector}_monthly_revisions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770700a2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Clean-up dataframe\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a673fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the month and year from the column 'revision_date'\n",
    "globals()[f\"old_{sector}_monthly_revisions\"]['month'] = globals()[f\"old_{sector}_monthly_revisions\"]['revision_date'].str.split('_').str[0]\n",
    "globals()[f\"old_{sector}_monthly_revisions\"]['year'] = globals()[f\"old_{sector}_monthly_revisions\"]['revision_date'].str.split('_').str[1]\n",
    "\n",
    "# Match the names of the months to their respective numbers\n",
    "month_mapping = {\n",
    "    'ene': '01', 'feb': '02', 'mar': '03', 'abr': '04',\n",
    "    'may': '05', 'jun': '06', 'jul': '07', 'ago': '08',\n",
    "    'sep': '09', 'oct': '10', 'nov': '11', 'dic': '12'\n",
    "}\n",
    "\n",
    "globals()[f\"old_{sector}_monthly_revisions\"]['month'] = globals()[f\"old_{sector}_monthly_revisions\"]['month'].map(month_mapping)\n",
    "\n",
    "# Create a new column with the date in YYYYY-MM-DD format\n",
    "globals()[f\"old_{sector}_monthly_revisions\"]['revision_date'] = globals()[f\"old_{sector}_monthly_revisions\"]['year'] + '-' + globals()[f\"old_{sector}_monthly_revisions\"]['month']\n",
    "\n",
    "# Convert column 'revision_date' to date data type\n",
    "globals()[f\"old_{sector}_monthly_revisions\"]['revision_date'] = pd.to_datetime(globals()[f\"old_{sector}_monthly_revisions\"]['revision_date'], format='%Y-%m')\n",
    "\n",
    "# Remove temporary columns 'month' and 'year'\n",
    "globals()[f\"old_{sector}_monthly_revisions\"].drop(['month', 'year'], axis=1, inplace=True)\n",
    "\n",
    "# Display the result\n",
    "globals()[f\"old_{sector}_monthly_revisions\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fad9f47",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a946f9c9",
   "metadata": {},
   "source": [
    "<div id=\"5\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfed7094",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">5.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Uploading data to SQL</span></h1> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c749c49",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "Finally, we upload all the datasets generated in this jupyter notebook to the <code>'gdp_revisions_datasets'</code> database of <code>PostgresSQL</code>.\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8ed15",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_sqlalchemy_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b43d9d",
   "metadata": {},
   "source": [
    "<div id=\"5-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1af27c",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">5.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Vintages\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6c8ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#globals()[f\"old_{sector}_annual_growth_rates\"].to_sql(f'old_{sector}_annual_growth_rates', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc5d3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#globals()[f\"old_{sector}_quarterly_growth_rates\"].to_sql(f'old_{sector}_quarterly_growth_rates', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1de733",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"old_{sector}_monthly_growth_rates\"].to_sql(f'old_{sector}_monthly_growth_rates', engine, index=False, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d29ba9c",
   "metadata": {},
   "source": [
    "<div id=\"5-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c190a",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">5.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Revisions\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#globals()[f\"old_{sector}_annual_revisions\"].to_sql(f'old_{sector}_annual_revisions', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfee60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#globals()[f\"old_{sector}_quarterly_revisions\"].to_sql(f'old_{sector}_quarterly_revisions', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f506c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals()[f\"old_{sector}_monthly_revisions\"].to_sql(f'old_{sector}_monthly_revisions', engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93e09cf",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 20px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#select\" style=\"color: rgb(255, 32, 78); text-decoration: none;\"></a>\n",
    "    </span> \n",
    "    <a href=\"#select\" style=\"color: rgb(255, 32, 78); text-decoration: none;\">Back to economic sectors.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d2a2e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f4ef74",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13fcf35e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
