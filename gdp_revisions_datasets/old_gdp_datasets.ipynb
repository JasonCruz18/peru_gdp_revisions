{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0ee00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0953333",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter bt pro roman'; color: rgb(0, 65, 75);\">\n",
    "<h1>\n",
    "Old GDP Revisions Datasets\n",
    "</h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c323e5f0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter bt pro roman'; color: rgb(0, 65, 75);\">\n",
    "<h3>\n",
    "Documentation\n",
    "<br>\n",
    "____________________\n",
    "<br>\n",
    "</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc075bd7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'PT Serif Pro Book'; color: rgb(0, 65, 75); font-size: 16px;\">\n",
    "    Jason Cruz\n",
    "    <br>\n",
    "    <a href=\"mailto:jj.cruza@up.edu.pe\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">\n",
    "        jj.cruza@up.edu.pe\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b0f23d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "This <span style=\"color: rgb(0, 65, 75);\">jupyter notebook</span> documents step-by-step the <b>construction of old datasets</b> for the project <b>'Revisions and Biases in Preliminary GDP Estimates in Peru'</b>.\n",
    "\n",
    "This jupyter notebook goes from the cleaning of the tables (Weekly Reports, WR) provided confidentially by the Central Bank to the construction of the <b>vintages</b> and <b>revisions</b> datasets from 1994-2024.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addcdf2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;line-height: 1.5;\">\n",
    "<span style=\"font-size: 24px;\">&#128196;</span> The Weekly Report/<i>Nota Semanal</i> (WR/<i>NS</i>) of the Central Bank.\n",
    "    <br>\n",
    "    <span style=\"font-size: 24px;\">&#8987;</span> Available since <b>1994-2012</b> (Table 1) and since <b>1997-2012</b> (Table 2). \n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516ae6c",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Amaya; text-align: left; color: rgb(0, 65, 75); font-size:16px\">The following <b>outline is functional</b>. By utilising the provided buttons, users are able to enhance their experience by browsing this script.<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d69587",
   "metadata": {},
   "source": [
    "<div id=\"outilne\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15589700",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #292929; padding: 10px; line-height: 1.5; font-family: 'PT Serif Pro Book';\">\n",
    "    <h2 style=\"text-align: left; color: #E0E0E0;\">\n",
    "        Outline\n",
    "    </h2>\n",
    "    <br>\n",
    "    <a href=\"#libraries\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        Libraries</a>\n",
    "    <br>\n",
    "    <a href=\"#setup\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        Initial set-up</a>\n",
    "    <br>\n",
    "    <a href=\"#1\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        1. Duplicate tables for all other NS ids</a>\n",
    "    <br>\n",
    "    <a href=\"#1-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        1.1. Table 1.</a>\n",
    "    <br>\n",
    "    <a href=\"#1-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        1.2. Table 2.</a>\n",
    "    <br>\n",
    "    <a href=\"#2\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">\n",
    "        2. Data cleaning</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        2.1. Extracting tables and data cleanup.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1-1\" style=\"color: #94FFD8; font-size: 14px; margin-left: 40px;\">\n",
    "        2.1.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1-2\" style=\"color: #94FFD8; font-size: 14px; margin-left: 40px;\">\n",
    "        2.1.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.</a>\n",
    "    <br>\n",
    "    <a href=\"#3\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">3. Real-time data of Peru's GDP growth rates</a>\n",
    "    <br>\n",
    "    <a href=\"#3-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.1. Annual vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.2. Quarterly vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-3\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.3. Monthly vintages concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-4\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        3.4. Loading SQL.</a>\n",
    "    <br>\n",
    "    <a href=\"#4\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">4. GDP final revision dataset</a>\n",
    "    <br>\n",
    "    <a href=\"#4-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.1. Annual revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#4-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.2. Quarterly revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#4-3\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        4.3. Monthly revisions.</a>\n",
    "    <br>\n",
    "    <a href=\"#5\" style=\"color: #E0E0E0; font-size: 18px; margin-left: 0px;\">5. Uploading data to SQL</a>\n",
    "    <br>\n",
    "    <a href=\"#5-1\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        5.1. Vintages.</a>\n",
    "    <br>\n",
    "    <a href=\"#5-2\" style=\"color: #94FFD8; font-size: 16px; margin-left: 20px;\">\n",
    "        5.2. Revisions.</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a7c4d6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    Any questions or issues regarding the coding, please email Jason Cruz <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123); text-decoration: none;\"><span style=\"font-size: 24px;\">&#x2709;</span>\n",
    "    </a>.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ff8772",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "    If you don't have the libraries below, please use the following code (as example) to install the required libraries.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f517f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21974a",
   "metadata": {},
   "source": [
    "<div id=\"libraries\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a752d8fe",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    <h2>\n",
    "    Libraries\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00415459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Duplicate tables for all other NS ids\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "# 1.1. Table 1\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# 2. Data cleaning\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# 2.2. Extracting tables and data cleanup\n",
    "\n",
    "import pandas as pd  # For data manipulation and analysis\n",
    "import unicodedata  # For manipulating Unicode data\n",
    "import re  # For regular expressions operations\n",
    "from datetime import datetime  # For working with dates and times\n",
    "import locale  # For locale-specific formatting of numbers, dates, and currencies\n",
    "import numpy as np\n",
    "import unidecode\n",
    "\n",
    "# 2.2.1. Table 1. Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "\n",
    "import tabula  # Used to extract tables from PDF files into pandas DataFrames\n",
    "from tkinter import Tk, messagebox, TOP, YES, NO  # Used for creating graphical user interfaces\n",
    "from sqlalchemy import create_engine  # Used for connecting to and interacting with SQL databases\n",
    "\n",
    "# 2.2.2. Table 2. Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "\n",
    "import roman\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# 3. Real-time data of Peru's GDP growth rates\n",
    "#-------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "import psycopg2  # For interacting with PostgreSQL databases\n",
    "from sqlalchemy import create_engine, text  # For creating and executing SQL queries using SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e8167e",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d73758",
   "metadata": {},
   "source": [
    "<div id=\"setup\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4fbf38",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark;\">\n",
    "    <h2>\n",
    "    Initial set-up\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d8675b",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> Setting the base path. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f382fef7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter your base path to set your main working directory, then press enter: \n",
      "C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\Research Assistant\\CIUP\\GDP Revisions\\gdp_revisions\\old_database\n",
      "Correctly defined base path.\n"
     ]
    }
   ],
   "source": [
    "# Ask the user for the base path\n",
    "base_path = input(\"Please enter your base path to set your main working directory, then press enter: \\n\")\n",
    "\n",
    "# Check if the path is valid\n",
    "if os.path.isdir(base_path):\n",
    "    print(f\"Correctly defined base path.\")\n",
    "    os.chdir(base_path)\n",
    "else:\n",
    "    print(\"The entered path is not valid. Please try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16931de9",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    Download the <code>.zip</code> files of <code>table_1</code> and <code>table_2</code> and paste them into <code>raw_data</code> and <code>input_data</code> paths set below. \n",
    "    <p>\n",
    "     Note that the missing data will be filled in <code>input_data</code> in <a href=\"#1\" style=\"color: rgb(0, 153, 123); font-size: 16px;\">Section 1</a>. Then the changes will actually occur in the <code>input_data</code> folder. However, we created <code>raw_data</code> to map the tables as they were delivered by the Central Bank, i.e. the raw data delivered (without any transformation).\n",
    "       </p>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8651a1eb",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3ac6a98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank \n",
    "raw_data = 'raw_data' # to save raw data (.csv).\n",
    "if not os.path.exists(raw_data):\n",
    "    os.mkdir(raw_data) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9b71270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank as inputs (duplicated for all NS id) \n",
    "input_data = 'input_data' # to save input data (.csv).\n",
    "if not os.path.exists(input_data):\n",
    "    os.mkdir(input_data) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8d7bc1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank (Table 1)\n",
    "table_1_folder = os.path.join(input_data, 'table_1') # to save raw data (.csv).\n",
    "if not os.path.exists(table_1_folder):\n",
    "    os.mkdir(table_1_folder) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cbf5877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save csv files delivered by Central Bank (Table 2)\n",
    "table_2_folder = os.path.join(input_data, 'table_2') # to save raw data (.csv).\n",
    "if not os.path.exists(table_2_folder):\n",
    "    os.mkdir(table_2_folder) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "feed966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save dataframes generated record by year\n",
    "\n",
    "dataframes_record = 'dataframes_record'\n",
    "if not os.path.exists(dataframes_record):\n",
    "    os.makedirs(dataframes_record) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bb31bc",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae41a493",
   "metadata": {},
   "source": [
    "<p style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> The following function will establish a connection to the <code>gdp_revisions_datasets</code> database in <code>PostgreSQL</code>. The <b>input data</b> used in this jupyter notebook will be loaded from this <code>PostgreSQL</code> database, and similarly, all <b>output data</b> generated by this jupyter notebook will be stored in that database. Ensure that you set the necessary parameters to access the server once you have obtained the required permissions.<p/>\n",
    "    \n",
    "<p style=\"text-align: left; font-family: 'PT Serif Pro Book'; color: dark; font-size:16px\">\n",
    "To request permissions, please email Jason Cruz <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123); text-decoration: none;\"> <span style=\"font-size: 24px;\">&#x2709;</span>\n",
    "    </a>.\n",
    "<p/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c4457bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sqlalchemy_engine():\n",
    "    \"\"\"\n",
    "    Function to create an SQLAlchemy engine using environment variables.\n",
    "    \n",
    "    Returns:\n",
    "        engine: SQLAlchemy engine object.\n",
    "    \"\"\"\n",
    "    # Get environment variables\n",
    "    user = os.environ.get('CIUP_SQL_USER')  # Get the SQL user from environment variables\n",
    "    password = os.environ.get('CIUP_SQL_PASS')  # Get the SQL password from environment variables\n",
    "    host = os.environ.get('CIUP_SQL_HOST')  # Get the SQL host from environment variables\n",
    "    port = 5432  # Set the SQL port to 5432\n",
    "    database = 'gdp_revisions_datasets'  # Set the database name 'gdp_revisions_datasets' from SQL\n",
    "\n",
    "    # Check if all environment variables are defined\n",
    "    if not all([host, user, password]):\n",
    "        raise ValueError(\"Some environment variables are missing (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "    # Create connection string\n",
    "    connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    return engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8fa3d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Import all other functions required by this jupyter notebook.\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003ecd38",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\"> Please, check the script <code>gdp_revisions_datasets_functions.py</code> which contains all the functions required by this jupyter notebook. The functions there are ordered according to the <a href=\"#outilne\" style=\"color: #3d30a2;\">sections</a> of this jupyter notebok.<div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3cda8404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.12.1)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from old_gdp_revisions_datasets_functions import *\n",
    "from gdp_revisions_datasets_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e10d5d",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465bedbd",
   "metadata": {},
   "source": [
    "<div id=\"1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba54b25f",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;; color: dark;\">1.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Duplicate tables for all other NS ids</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fd1034",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "    <p>The Central Bank has provided us with confidential data for Table 1 (1994-2012) and Table 2 (1997-2012). However, in each year we have been provided from the tables where the revisions occurred or, more generally, where the Central Bank has received from INEI the updated information of all NS tables.</p>\n",
    "    \n",
    "   <p>So, we will duplicate these tables to complete the total NS per year (50 approximately due to the number of weeks per year).</p>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9443ed",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "The following code imports the data containing the dummies of the tables that were delivered by the Central Bank (1 if the table was delivered and 0 if it was not) from SQL \n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb719841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to PostgresSQL\n",
    "engine = create_sqlalchemy_engine()\n",
    "\n",
    "# Define SQL query to import data\n",
    "query = f\"SELECT * FROM old_raw_data_delivered\"\n",
    "\n",
    "# Importing data into a pandas DataFrame\n",
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5d5875",
   "metadata": {},
   "source": [
    "<div id=\"1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf5b4f6",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">1.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Table 1\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1686bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No existing file to duplicate for ns-01-2010.csv\n",
      "No existing file to duplicate for ns-02-2010.csv\n",
      "Duplicated ns-04-2010.csv to ns-05-2010.csv\n",
      "Duplicated ns-04-2010.csv to ns-06-2010.csv\n",
      "Duplicated ns-08-2010.csv to ns-09-2010.csv\n",
      "Duplicated ns-08-2010.csv to ns-10-2010.csv\n",
      "Duplicated ns-11-2010.csv to ns-12-2010.csv\n",
      "Duplicated ns-11-2010.csv to ns-13-2010.csv\n",
      "Duplicated ns-11-2010.csv to ns-14-2010.csv\n",
      "Duplicated ns-15-2010.csv to ns-16-2010.csv\n",
      "Duplicated ns-15-2010.csv to ns-17-2010.csv\n",
      "Duplicated ns-15-2010.csv to ns-18-2010.csv\n",
      "Duplicated ns-19-2010.csv to ns-20-2010.csv\n",
      "Duplicated ns-19-2010.csv to ns-21-2010.csv\n",
      "Duplicated ns-19-2010.csv to ns-22-2010.csv\n",
      "Duplicated ns-23-2010.csv to ns-24-2010.csv\n",
      "Duplicated ns-23-2010.csv to ns-25-2010.csv\n",
      "Duplicated ns-23-2010.csv to ns-26-2010.csv\n",
      "Duplicated ns-23-2010.csv to ns-27-2010.csv\n",
      "Duplicated ns-28-2010.csv to ns-29-2010.csv\n",
      "Duplicated ns-28-2010.csv to ns-30-2010.csv\n",
      "Duplicated ns-31-2010.csv to ns-32-2010.csv\n",
      "Duplicated ns-31-2010.csv to ns-33-2010.csv\n",
      "Duplicated ns-31-2010.csv to ns-34-2010.csv\n",
      "Duplicated ns-31-2010.csv to ns-35-2010.csv\n",
      "Duplicated ns-36-2010.csv to ns-37-2010.csv\n",
      "Duplicated ns-36-2010.csv to ns-38-2010.csv\n",
      "Duplicated ns-36-2010.csv to ns-39-2010.csv\n",
      "Duplicated ns-40-2010.csv to ns-41-2010.csv\n",
      "Duplicated ns-40-2010.csv to ns-42-2010.csv\n",
      "Duplicated ns-40-2010.csv to ns-43-2010.csv\n",
      "Duplicated ns-44-2010.csv to ns-45-2010.csv\n",
      "Duplicated ns-44-2010.csv to ns-46-2010.csv\n",
      "Duplicated ns-44-2010.csv to ns-47-2010.csv\n",
      "Duplicated ns-48-2010.csv to ns-49-2010.csv\n",
      "Duplicated ns-49-2010.csv to ns-01-2011.csv\n",
      "Duplicated ns-49-2010.csv to ns-02-2011.csv\n",
      "Duplicated ns-03-2011.csv to ns-04-2011.csv\n",
      "Duplicated ns-03-2011.csv to ns-05-2011.csv\n",
      "Duplicated ns-03-2011.csv to ns-06-2011.csv\n",
      "Duplicated ns-08-2011.csv to ns-09-2011.csv\n",
      "Duplicated ns-08-2011.csv to ns-10-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-12-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-13-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-14-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-15-2011.csv\n",
      "Duplicated ns-16-2011.csv to ns-17-2011.csv\n",
      "Duplicated ns-16-2011.csv to ns-18-2011.csv\n",
      "Duplicated ns-19-2011.csv to ns-20-2011.csv\n",
      "Duplicated ns-19-2011.csv to ns-21-2011.csv\n",
      "Duplicated ns-19-2011.csv to ns-22-2011.csv\n",
      "Duplicated ns-24-2011.csv to ns-25-2011.csv\n",
      "Duplicated ns-24-2011.csv to ns-26-2011.csv\n",
      "Duplicated ns-24-2011.csv to ns-27-2011.csv\n",
      "Duplicated ns-28-2011.csv to ns-29-2011.csv\n",
      "Duplicated ns-28-2011.csv to ns-30-2011.csv\n",
      "Duplicated ns-31-2011.csv to ns-32-2011.csv\n",
      "Duplicated ns-31-2011.csv to ns-33-2011.csv\n",
      "Duplicated ns-31-2011.csv to ns-34-2011.csv\n",
      "Duplicated ns-31-2011.csv to ns-35-2011.csv\n",
      "Duplicated ns-36-2011.csv to ns-37-2011.csv\n",
      "Duplicated ns-36-2011.csv to ns-38-2011.csv\n",
      "Duplicated ns-36-2011.csv to ns-39-2011.csv\n",
      "Duplicated ns-40-2011.csv to ns-41-2011.csv\n",
      "Duplicated ns-40-2011.csv to ns-42-2011.csv\n",
      "Duplicated ns-40-2011.csv to ns-43-2011.csv\n",
      "Duplicated ns-44-2011.csv to ns-45-2011.csv\n",
      "Duplicated ns-44-2011.csv to ns-46-2011.csv\n",
      "Duplicated ns-44-2011.csv to ns-47-2011.csv\n",
      "Duplicated ns-44-2011.csv to ns-48-2011.csv\n",
      "Duplicated ns-49-2011.csv to ns-01-2012.csv\n",
      "Duplicated ns-49-2011.csv to ns-02-2012.csv\n",
      "Duplicated ns-03-2012.csv to ns-04-2012.csv\n",
      "Duplicated ns-03-2012.csv to ns-05-2012.csv\n",
      "Duplicated ns-03-2012.csv to ns-06-2012.csv\n",
      "Duplicated ns-03-2012.csv to ns-07-2012.csv\n",
      "Duplicated ns-08-2012.csv to ns-09-2012.csv\n",
      "Duplicated ns-08-2012.csv to ns-10-2012.csv\n",
      "Duplicated ns-08-2012.csv to ns-11-2012.csv\n",
      "Duplicated ns-12-2012.csv to ns-13-2012.csv\n",
      "Duplicated ns-12-2012.csv to ns-14-2012.csv\n",
      "Duplicated ns-15-2012.csv to ns-16-2012.csv\n",
      "Duplicated ns-15-2012.csv to ns-17-2012.csv\n",
      "Duplicated ns-15-2012.csv to ns-18-2012.csv\n",
      "Duplicated ns-19-2012.csv to ns-20-2012.csv\n",
      "Duplicated ns-19-2012.csv to ns-21-2012.csv\n",
      "Duplicated ns-19-2012.csv to ns-22-2012.csv\n",
      "Duplicated ns-19-2012.csv to ns-23-2012.csv\n",
      "Duplicated ns-25-2012.csv to ns-26-2012.csv\n",
      "Duplicated ns-25-2012.csv to ns-27-2012.csv\n",
      "Duplicated ns-28-2012.csv to ns-29-2012.csv\n",
      "Duplicated ns-28-2012.csv to ns-30-2012.csv\n",
      "Duplicated ns-31-2012.csv to ns-32-2012.csv\n",
      "Duplicated ns-31-2012.csv to ns-33-2012.csv\n",
      "Duplicated ns-31-2012.csv to ns-34-2012.csv\n",
      "Duplicated ns-31-2012.csv to ns-35-2012.csv\n",
      "Duplicated ns-36-2012.csv to ns-37-2012.csv\n",
      "Duplicated ns-36-2012.csv to ns-38-2012.csv\n",
      "Duplicated ns-36-2012.csv to ns-39-2012.csv\n",
      "Duplicated ns-40-2012.csv to ns-41-2012.csv\n",
      "Duplicated ns-40-2012.csv to ns-42-2012.csv\n",
      "Duplicated ns-40-2012.csv to ns-43-2012.csv\n",
      "Duplicated ns-40-2012.csv to ns-44-2012.csv\n",
      "Duplicated ns-45-2012.csv to ns-46-2012.csv\n",
      "Duplicated ns-45-2012.csv to ns-47-2012.csv\n",
      "Duplicated ns-45-2012.csv to ns-48-2012.csv\n"
     ]
    }
   ],
   "source": [
    "# Process each year\n",
    "for year in range(2010, 2013): # Please change your preferred year range\n",
    "    df_year = df[df['year'] == year]\n",
    "    duplicate_files_table_1(year, df_year, table_1_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16bcdef",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866a9694",
   "metadata": {},
   "source": [
    "<div id=\"1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff12be5",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">1.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Table 2\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95e87957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated ns-45-2010.csv to ns-01-2011.csv\n",
      "Duplicated ns-45-2010.csv to ns-02-2011.csv\n",
      "Duplicated ns-45-2010.csv to ns-03-2011.csv\n",
      "Duplicated ns-45-2010.csv to ns-04-2011.csv\n",
      "Duplicated ns-45-2010.csv to ns-05-2011.csv\n",
      "Duplicated ns-45-2010.csv to ns-06-2011.csv\n",
      "Duplicated ns-45-2010.csv to ns-07-2011.csv\n",
      "Duplicated ns-08-2011.csv to ns-09-2011.csv\n",
      "Duplicated ns-08-2011.csv to ns-10-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-12-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-13-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-14-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-15-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-16-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-17-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-18-2011.csv\n",
      "Duplicated ns-11-2011.csv to ns-19-2011.csv\n",
      "Duplicated ns-20-2011.csv to ns-21-2011.csv\n",
      "Duplicated ns-20-2011.csv to ns-22-2011.csv\n",
      "Duplicated ns-23-2011.csv to ns-24-2011.csv\n",
      "Duplicated ns-23-2011.csv to ns-25-2011.csv\n",
      "Duplicated ns-23-2011.csv to ns-26-2011.csv\n",
      "Duplicated ns-23-2011.csv to ns-27-2011.csv\n",
      "Duplicated ns-23-2011.csv to ns-28-2011.csv\n",
      "Duplicated ns-23-2011.csv to ns-29-2011.csv\n",
      "Duplicated ns-23-2011.csv to ns-30-2011.csv\n",
      "Duplicated ns-23-2011.csv to ns-31-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-33-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-34-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-35-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-36-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-37-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-38-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-39-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-40-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-41-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-42-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-43-2011.csv\n",
      "Duplicated ns-32-2011.csv to ns-44-2011.csv\n",
      "Duplicated ns-45-2011.csv to ns-46-2011.csv\n",
      "Duplicated ns-45-2011.csv to ns-47-2011.csv\n",
      "Duplicated ns-45-2011.csv to ns-48-2011.csv\n",
      "Duplicated ns-45-2011.csv to ns-49-2011.csv\n"
     ]
    }
   ],
   "source": [
    "# Process each year\n",
    "for year in range(2011, 2012): # Please change your preferred year range\n",
    "    df_year = df[df['year'] == year]\n",
    "    duplicate_files_table_2(year, df_year, table_2_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710b388",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1baf20e",
   "metadata": {},
   "source": [
    "<div id=\"2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86728175",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;; color: dark;\">2.</span> <span style = \"color: dark; font-family: PT Serif Pro Book;\">Data cleaning</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b56e8cc",
   "metadata": {},
   "source": [
    "<div id=\"2-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff9f258",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    Extracting tables and data cleanup\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad84b6a7",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color:dark; font-size:16px\">\n",
    "<p>     \n",
    "PENDING\n",
    "</p>\n",
    "<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34cbde93",
   "metadata": {},
   "source": [
    "<div id=\"2-1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83c9908",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.1.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 1.</span> Extraction and cleaning of data from tables on monthly real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d245d93f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <b>\"ns_dates\"</b> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "428b77b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'economic_sectors'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lee el archivo CSV con el delimitador ';'\n",
    "df = pd.read_csv('C:\\\\Users\\\\Jason Cruz\\\\OneDrive\\\\Documentos\\\\Research Assistant\\\\CIUP\\\\GDP Revisions\\\\gdp_revisions\\\\old_database\\\\input_data\\\\table_1\\\\1994\\\\ns-03-1994.csv', delimiter=';')\n",
    "df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b63f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7c8ffb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing folder 1994\n",
      "  1. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-03-1994.csv es: ns_03_1994_1\n",
      "  2. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-06-1994.csv es: ns_06_1994_2\n",
      "  3. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-09-1994.csv es: ns_09_1994_3\n",
      "  4. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-13-1994.csv es: ns_13_1994_4\n",
      "  5. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-20-1994.csv es: ns_20_1994_5\n",
      "  6. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-22-1994.csv es: ns_22_1994_6\n",
      "  7. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-25-1994.csv es: ns_25_1994_7\n",
      "  8. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-31-1994.csv es: ns_31_1994_8\n",
      "  9. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-33-1994.csv es: ns_33_1994_9\n",
      "  10. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-37-1994.csv es: ns_37_1994_10\n",
      "  11. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-43-1994.csv es: ns_43_1994_11\n",
      "  12. El dataframe generado para el archivo input_data\\table_1\\1994\\ns-49-1994.csv es: ns_49_1994_12\n",
      "Processing folder 1995\n",
      "  1. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-01-1995.csv es: ns_01_1995_1\n",
      "  2. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-07-1995.csv es: ns_07_1995_2\n",
      "  3. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-13-1995.csv es: ns_13_1995_3\n",
      "  4. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-16-1995.csv es: ns_16_1995_4\n",
      "  5. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-20-1995.csv es: ns_20_1995_5\n",
      "  6. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-25-1995.csv es: ns_25_1995_6\n",
      "  7. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-27-1995.csv es: ns_27_1995_7\n",
      "  8. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-31-1995.csv es: ns_31_1995_8\n",
      "  9. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-38-1995.csv es: ns_38_1995_9\n",
      "  10. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-43-1995.csv es: ns_43_1995_10\n",
      "  11. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-44-1995.csv es: ns_44_1995_11\n",
      "  12. El dataframe generado para el archivo input_data\\table_1\\1995\\ns-48-1995.csv es: ns_48_1995_12\n",
      "Processing folder 1996\n",
      "  1. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-05-1996.csv es: ns_05_1996_1\n",
      "  2. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-09-1996.csv es: ns_09_1996_2\n",
      "  3. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-10-1996.csv es: ns_10_1996_3\n",
      "  4. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-15-1996.csv es: ns_15_1996_4\n",
      "  5. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-18-1996.csv es: ns_18_1996_5\n",
      "  6. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-22-1996.csv es: ns_22_1996_6\n",
      "  7. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-27-1996.csv es: ns_27_1996_7\n",
      "  8. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-35-1996.csv es: ns_35_1996_8\n",
      "  9. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-39-1996.csv es: ns_39_1996_9\n",
      "  10. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-41-1996.csv es: ns_41_1996_10\n",
      "  11. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-44-1996.csv es: ns_44_1996_11\n",
      "  12. El dataframe generado para el archivo input_data\\table_1\\1996\\ns-49-1996.csv es: ns_49_1996_12\n",
      "Processing folder 1997\n",
      "  1. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-02-1997.csv es: ns_02_1997_1\n",
      "  2. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-06-1997.csv es: ns_06_1997_2\n",
      "  3. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-10-1997.csv es: ns_10_1997_3\n",
      "  4. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-11-1997.csv es: ns_11_1997_4\n",
      "  5. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-15-1997.csv es: ns_15_1997_5\n",
      "  6. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-19-1997.csv es: ns_19_1997_6\n",
      "  7. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-25-1997.csv es: ns_25_1997_7\n",
      "  8. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-26-1997.csv es: ns_26_1997_8\n",
      "  9. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-32-1997.csv es: ns_32_1997_9\n",
      "  10. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-37-1997.csv es: ns_37_1997_10\n",
      "  11. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-38-1997.csv es: ns_38_1997_11\n",
      "  12. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-42-1997.csv es: ns_42_1997_12\n",
      "  13. El dataframe generado para el archivo input_data\\table_1\\1997\\ns-48-1997.csv es: ns_48_1997_13\n",
      "Processing folder 1998\n",
      "  1. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-04-1998.csv es: ns_04_1998_1\n",
      "  2. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-06-1998.csv es: ns_06_1998_2\n",
      "  3. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-13-1998.csv es: ns_13_1998_3\n",
      "  4. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-14-1998.csv es: ns_14_1998_4\n",
      "  5. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-20-1998.csv es: ns_20_1998_5\n",
      "  6. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-24-1998.csv es: ns_24_1998_6\n",
      "  7. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-29-1998.csv es: ns_29_1998_7\n",
      "  8. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-31-1998.csv es: ns_31_1998_8\n",
      "  9. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-35-1998.csv es: ns_35_1998_9\n",
      "  10. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-42-1998.csv es: ns_42_1998_10\n",
      "  11. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-45-1998.csv es: ns_45_1998_11\n",
      "  12. El dataframe generado para el archivo input_data\\table_1\\1998\\ns-47-1998.csv es: ns_47_1998_12\n",
      "Processing folder 1999\n",
      "  1. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-05-1999.csv es: ns_05_1999_1\n",
      "  2. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-09-1999.csv es: ns_09_1999_2\n",
      "  3. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-13-1999.csv es: ns_13_1999_3\n",
      "  4. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-17-1999.csv es: ns_17_1999_4\n",
      "  5. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-18-1999.csv es: ns_18_1999_5\n",
      "  6. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-25-1999.csv es: ns_25_1999_6\n",
      "  7. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-29-1999.csv es: ns_29_1999_7\n",
      "  8. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-30-1999.csv es: ns_30_1999_8\n",
      "  9. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-37-1999.csv es: ns_37_1999_9\n",
      "  10. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-38-1999.csv es: ns_38_1999_10\n",
      "  11. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-39-1999.csv es: ns_39_1999_11\n",
      "  12. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-44-1999.csv es: ns_44_1999_12\n",
      "  13. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-46-1999.csv es: ns_46_1999_13\n",
      "  14. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-47-1999.csv es: ns_47_1999_14\n",
      "  15. El dataframe generado para el archivo input_data\\table_1\\1999\\ns-48-1999.csv es: ns_48_1999_15\n",
      "Processing folder 2000\n",
      "  1. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-01-2000.csv es: ns_01_2000_1\n",
      "  2. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-04-2000.csv es: ns_04_2000_2\n",
      "  3. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-07-2000.csv es: ns_07_2000_3\n",
      "  4. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-11-2000.csv es: ns_11_2000_4\n",
      "  5. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-14-2000.csv es: ns_14_2000_5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-19-2000.csv es: ns_19_2000_6\n",
      "  7. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-22-2000.csv es: ns_22_2000_7\n",
      "  8. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-28-2000.csv es: ns_28_2000_8\n",
      "  9. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-32-2000.csv es: ns_32_2000_9\n",
      "  10. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-38-2000.csv es: ns_38_2000_10\n",
      "  11. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-42-2000.csv es: ns_42_2000_11\n",
      "  12. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-46-2000.csv es: ns_46_2000_12\n",
      "  13. El dataframe generado para el archivo input_data\\table_1\\2000\\ns-49-2000.csv es: ns_49_2000_13\n",
      "Processing folder 2001\n",
      "  1. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-01-2001.csv es: ns_01_2001_1\n",
      "  2. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-05-2001.csv es: ns_05_2001_2\n",
      "  3. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-08-2001.csv es: ns_08_2001_3\n",
      "  4. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-10-2001.csv es: ns_10_2001_4\n",
      "  5. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-16-2001.csv es: ns_16_2001_5\n",
      "  6. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-18-2001.csv es: ns_18_2001_6\n",
      "  7. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-25-2001.csv es: ns_25_2001_7\n",
      "  8. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-26-2001.csv es: ns_26_2001_8\n",
      "  9. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-32-2001.csv es: ns_32_2001_9\n",
      "  10. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-34-2001.csv es: ns_34_2001_10\n",
      "  11. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-39-2001.csv es: ns_39_2001_11\n",
      "  12. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-43-2001.csv es: ns_43_2001_12\n",
      "  13. El dataframe generado para el archivo input_data\\table_1\\2001\\ns-48-2001.csv es: ns_48_2001_13\n",
      "Processing folder 2009\n",
      "Folder input_data\\table_1\\2010 has already been processed.\n",
      "Folder input_data\\table_1\\2011 has already been processed.\n",
      "Folder input_data\\table_1\\2012 has already been processed.\n",
      "Processing completed for all folders.\n"
     ]
    }
   ],
   "source": [
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Dictionary to store generated DataFrames\n",
    "old_dataframes_dict_1 = {}\n",
    "\n",
    "# Path for the processed folders log file\n",
    "record_path = 'dataframes_record/old_processed_folders_1.txt'\n",
    "\n",
    "# Function to correct month names\n",
    "def correct_month_name(month):\n",
    "    months_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Add more mappings as needed for other month names\n",
    "    }\n",
    "    return months_mapping.get(month, month)\n",
    "\n",
    "# Function to register processed folder\n",
    "def register_processed_folder(folder, num_processed_files):\n",
    "    with open(record_path, 'a') as file:\n",
    "        file.write(f\"{folder}:{num_processed_files}\\n\")\n",
    "\n",
    "# Function to check if folder has been processed\n",
    "def folder_processed(folder):\n",
    "    if not os.path.exists(record_path):\n",
    "        return False\n",
    "    with open(record_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(folder):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to fetch date from database\n",
    "def get_date(df, engine):\n",
    "    id_ns = df['id_ns'].iloc[0]\n",
    "    year = df['year'].iloc[0]\n",
    "    query = f\"SELECT date FROM dates_growth_rates WHERE id_ns = '{id_ns}' AND year = '{year}';\"\n",
    "    date_result = pd.read_sql(query, engine)\n",
    "    return date_result.iloc[0, 0] if not date_result.empty else None\n",
    "\n",
    "def process_csv(csv_path, engine):\n",
    "    old_tables_dict_1 = {}  # Local dictionary for each CSV\n",
    "    table_counter = 1\n",
    "\n",
    "    filename = os.path.basename(csv_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None # Return None for tables_dict_1 as well\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(csv_path))[0].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(csv_path, delimiter=';')\n",
    "    \n",
    "    dataframe_name = f\"{new_filename}_{table_counter}\"\n",
    "    old_tables_dict_1[dataframe_name] = df.copy()\n",
    "\n",
    "    # Apply cleanup functions to a copy of the DataFrame\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Conditional cleaning based on the first column\n",
    "    if df_clean.columns[1] == 'economic_sectors':\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_services(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "    else:\n",
    "        # Cleaning functions (set as required)\n",
    "        df_clean = clean_column_names(df_clean)\n",
    "        df_clean = adjust_column_names(df_clean)\n",
    "        df_clean = drop_rare_caracter_row(df_clean)\n",
    "        df_clean = drop_nan_rows(df_clean)\n",
    "        df_clean = drop_nan_columns(df_clean)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = remove_digit_slash(df_clean)\n",
    "        df_clean = replace_var_perc_first_column(df_clean)\n",
    "        df_clean = replace_var_perc_last_columns(df_clean)\n",
    "        df_clean = replace_number_moving_average(df_clean)\n",
    "        df_clean = relocate_last_column(df_clean)\n",
    "        df_clean = clean_first_row(df_clean)\n",
    "        df_clean = find_year_column(df_clean)\n",
    "        year_columns = extract_years(df_clean)\n",
    "        df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "        df_clean = first_row_columns(df_clean)\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_services(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "    # Add the column 'year' to the clean DataFrame\n",
    "    df_clean.insert(0, 'year', year)\n",
    "    \n",
    "    # Add the column 'id_ns' to the clean DataFrame\n",
    "    df_clean.insert(1, 'id_ns', id_ns)\n",
    "    \n",
    "    # Get corresponding date from database\n",
    "    date = get_date(df_clean, engine)\n",
    "    if date:\n",
    "        # Add 'date' column to cleaned DataFrame\n",
    "        df_clean.insert(2, 'date', date)\n",
    "    else:\n",
    "        print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "    # Store cleaned DataFrame in old_dataframes_dict_1\n",
    "    old_dataframes_dict_1[dataframe_name] = df_clean\n",
    "\n",
    "    return id_ns, year, old_tables_dict_1\n",
    "\n",
    "# Function to process folder\n",
    "def process_folder(folder, engine):\n",
    "    print(f\"Processing folder {os.path.basename(folder)}\")\n",
    "    csv_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\n",
    "    num_csv_processed = 0\n",
    "    num_dataframes_generated = 0\n",
    "\n",
    "    table_counter = 1  # Initialize table counter here\n",
    "    old_tables_dict_1 = {}  # Declare old_tables_dict_1 outside main loop\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        id_ns, year, tables_dict_temp = process_csv(csv_file, engine)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for dataframe_name, df in tables_dict_temp.items():\n",
    "                file_name = os.path.splitext(os.path.basename(csv_file))[0].replace('-', '_')\n",
    "                dataframe_name = f\"{file_name}_{table_counter}\"\n",
    "                \n",
    "                # Store raw DataFrame in old_tables_dict_1\n",
    "                old_tables_dict_1[dataframe_name] = df.copy()\n",
    "                \n",
    "                # Apply cleanup functions to a copy of the DataFrame\n",
    "                df_clean = df.copy()\n",
    "\n",
    "                # Conditional cleaning based on the first column\n",
    "                if df_clean.columns[1] == 'economic_sectors':\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                else:\n",
    "                    # Cleaning functions (set as required)\n",
    "                    df_clean = clean_column_names(df_clean)\n",
    "                    df_clean = adjust_column_names(df_clean)\n",
    "                    df_clean = drop_rare_caracter_row(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    df_clean = drop_nan_columns(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = remove_digit_slash(df_clean)\n",
    "                    df_clean = replace_var_perc_first_column(df_clean)\n",
    "                    df_clean = replace_var_perc_last_columns(df_clean)\n",
    "                    df_clean = replace_number_moving_average(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = find_year_column(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = get_months_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "                # Add the column 'year' to the clean DataFrame\n",
    "                df_clean.insert(0, 'year', year)\n",
    "\n",
    "                # Add the column 'id_ns' to the clean DataFrame\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "\n",
    "                # Get corresponding date from database\n",
    "                date = get_date(df_clean, engine)\n",
    "                if date:\n",
    "                    # Add 'date' column to cleaned DataFrame\n",
    "                    df_clean.insert(2, 'date', date)\n",
    "                else:\n",
    "                    print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "                # Store cleaned DataFrame in old_dataframes_dict_1\n",
    "                old_dataframes_dict_1[dataframe_name] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. The dataframe generated for the {csv_file} file is: {dataframe_name}')\n",
    "                num_dataframes_generated += 1\n",
    "                table_counter += 1  # Increment table counter here\n",
    "        \n",
    "        num_csv_processed += 1  # Increment number of processed CSV for each CSV in folder\n",
    "\n",
    "    return num_csv_processed, num_dataframes_generated, old_tables_dict_1\n",
    "\n",
    "def process_folders():\n",
    "    csv_folder = table_1_folder\n",
    "    folders = [os.path.join(csv_folder, d) for d in os.listdir(csv_folder) if os.path.isdir(os.path.join(csv_folder, d)) and re.match(r'\\d{4}', d)]\n",
    "    \n",
    "    old_tables_dict_1 = {}  # Initialize old_tables_dict_1 here\n",
    "    \n",
    "    for folder in folders:\n",
    "        if folder_processed(folder):\n",
    "            print(f\"Folder {folder} has already been processed.\")\n",
    "            continue\n",
    "        \n",
    "        num_csv_processed, num_dataframes_generated, tables_dict_temp = process_folder(folder, engine)\n",
    "        \n",
    "        # Update old_tables_dict_1 with values returned from process_folder()\n",
    "        old_tables_dict_1.update(tables_dict_temp)\n",
    "        \n",
    "        register_processed_folder(folder, num_csv_processed)\n",
    "\n",
    "        # Ask user if they want to continue with next folder\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Ensure the messagebox is in front\n",
    "        message = f\"Process {folder} complete. Processed {num_csv_processed} CSV(s) and generated {num_dataframes_generated} DataFrame(s). Continue with next folder?\"\n",
    "        if not messagebox.askyesno(\"Continue?\", message):\n",
    "            break\n",
    "            \n",
    "    print(\"Processing completed for all folders.\")  # Add a message to indicate completion\n",
    "    \n",
    "    return old_tables_dict_1\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    engine = create_sqlalchemy_engine()\n",
    "    old_tables_dict_1 = process_folders()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fda07520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sectores_economicos</th>\n",
       "      <th>economic_sectors</th>\n",
       "      <th>1996_nov</th>\n",
       "      <th>1996_dic</th>\n",
       "      <th>1996_ene_dic</th>\n",
       "      <th>1997_ene</th>\n",
       "      <th>1997_feb</th>\n",
       "      <th>1997_mar</th>\n",
       "      <th>1997_abr</th>\n",
       "      <th>1997_may</th>\n",
       "      <th>1997_jun</th>\n",
       "      <th>1997_jul</th>\n",
       "      <th>1997_ago</th>\n",
       "      <th>1997_sep</th>\n",
       "      <th>1997_oct</th>\n",
       "      <th>1997_nov</th>\n",
       "      <th>1997_ene_nov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agropecuario</td>\n",
       "      <td>agriculture and livestock</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>21.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agricola</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>19.2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>38.9</td>\n",
       "      <td>16.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-14.7</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pecuario</td>\n",
       "      <td>livestock</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pesca</td>\n",
       "      <td>fishing</td>\n",
       "      <td>44.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-18.9</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>45.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>33.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>-51.9</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineria</td>\n",
       "      <td>mining and fuel</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mineria metalica</td>\n",
       "      <td>metals</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>petroleo crudo</td>\n",
       "      <td>fuels</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>manufactura</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>procesadores recursos primarios</td>\n",
       "      <td>based on raw materials</td>\n",
       "      <td>19.3</td>\n",
       "      <td>32.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-10.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>28.2</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>-16.2</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>resto industria</td>\n",
       "      <td>non primary</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>16.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>construccion</td>\n",
       "      <td>construction</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>34.6</td>\n",
       "      <td>37.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>35.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>comercio</td>\n",
       "      <td>commerce</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>otros servicios</td>\n",
       "      <td>other services</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pbi</td>\n",
       "      <td>gdp</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>11.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>pbi promedio de ultimos doce meses</td>\n",
       "      <td>average gdp for the last twelve months</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pbi desestacionalizado</td>\n",
       "      <td>seasonally adjusted gdp</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   sectores_economicos  \\\n",
       "0                         agropecuario   \n",
       "1                             agricola   \n",
       "2                             pecuario   \n",
       "3                                pesca   \n",
       "4                              mineria   \n",
       "5                     mineria metalica   \n",
       "6                       petroleo crudo   \n",
       "7                          manufactura   \n",
       "8      procesadores recursos primarios   \n",
       "9                      resto industria   \n",
       "10                        construccion   \n",
       "11                            comercio   \n",
       "12                     otros servicios   \n",
       "13                                 pbi   \n",
       "14  pbi promedio de ultimos doce meses   \n",
       "15              pbi desestacionalizado   \n",
       "\n",
       "                          economic_sectors  1996_nov  1996_dic  1996_ene_dic  \\\n",
       "0                agriculture and livestock       8.2       9.3           5.8   \n",
       "1                              agriculture      19.2      17.1           8.3   \n",
       "2                                livestock      -3.5       0.0           0.6   \n",
       "3                                  fishing      44.1      75.0          -0.5   \n",
       "4                          mining and fuel       2.0       2.0           2.8   \n",
       "5                                   metals       2.4       0.8           5.3   \n",
       "6                                    fuels       1.3       3.9          -1.2   \n",
       "7                            manufacturing       7.2      11.8           2.7   \n",
       "8                   based on raw materials      19.3      32.6           5.5   \n",
       "9                              non primary       1.8       3.2           1.6   \n",
       "10                            construction      -0.2       5.1          -4.6   \n",
       "11                                commerce       4.8       7.2           3.0   \n",
       "12                          other services       4.2       5.3           3.2   \n",
       "13                                     gdp       5.2       7.8           2.6   \n",
       "14  average gdp for the last twelve months       1.8       2.6           NaN   \n",
       "15                 seasonally adjusted gdp      -0.1       0.7           NaN   \n",
       "\n",
       "    1997_ene  1997_feb  1997_mar  1997_abr  1997_may  1997_jun  1997_jul  \\\n",
       "0       21.8      12.6      14.2       7.9       6.5      -3.2      -3.3   \n",
       "1       38.9      16.4      19.7       8.7       7.6      -4.5      -6.0   \n",
       "2        3.0       7.5       4.5       5.7       2.6       2.2       4.5   \n",
       "3      -18.9     -20.0      31.2      45.3      29.0     -11.4      -1.3   \n",
       "4        3.2       5.0       5.9       7.9       8.7       4.7       1.6   \n",
       "5        4.0       8.7       7.0       9.4      12.2       8.5       5.0   \n",
       "6        1.8      -1.3       4.1       5.5       3.2      -1.6      -4.7   \n",
       "7        3.4       0.1       5.5      20.4       7.5       9.6       5.6   \n",
       "8       -1.8     -10.8       9.5      28.2      12.4       1.1       3.1   \n",
       "9        5.8       4.1       4.3      16.7       5.1      13.5       6.5   \n",
       "10      10.7      15.3       3.1      22.5      16.4      34.6      37.6   \n",
       "11       5.8       3.0       5.6      17.3       4.7       5.8       4.5   \n",
       "12       3.6       3.2       3.8       9.2       4.6       8.3       5.5   \n",
       "13       5.7       4.5       6.0      14.1       7.2       7.4       6.2   \n",
       "14       3.2       3.2       3.8       4.8       5.3       5.6       5.7   \n",
       "15       1.7       2.4      -5.4      14.7      -1.6      -2.4       0.6   \n",
       "\n",
       "    1997_ago  1997_sep  1997_oct  1997_nov  1997_ene_nov  \n",
       "0       -8.0       0.5       3.2      10.4           4.2  \n",
       "1      -14.7      -4.9      -2.2       7.3           3.1  \n",
       "2        7.6       9.5      11.0      14.6           6.6  \n",
       "3       33.6      37.0      43.1     -51.9           1.3  \n",
       "4        7.8       7.4       3.7       4.7           5.5  \n",
       "5       14.2      16.0       9.9      10.0           9.5  \n",
       "6       -3.8      -6.4      -6.9      -4.8          -1.4  \n",
       "7        6.9      12.0      13.8      -0.8           7.5  \n",
       "8        7.1      18.0      14.3     -16.2           5.2  \n",
       "9        6.8      10.1      13.6       7.3           8.4  \n",
       "10      15.2      35.7      28.8      20.2          21.9  \n",
       "11       9.2      12.5       9.7       6.1           7.7  \n",
       "12       7.3       9.1       5.5       6.3           6.1  \n",
       "13       6.3      11.7      10.0       5.0           7.6  \n",
       "14       6.1       6.9       7.7       7.7           NaN  \n",
       "15      -3.9       5.3      -1.1      -4.6           NaN  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_tables_dict_1['ns_04_1998_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3294767c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id_ns</th>\n",
       "      <th>date</th>\n",
       "      <th>sectores_economicos</th>\n",
       "      <th>economic_sectors</th>\n",
       "      <th>1996_nov</th>\n",
       "      <th>1996_dic</th>\n",
       "      <th>1996_ene_dic</th>\n",
       "      <th>1997_ene</th>\n",
       "      <th>1997_feb</th>\n",
       "      <th>1997_mar</th>\n",
       "      <th>1997_abr</th>\n",
       "      <th>1997_may</th>\n",
       "      <th>1997_jun</th>\n",
       "      <th>1997_jul</th>\n",
       "      <th>1997_ago</th>\n",
       "      <th>1997_sep</th>\n",
       "      <th>1997_oct</th>\n",
       "      <th>1997_nov</th>\n",
       "      <th>1997_ene_nov</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>agropecuario</td>\n",
       "      <td>agriculture and livestock</td>\n",
       "      <td>8.2</td>\n",
       "      <td>9.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>21.8</td>\n",
       "      <td>12.6</td>\n",
       "      <td>14.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>-3.2</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>10.4</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>agricola</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>19.2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>8.3</td>\n",
       "      <td>38.9</td>\n",
       "      <td>16.4</td>\n",
       "      <td>19.7</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.6</td>\n",
       "      <td>-4.5</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-14.7</td>\n",
       "      <td>-4.9</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>pecuario</td>\n",
       "      <td>livestock</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>7.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>11.0</td>\n",
       "      <td>14.6</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>pesca</td>\n",
       "      <td>fishing</td>\n",
       "      <td>44.1</td>\n",
       "      <td>75.0</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>-18.9</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>31.2</td>\n",
       "      <td>45.3</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-11.4</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>33.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>43.1</td>\n",
       "      <td>-51.9</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>mineria</td>\n",
       "      <td>mining and fuel</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>8.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>7.8</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>mineria metalica</td>\n",
       "      <td>metals</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>12.2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>petroleo crudo</td>\n",
       "      <td>fuels</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>1.8</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.2</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-4.7</td>\n",
       "      <td>-3.8</td>\n",
       "      <td>-6.4</td>\n",
       "      <td>-6.9</td>\n",
       "      <td>-4.8</td>\n",
       "      <td>-1.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>manufactura</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>7.2</td>\n",
       "      <td>11.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>7.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>procesadores recursos primarios</td>\n",
       "      <td>based on raw materials</td>\n",
       "      <td>19.3</td>\n",
       "      <td>32.6</td>\n",
       "      <td>5.5</td>\n",
       "      <td>-1.8</td>\n",
       "      <td>-10.8</td>\n",
       "      <td>9.5</td>\n",
       "      <td>28.2</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3.1</td>\n",
       "      <td>7.1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.3</td>\n",
       "      <td>-16.2</td>\n",
       "      <td>5.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>resto industria</td>\n",
       "      <td>non primary</td>\n",
       "      <td>1.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.3</td>\n",
       "      <td>16.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>13.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.8</td>\n",
       "      <td>10.1</td>\n",
       "      <td>13.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>construccion</td>\n",
       "      <td>construction</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>5.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>10.7</td>\n",
       "      <td>15.3</td>\n",
       "      <td>3.1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>16.4</td>\n",
       "      <td>34.6</td>\n",
       "      <td>37.6</td>\n",
       "      <td>15.2</td>\n",
       "      <td>35.7</td>\n",
       "      <td>28.8</td>\n",
       "      <td>20.2</td>\n",
       "      <td>21.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>comercio</td>\n",
       "      <td>commerce</td>\n",
       "      <td>4.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>12.5</td>\n",
       "      <td>9.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>otros servicios</td>\n",
       "      <td>other services</td>\n",
       "      <td>4.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>5.5</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9.1</td>\n",
       "      <td>5.5</td>\n",
       "      <td>6.3</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>pbi</td>\n",
       "      <td>gdp</td>\n",
       "      <td>5.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>14.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>11.7</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>pbi promedio de ultimos doce meses</td>\n",
       "      <td>average gdp for the last twelve months</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.2</td>\n",
       "      <td>3.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>5.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>5.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.7</td>\n",
       "      <td>7.7</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1998</td>\n",
       "      <td>04</td>\n",
       "      <td>1998-01-30</td>\n",
       "      <td>pbi desestacionalizado</td>\n",
       "      <td>seasonally adjusted gdp</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-5.4</td>\n",
       "      <td>14.7</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>-2.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>5.3</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>-4.6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year id_ns       date                 sectores_economicos  \\\n",
       "0   1998    04 1998-01-30                        agropecuario   \n",
       "1   1998    04 1998-01-30                            agricola   \n",
       "2   1998    04 1998-01-30                            pecuario   \n",
       "3   1998    04 1998-01-30                               pesca   \n",
       "4   1998    04 1998-01-30                             mineria   \n",
       "5   1998    04 1998-01-30                    mineria metalica   \n",
       "6   1998    04 1998-01-30                      petroleo crudo   \n",
       "7   1998    04 1998-01-30                         manufactura   \n",
       "8   1998    04 1998-01-30     procesadores recursos primarios   \n",
       "9   1998    04 1998-01-30                     resto industria   \n",
       "10  1998    04 1998-01-30                        construccion   \n",
       "11  1998    04 1998-01-30                            comercio   \n",
       "12  1998    04 1998-01-30                     otros servicios   \n",
       "13  1998    04 1998-01-30                                 pbi   \n",
       "14  1998    04 1998-01-30  pbi promedio de ultimos doce meses   \n",
       "15  1998    04 1998-01-30              pbi desestacionalizado   \n",
       "\n",
       "                          economic_sectors  1996_nov  1996_dic  1996_ene_dic  \\\n",
       "0                agriculture and livestock       8.2       9.3           5.8   \n",
       "1                              agriculture      19.2      17.1           8.3   \n",
       "2                                livestock      -3.5       0.0           0.6   \n",
       "3                                  fishing      44.1      75.0          -0.5   \n",
       "4                          mining and fuel       2.0       2.0           2.8   \n",
       "5                                   metals       2.4       0.8           5.3   \n",
       "6                                    fuels       1.3       3.9          -1.2   \n",
       "7                            manufacturing       7.2      11.8           2.7   \n",
       "8                   based on raw materials      19.3      32.6           5.5   \n",
       "9                              non primary       1.8       3.2           1.6   \n",
       "10                            construction      -0.2       5.1          -4.6   \n",
       "11                                commerce       4.8       7.2           3.0   \n",
       "12                          other services       4.2       5.3           3.2   \n",
       "13                                     gdp       5.2       7.8           2.6   \n",
       "14  average gdp for the last twelve months       1.8       2.6           NaN   \n",
       "15                 seasonally adjusted gdp      -0.1       0.7           NaN   \n",
       "\n",
       "    1997_ene  1997_feb  1997_mar  1997_abr  1997_may  1997_jun  1997_jul  \\\n",
       "0       21.8      12.6      14.2       7.9       6.5      -3.2      -3.3   \n",
       "1       38.9      16.4      19.7       8.7       7.6      -4.5      -6.0   \n",
       "2        3.0       7.5       4.5       5.7       2.6       2.2       4.5   \n",
       "3      -18.9     -20.0      31.2      45.3      29.0     -11.4      -1.3   \n",
       "4        3.2       5.0       5.9       7.9       8.7       4.7       1.6   \n",
       "5        4.0       8.7       7.0       9.4      12.2       8.5       5.0   \n",
       "6        1.8      -1.3       4.1       5.5       3.2      -1.6      -4.7   \n",
       "7        3.4       0.1       5.5      20.4       7.5       9.6       5.6   \n",
       "8       -1.8     -10.8       9.5      28.2      12.4       1.1       3.1   \n",
       "9        5.8       4.1       4.3      16.7       5.1      13.5       6.5   \n",
       "10      10.7      15.3       3.1      22.5      16.4      34.6      37.6   \n",
       "11       5.8       3.0       5.6      17.3       4.7       5.8       4.5   \n",
       "12       3.6       3.2       3.8       9.2       4.6       8.3       5.5   \n",
       "13       5.7       4.5       6.0      14.1       7.2       7.4       6.2   \n",
       "14       3.2       3.2       3.8       4.8       5.3       5.6       5.7   \n",
       "15       1.7       2.4      -5.4      14.7      -1.6      -2.4       0.6   \n",
       "\n",
       "    1997_ago  1997_sep  1997_oct  1997_nov  1997_ene_nov  \n",
       "0       -8.0       0.5       3.2      10.4           4.2  \n",
       "1      -14.7      -4.9      -2.2       7.3           3.1  \n",
       "2        7.6       9.5      11.0      14.6           6.6  \n",
       "3       33.6      37.0      43.1     -51.9           1.3  \n",
       "4        7.8       7.4       3.7       4.7           5.5  \n",
       "5       14.2      16.0       9.9      10.0           9.5  \n",
       "6       -3.8      -6.4      -6.9      -4.8          -1.4  \n",
       "7        6.9      12.0      13.8      -0.8           7.5  \n",
       "8        7.1      18.0      14.3     -16.2           5.2  \n",
       "9        6.8      10.1      13.6       7.3           8.4  \n",
       "10      15.2      35.7      28.8      20.2          21.9  \n",
       "11       9.2      12.5       9.7       6.1           7.7  \n",
       "12       7.3       9.1       5.5       6.3           6.1  \n",
       "13       6.3      11.7      10.0       5.0           7.6  \n",
       "14       6.1       6.9       7.7       7.7           NaN  \n",
       "15      -3.9       5.3      -1.1      -4.6           NaN  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_dataframes_dict_1['ns_04_1998_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bb917b",
   "metadata": {},
   "source": [
    "<div id=\"2-1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d489b",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">2.1.2.</span>\n",
    "    <span style = \"color: dark; font-family: PT Serif Pro Book;\">\n",
    "    <span style = \"color: rgb(0, 65, 75); font-family: PT Serif Pro Book;\">Table 2.</span> Extraction and cleaning of data from tables on quarterly and annual real GDP growth rates.\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f21687b",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "    <span style=\"font-size: 24px; color: rgb(255, 32, 78); font-weight: bold;\">&#9888;</span>\n",
    "    <span style=\"font-family: PT Serif Pro Book; color: black; font-size: 16px;\">\n",
    "        Please check that the flat file <b>\"ns_dates.csv\"</b> is updated with the dates, years and ids for the newly downloaded PDF <span style=\"font-size: 24px;\">&#128462;</span> (WR). That file is located in the <b>\"ns_dates\"</b> folder and is uploaded to SQL from the jupyeter notebook <code>aux_files_to_sql.ipynb</code>\n",
    "    </span>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e73d42d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ab041892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carpeta C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2009 ya ha sido procesada.\n",
      "Procesando la carpeta 2010\n",
      "  1. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-04-2010.csv es: ns_04_2010_1\n",
      "  2. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-05-2010.csv es: ns_05_2010_2\n",
      "  3. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-06-2010.csv es: ns_06_2010_3\n",
      "  4. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-07-2010.csv es: ns_07_2010_4\n",
      "  5. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-08-2010.csv es: ns_08_2010_5\n",
      "  6. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-09-2010.csv es: ns_09_2010_6\n",
      "  7. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-10-2010.csv es: ns_10_2010_7\n",
      "  8. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-11-2010.csv es: ns_11_2010_8\n",
      "  9. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-12-2010.csv es: ns_12_2010_9\n",
      "  10. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-13-2010.csv es: ns_13_2010_10\n",
      "  11. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-14-2010.csv es: ns_14_2010_11\n",
      "  12. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-15-2010.csv es: ns_15_2010_12\n",
      "  13. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-16-2010.csv es: ns_16_2010_13\n",
      "  14. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-17-2010.csv es: ns_17_2010_14\n",
      "  15. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-18-2010.csv es: ns_18_2010_15\n",
      "  16. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-19-2010.csv es: ns_19_2010_16\n",
      "  17. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-20-2010.csv es: ns_20_2010_17\n",
      "  18. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-21-2010.csv es: ns_21_2010_18\n",
      "  19. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-22-2010.csv es: ns_22_2010_19\n",
      "  20. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-23-2010.csv es: ns_23_2010_20\n",
      "  21. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-24-2010.csv es: ns_24_2010_21\n",
      "  22. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-25-2010.csv es: ns_25_2010_22\n",
      "  23. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-26-2010.csv es: ns_26_2010_23\n",
      "  24. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-27-2010.csv es: ns_27_2010_24\n",
      "  25. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-28-2010.csv es: ns_28_2010_25\n",
      "  26. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-29-2010.csv es: ns_29_2010_26\n",
      "  27. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-30-2010.csv es: ns_30_2010_27\n",
      "  28. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-31-2010.csv es: ns_31_2010_28\n",
      "  29. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-32-2010.csv es: ns_32_2010_29\n",
      "  30. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-33-2010.csv es: ns_33_2010_30\n",
      "  31. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-34-2010.csv es: ns_34_2010_31\n",
      "  32. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-35-2010.csv es: ns_35_2010_32\n",
      "  33. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-36-2010.csv es: ns_36_2010_33\n",
      "  34. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-37-2010.csv es: ns_37_2010_34\n",
      "  35. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-38-2010.csv es: ns_38_2010_35\n",
      "  36. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-39-2010.csv es: ns_39_2010_36\n",
      "  37. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-40-2010.csv es: ns_40_2010_37\n",
      "  38. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-41-2010.csv es: ns_41_2010_38\n",
      "  39. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-42-2010.csv es: ns_42_2010_39\n",
      "  40. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-43-2010.csv es: ns_43_2010_40\n",
      "  41. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-44-2010.csv es: ns_44_2010_41\n",
      "  42. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-45-2010.csv es: ns_45_2010_42\n",
      "  43. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-46-2010.csv es: ns_46_2010_43\n",
      "  44. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-47-2010.csv es: ns_47_2010_44\n",
      "  45. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-48-2010.csv es: ns_48_2010_45\n",
      "  46. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2010\\ns-49-2010.csv es: ns_49_2010_46\n",
      "Procesando la carpeta 2011\n",
      "  1. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-01-2011.csv es: ns_01_2011_1\n",
      "  2. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-02-2011.csv es: ns_02_2011_2\n",
      "  3. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-03-2011.csv es: ns_03_2011_3\n",
      "  4. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-04-2011.csv es: ns_04_2011_4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-05-2011.csv es: ns_05_2011_5\n",
      "  6. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-06-2011.csv es: ns_06_2011_6\n",
      "  7. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-07-2011.csv es: ns_07_2011_7\n",
      "  8. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-08-2011.csv es: ns_08_2011_8\n",
      "  9. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-09-2011.csv es: ns_09_2011_9\n",
      "  10. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-10-2011.csv es: ns_10_2011_10\n",
      "  11. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-11-2011.csv es: ns_11_2011_11\n",
      "  12. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-12-2011.csv es: ns_12_2011_12\n",
      "  13. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-13-2011.csv es: ns_13_2011_13\n",
      "  14. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-14-2011.csv es: ns_14_2011_14\n",
      "  15. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-15-2011.csv es: ns_15_2011_15\n",
      "  16. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-16-2011.csv es: ns_16_2011_16\n",
      "  17. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-17-2011.csv es: ns_17_2011_17\n",
      "  18. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-18-2011.csv es: ns_18_2011_18\n",
      "  19. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-19-2011.csv es: ns_19_2011_19\n",
      "  20. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-20-2011.csv es: ns_20_2011_20\n",
      "  21. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-21-2011.csv es: ns_21_2011_21\n",
      "  22. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-22-2011.csv es: ns_22_2011_22\n",
      "  23. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-23-2011.csv es: ns_23_2011_23\n",
      "  24. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-24-2011.csv es: ns_24_2011_24\n",
      "  25. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-25-2011.csv es: ns_25_2011_25\n",
      "  26. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-26-2011.csv es: ns_26_2011_26\n",
      "  27. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-27-2011.csv es: ns_27_2011_27\n",
      "  28. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-28-2011.csv es: ns_28_2011_28\n",
      "  29. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-29-2011.csv es: ns_29_2011_29\n",
      "  30. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-30-2011.csv es: ns_30_2011_30\n",
      "  31. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-31-2011.csv es: ns_31_2011_31\n",
      "  32. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-32-2011.csv es: ns_32_2011_32\n",
      "  33. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-33-2011.csv es: ns_33_2011_33\n",
      "  34. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-34-2011.csv es: ns_34_2011_34\n",
      "  35. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-35-2011.csv es: ns_35_2011_35\n",
      "  36. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-36-2011.csv es: ns_36_2011_36\n",
      "  37. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-37-2011.csv es: ns_37_2011_37\n",
      "  38. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-38-2011.csv es: ns_38_2011_38\n",
      "  39. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-39-2011.csv es: ns_39_2011_39\n",
      "  40. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-40-2011.csv es: ns_40_2011_40\n",
      "  41. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-41-2011.csv es: ns_41_2011_41\n",
      "  42. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-42-2011.csv es: ns_42_2011_42\n",
      "  43. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-43-2011.csv es: ns_43_2011_43\n",
      "  44. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-44-2011.csv es: ns_44_2011_44\n",
      "  45. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-45-2011.csv es: ns_45_2011_45\n",
      "  46. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-46-2011.csv es: ns_46_2011_46\n",
      "  47. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-47-2011.csv es: ns_47_2011_47\n",
      "  48. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-48-2011.csv es: ns_48_2011_48\n",
      "  49. El dataframe generado para el archivo C:\\Users\\Jason Cruz\\OneDrive\\Documentos\\coding_training\\old_dataset\\raw_data\\tabla 2\\2011\\ns-49-2011.csv es: ns_49_2011_49\n",
      "Procesamiento detenido por el usuario.\n",
      "Procesamiento completado para todas las carpetas.\n"
     ]
    }
   ],
   "source": [
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Dictionary to store generated DataFrames\n",
    "old_dataframes_dict_2 = {}\n",
    "\n",
    "# Path for the processed folders log file\n",
    "record_path = 'dataframes_record/old_processed_folders_2.txt'\n",
    "\n",
    "# Function to correct month names\n",
    "def correct_month_name(month):\n",
    "    months_mapping = {\n",
    "        'setiembre': 'septiembre',\n",
    "        # Add more mappings as needed for other month names\n",
    "    }\n",
    "    return months_mapping.get(month, month)\n",
    "\n",
    "# Function to register processed folder\n",
    "def register_processed_folder(folder, num_processed_files):\n",
    "    with open(record_path, 'a') as file:\n",
    "        file.write(f\"{folder}:{num_processed_files}\\n\")\n",
    "\n",
    "# Function to check if folder has been processed\n",
    "def folder_processed(folder):\n",
    "    if not os.path.exists(record_path):\n",
    "        return False\n",
    "    with open(record_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith(folder):\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "# Function to fetch date from database\n",
    "def get_date(df, engine):\n",
    "    id_ns = df['id_ns'].iloc[0]\n",
    "    year = df['year'].iloc[0]\n",
    "    query = f\"SELECT date FROM dates_growth_rates WHERE id_ns = '{id_ns}' AND year = '{year}';\"\n",
    "    date_result = pd.read_sql(query, engine)\n",
    "    return date_result.iloc[0, 0] if not date_result.empty else None\n",
    "\n",
    "def process_csv(csv_path, engine):\n",
    "    old_tables_dict_2 = {}  # Local dictionary for each CSV\n",
    "    table_counter = 1\n",
    "\n",
    "    filename = os.path.basename(csv_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None # Return None for tables_dict_1 as well\n",
    "\n",
    "    new_filename = os.path.splitext(os.path.basename(csv_path))[0].replace('-', '_')\n",
    "\n",
    "    df = pd.read_csv(csv_path, delimiter=';')\n",
    "    \n",
    "    dataframe_name = f\"{new_filename}_{table_counter}\"\n",
    "    old_tables_dict_2[dataframe_name] = df.copy()\n",
    "\n",
    "    # Apply cleanup functions to a copy of the DataFrame\n",
    "    df_clean = df.copy()\n",
    "\n",
    "    # Conditional cleaning based on the first column\n",
    "    if df_clean.columns[1] == 'sectores_economicos':\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_services(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "    else:\n",
    "        # Cleaning functions (set as required)\n",
    "        df_clean = replace_total_with_year(df_clean)\n",
    "        df_clean = drop_nan_rows(df_clean)\n",
    "        year_columns = extract_years(df_clean)\n",
    "        df_clean = roman_arabic(df_clean)\n",
    "        df_clean = fix_duplicates(df_clean)\n",
    "        df_clean = relocate_last_column(df_clean)\n",
    "        df_clean = replace_first_row_nan(df_clean)\n",
    "        df_clean = clean_first_row(df_clean)\n",
    "        df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = first_row_columns(df_clean)\n",
    "        df_clean = clean_columns_values(df_clean)\n",
    "        df_clean = reset_index(df_clean)\n",
    "        df_clean = convert_float(df_clean)\n",
    "        df_clean = replace_set_sep(df_clean)\n",
    "        df_clean = spaces_se_es(df_clean)\n",
    "        df_clean = replace_services(df_clean)\n",
    "        df_clean = rounding_values(df_clean, decimals=1)\n",
    "\n",
    "    # Add the column 'year' to the clean DataFrame\n",
    "    df_clean.insert(0, 'year', year)\n",
    "    \n",
    "    # Add the column 'id_ns' to the clean DataFrame\n",
    "    df_clean.insert(1, 'id_ns', id_ns)\n",
    "    \n",
    "    # Get corresponding date from database\n",
    "    date = get_date(df_clean, engine)\n",
    "    if date:\n",
    "        # Add 'date' column to cleaned DataFrame\n",
    "        df_clean.insert(2, 'date', date)\n",
    "    else:\n",
    "        print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "    # Store cleaned DataFrame in old_dataframes_dict_2\n",
    "    old_dataframes_dict_2[dataframe_name] = df_clean\n",
    "\n",
    "    return id_ns, year, old_tables_dict_2\n",
    "\n",
    "# Function to process folder\n",
    "def process_folder(folder, engine):\n",
    "    print(f\"Processing folder {os.path.basename(folder)}\")\n",
    "    csv_files = [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith('.csv')]\n",
    "\n",
    "    num_csv_processed = 0\n",
    "    num_dataframes_generated = 0\n",
    "\n",
    "    table_counter = 1  # Initialize table counter here\n",
    "    old_tables_dict_2 = {}  # Declare old_tables_dict_1 outside main loop\n",
    "    \n",
    "    for csv_file in csv_files:\n",
    "        id_ns, year, tables_dict_temp = process_csv(csv_file, engine)\n",
    "\n",
    "        if tables_dict_temp:\n",
    "            for dataframe_name, df in tables_dict_temp.items():\n",
    "                file_name = os.path.splitext(os.path.basename(csv_file))[0].replace('-', '_')\n",
    "                dataframe_name = f\"{file_name}_{table_counter}\"\n",
    "                \n",
    "                # Store raw DataFrame in old_tables_dict_2\n",
    "                old_tables_dict_2[dataframe_name] = df.copy()\n",
    "                \n",
    "                # Procesar y limpiar el DataFrame\n",
    "                df_clean = df.copy()\n",
    "                \n",
    "                # Conditional cleaning based on the first column\n",
    "                if df_clean.columns[1] == 'sectores_economicos':\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                else:\n",
    "                    # Cleaning functions (set as required)\n",
    "                    df_clean = replace_total_with_year(df_clean)\n",
    "                    df_clean = drop_nan_rows(df_clean)\n",
    "                    year_columns = extract_years(df_clean)\n",
    "                    df_clean = roman_arabic(df_clean)\n",
    "                    df_clean = fix_duplicates(df_clean)\n",
    "                    df_clean = relocate_last_column(df_clean)\n",
    "                    df_clean = replace_first_row_nan(df_clean)\n",
    "                    df_clean = clean_first_row(df_clean)\n",
    "                    df_clean = get_quarters_sublist_list(df_clean, year_columns)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = first_row_columns(df_clean)\n",
    "                    df_clean = clean_columns_values(df_clean)\n",
    "                    df_clean = reset_index(df_clean)\n",
    "                    df_clean = convert_float(df_clean)\n",
    "                    df_clean = replace_set_sep(df_clean)\n",
    "                    df_clean = spaces_se_es(df_clean)\n",
    "                    df_clean = replace_services(df_clean)\n",
    "                    df_clean = rounding_values(df_clean, decimals=1)\n",
    "                \n",
    "                # Add the column 'year' to the clean DataFrame\n",
    "                df_clean.insert(0, 'year', year)\n",
    "\n",
    "                # Add the column 'id_ns' to the clean DataFrame\n",
    "                df_clean.insert(1, 'id_ns', id_ns)\n",
    "\n",
    "                # Get corresponding date from database\n",
    "                date = get_date(df_clean, engine)\n",
    "                if date:\n",
    "                    # Add 'date' column to cleaned DataFrame\n",
    "                    df_clean.insert(2, 'date', date)\n",
    "                else:\n",
    "                    print(\"Date not found in database for id_ns:\", id_ns, \"and year:\", year)\n",
    "\n",
    "                # Store cleaned DataFrame in old_dataframes_dict_2\n",
    "                old_dataframes_dict_2[dataframe_name] = df_clean\n",
    "\n",
    "                print(f'  {table_counter}. The dataframe generated for the {csv_file} file is: {dataframe_name}')\n",
    "                num_dataframes_generated += 1\n",
    "                table_counter += 1  # Increment table counter here\n",
    "        \n",
    "        num_csv_processed += 1  # Increment number of processed CSV for each CSV in folder\n",
    "\n",
    "    return num_csv_processed, num_dataframes_generated, old_tables_dict_2\n",
    "\n",
    "def process_folders():\n",
    "    csv_folder = table_2_folder\n",
    "    folders = [os.path.join(csv_folder, d) for d in os.listdir(csv_folder) if os.path.isdir(os.path.join(csv_folder, d)) and re.match(r'\\d{4}', d)]\n",
    "    \n",
    "    old_tables_dict_2 = {}  # Initialize old_tables_dict_1 here\n",
    "    \n",
    "    for folder in folders:\n",
    "        if folder_processed(folder):\n",
    "            print(f\"Folder {folder} has already been processed.\")\n",
    "            continue\n",
    "        \n",
    "        num_csv_processed, num_dataframes_generated, tables_dict_temp = process_folder(folder, engine)\n",
    "        \n",
    "        # Update old_tables_dict_2 with values returned from process_folder()\n",
    "        old_tables_dict_2.update(tables_dict_temp)\n",
    "        \n",
    "        register_processed_folder(folder, num_csv_processed)\n",
    "\n",
    "        # Ask user if they want to continue with next folder\n",
    "        root = Tk()\n",
    "        root.withdraw()\n",
    "        root.attributes('-topmost', True)  # Ensure the messagebox is in front\n",
    "        message = f\"Process {folder} complete. Processed {num_csv_processed} CSV(s) and generated {num_dataframes_generated} DataFrame(s). Continue with next folder?\"\n",
    "        if not messagebox.askyesno(\"Continue?\", message):\n",
    "            break\n",
    "\n",
    "    print(\"Processing completed for all folders.\")  # Add a message to indicate completion\n",
    "\n",
    "    return old_tables_dict_2\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    engine = create_sqlalchemy_engine()\n",
    "    old_tables_dict_2 = process_folders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tables_dict_2['ns_04_2010_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b05cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataframes_dict_2['ns_32_2010_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6942ad4",
   "metadata": {},
   "source": [
    "<div style=\"font-family: PT Serif Pro Book; text-align: left; color: dark; font-size: 16px;\">\n",
    "    <span style=\"font-size: 30px; color: rgb(255, 32, 78); font-weight: bold;\">\n",
    "        <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">&#11180;</a>\n",
    "    </span> \n",
    "    <a href=\"#outilne\" style=\"color: rgb(0, 153, 123); text-decoration: none;\">Back to the outline.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7156504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
