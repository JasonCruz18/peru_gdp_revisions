{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65529edd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca53227e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter'; color: rgb(0, 65, 75);\">\n",
    "    <h1>\n",
    "    GDP Revisions Datasets\n",
    "    </h1>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06137d2",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter'; color: rgb(0, 65, 75);\">\n",
    "    <h4>\n",
    "        Documentation\n",
    "        <br>\n",
    "        ____________________\n",
    "            </br>\n",
    "    </h4>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666fe505",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color: dark;\">\n",
    "    This \n",
    "    <span style=\"color: rgb(61, 48, 162);\">jupyter notebook</span>\n",
    "    provides a step-by-step guide to <b>data building</b> regarding the project <b>'Revisiones y sesgos en las estimaciones preliminares del PBI en el Perú'</b>. The guide covers downloading PDF files containing tables with information on annual, quarterly, and monthly Peru's GDP growth rates (including sectoral GDP) and extracting this information into SQL tables. These data sets will be used for data analysis.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d22837",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-family: 'charter'; color: rgb(0, 65, 75);\">\n",
    "    Jason Cruz\n",
    "    <br>\n",
    "    <a href=\"mailto:jj.cruza@up.edu.pe\" style=\"color: rgb(0, 153, 123)\">\n",
    "        jj.cruza@up.edu.pe\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f71392",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Times New Roman; text-align: left; color: rgb(61, 48, 162)\">The provided outline is functional. Use the buttons to enhance the experience of this script.<div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e3813a",
   "metadata": {},
   "source": [
    "<div id=\"outilne\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bde4ba",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #141414; padding: 10px;\">\n",
    "<h2 style=\"text-align: left; font-family: 'charter'; color: #E0E0E0;\">\n",
    "    Outline\n",
    "    </h2>\n",
    "    <br>\n",
    "    <a href=\"#1\" style=\"color: #687EFF; font-size: 18px;\">\n",
    "        1. PDF Downloader</a>\n",
    "    <br>\n",
    "    <a href=\"#2\" style=\"color: #687EFF; font-size: 18px;\">\n",
    "        2. Extracting Tables (and data cleaning)</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        2.1. 'pdfplumber' demo.</a>\n",
    "    <br>\n",
    "    <a href=\"#2-1-1\" style=\"color: #E0E0E0; font-size: 12px;\">\n",
    "        2.1.1. What data would we get if we used the default settings?.</a>   \n",
    "    <br>\n",
    "    <a href=\"#2-1-2\" style=\"color: #E0E0E0; font-size: 12px;\">\n",
    "        2.1.2. Using custom '.extract_table' settings.</a>\n",
    "    <br> \n",
    "    <a href=\"#2-2\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        2.2. Extracting tables and generating dataframes (includes data cleanup).</a>\n",
    "    <br>\n",
    "    <a href=\"#3\" style=\"color: #687EFF; font-size: 18px;\">3. SQL Tables</a>\n",
    "    <br>\n",
    "    <a href=\"#3-1\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        3.1. Annual Concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-2\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        3.2. Quarterly Concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-3\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        3.3. Monthly Concatenation.</a>\n",
    "    <br>\n",
    "    <a href=\"#3-4\" style=\"color: rgb(0, 153, 123); font-size: 12px;\">\n",
    "        3.4. Loading SQL.</a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01b18b0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    Any questions or issues regarding the coding, please <a href=\"mailto:jj.cruza@alum.up.edu.pe\" style=\"color: rgb(0, 153, 123)\">email Jason Cruz\n",
    "    </a>.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f385b8f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    If you don't have the libraries below, please use the following code (as example) to install the required libraries.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e29417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install os # Comment this code with \"#\" if you have already installed this library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a3053f",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    <h2>\n",
    "    Libraries\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eef8a4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF Downloader\n",
    "\n",
    "import os  # for file and directory manipulation\n",
    "import random  # to generate random numbers\n",
    "import time  # to manage time and take breaks in the script\n",
    "import requests  # to make HTTP requests to web servers\n",
    "from selenium import webdriver  # for automating web browsers\n",
    "from selenium.webdriver.common.by import By  # to locate elements on a webpage\n",
    "from selenium.webdriver.support.ui import WebDriverWait  # to wait until certain conditions are met on a webpage.\n",
    "from selenium.webdriver.support import expected_conditions as EC  # to define expected conditions\n",
    "from selenium.common.exceptions import StaleElementReferenceException  # To handle exceptions related to elements on the webpage that are no longer available.\n",
    "\n",
    "\n",
    "# Extracting Tables (and data cleaning)\n",
    "\n",
    "import pdfplumber  # for extracting text and metadata from PDF files\n",
    "import pandas as pd  # for data manipulation and analysis\n",
    "import os  # for interacting with the operating system\n",
    "import unicodedata  # for manipulating Unicode data\n",
    "import re  # for regular expressions operations\n",
    "from datetime import datetime  # for working with dates and times\n",
    "import locale  # for locale-specific formatting of numbers, dates, and currencies\n",
    "\n",
    "\n",
    "# SQL tables\n",
    "\n",
    "import psycopg2  # for interacting with PostgreSQL databases\n",
    "from sqlalchemy import create_engine, text  # for creating and executing SQL queries using SQLAlchemy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b859ccef",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left; font-family: 'charter'; color: dark;\">\n",
    "    <h2>\n",
    "    Initial set-up\n",
    "    </h2>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb70babd",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\"> The next 3 code lines will create folders in your current path, call them to import and export your outputs. <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8899a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to download PDF files\n",
    "\n",
    "raw_pdf = 'raw_pdf' # to save raw data (.pdf).\n",
    "if not os.path.exists(raw_pdf):\n",
    "    os.mkdir(raw_pdf) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdd8e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder path to save text file with the names of already downloaded files\n",
    "\n",
    "download_record = 'download_record'\n",
    "if not os.path.exists(download_record):\n",
    "    os.mkdir(download_record) # to create the folder (if it doesn't exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be2a42b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8724cb2e",
   "metadata": {},
   "source": [
    "<div id=\"1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bf24f3",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: charter;\">1.</span> <span style = \"color: dark; font-family: charter;\">PDF Downloader</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d278669f",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Our main source for data collection is the <a href=\"https://www.bcrp.gob.pe/\" style=\"color: rgb(0, 153, 123)\">BCRP's web page</a> (.../publicaciones/nota-semanal). The BCRP publishes \"Notas Semanales\", documents that contain, among other information, tables of GDP and sectoral GDP growth rate values for annual, quarterly and monthly frequencies.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c6c95",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47560cf2",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    The provided code will download all the 'Notas Semanales' files in PDF format from this web page.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11851f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the BCRP URL\n",
    "bcrp_url = \"https://www.bcrp.gob.pe/publicaciones/nota-semanal.html\"  # Never replace this URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9634fd79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c889b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the driver path\n",
    "driver_path = os.environ.get('driver_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6639a8c5",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    The provided code will download all the 'Notas Semanales' files in PDF format from this web page.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd970d44",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='127.0.0.1', port=11249): Max retries exceeded with url: /session/0a8de564abaea62b5b31aa3c1f847b11/window/handles (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021925C53020>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\util\\connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connectionpool.py:715\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 715\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    723\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    725\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connectionpool.py:416\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    415\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 416\u001b[0m         \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhttplib_request_kw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    418\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers)\u001b[0m\n\u001b[0;32m    243\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[1;32m--> 244\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mHTTPConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\http\\client.py:1327\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1327\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\http\\client.py:1373\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1372\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1373\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\http\\client.py:1322\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1322\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\http\\client.py:1081\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1080\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1081\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1084\u001b[0m \n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\http\\client.py:1025\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[0;32m    188\u001b[0m     )\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x0000021925C53020>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m     driver\u001b[38;5;241m.\u001b[39mexecute_script(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marguments[0].click();\u001b[39m\u001b[38;5;124m\"\u001b[39m, pdf_link)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Wait for the new page to completely open (adjust the time as necessary)\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m \u001b[43mwait\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumber_of_windows_to_be\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Switch to the new window or tab\u001b[39;00m\n\u001b[0;32m     31\u001b[0m windows \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mwindow_handles\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\selenium\\webdriver\\support\\wait.py:71\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[1;34m(self, method, message)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 71\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m value:\n\u001b[0;32m     73\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\selenium\\webdriver\\support\\expected_conditions.py:380\u001b[0m, in \u001b[0;36mnumber_of_windows_to_be.__call__\u001b[1;34m(self, driver)\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, driver):\n\u001b[1;32m--> 380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwindow_handles\u001b[49m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_windows\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:724\u001b[0m, in \u001b[0;36mWebDriver.window_handles\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    718\u001b[0m \u001b[38;5;124;03mReturns the handles of all windows within the current session.\u001b[39;00m\n\u001b[0;32m    719\u001b[0m \n\u001b[0;32m    720\u001b[0m \u001b[38;5;124;03m:Usage:\u001b[39;00m\n\u001b[0;32m    721\u001b[0m \u001b[38;5;124;03m    driver.window_handles\u001b[39;00m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw3c:\n\u001b[1;32m--> 724\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW3C_GET_WINDOW_HANDLES\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    725\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(Command\u001b[38;5;241m.\u001b[39mGET_WINDOW_HANDLES)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:319\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    316\u001b[0m         params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[0;32m    318\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_value(params)\n\u001b[1;32m--> 319\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    321\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:374\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    372\u001b[0m data \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mdump_json(params)\n\u001b[0;32m    373\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_url, path)\n\u001b[1;32m--> 374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:397\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    394\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    396\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 397\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m resp\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\request.py:77\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     74\u001b[0m urlopen_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_url\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m url\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_url_methods:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[0;32m     82\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[0;32m     83\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\request.py:99\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[1;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fields:\n\u001b[0;32m     97\u001b[0m     url \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m urlencode(fields)\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connectionpool.py:827\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    826\u001b[0m     )\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    844\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connectionpool.py:827\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    826\u001b[0m     )\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    844\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connectionpool.py:827\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    825\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    826\u001b[0m     )\n\u001b[1;32m--> 827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[0;32m    841\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    843\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    844\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\connectionpool.py:799\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (SocketError, HTTPException)):\n\u001b[0;32m    797\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[1;32m--> 799\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    804\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\gdp_revisions\\Lib\\site-packages\\urllib3\\util\\retry.py:592\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    581\u001b[0m new_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew(\n\u001b[0;32m    582\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal,\n\u001b[0;32m    583\u001b[0m     connect\u001b[38;5;241m=\u001b[39mconnect,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    588\u001b[0m     history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[0;32m    589\u001b[0m )\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[1;32m--> 592\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[0;32m    594\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=11249): Max retries exceeded with url: /session/0a8de564abaea62b5b31aa3c1f847b11/window/handles (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x0000021925C53020>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión'))"
     ]
    }
   ],
   "source": [
    "# List for keeping track of successfully downloaded files\n",
    "downloaded_files = []\n",
    "\n",
    "# Load list of previously downloaded files if available\n",
    "if os.path.exists(os.path.join(download_record, \"downloaded_files.txt\")):\n",
    "    with open(os.path.join(download_record, \"downloaded_files.txt\"), \"r\") as f:\n",
    "        downloaded_files = f.read().splitlines()\n",
    "\n",
    "# Browser driver configuration\n",
    "driver = webdriver.Chrome(executable_path=driver_path)\n",
    "\n",
    "def random_wait(min_time, max_time):\n",
    "    \"\"\"\n",
    "    Waits randomly for a time between min_time and max_time seconds \n",
    "    before continuing with the execution of the script.\n",
    "    \"\"\"\n",
    "    wait_time = random.uniform(min_time, max_time)\n",
    "    print(f\"Waiting randomly for {wait_time:.2f} seconds\")\n",
    "    time.sleep(wait_time)\n",
    "\n",
    "def download_pdf(pdf_link):\n",
    "    \"\"\"\n",
    "    Clicks on the link using JavaScript to initiate the PDF download.\n",
    "    \"\"\"\n",
    "    driver.execute_script(\"arguments[0].click();\", pdf_link)\n",
    "\n",
    "# Wait for the new page to completely open (adjust the time as necessary)\n",
    "wait.until(EC.number_of_windows_to_be(2))\n",
    "\n",
    "# Switch to the new window or tab\n",
    "windows = driver.window_handles\n",
    "driver.switch_to.window(windows[1])\n",
    "\n",
    "# Get the current URL (may vary depending on the site's specific logic)\n",
    "new_url = driver.current_url\n",
    "print(f\"{download_counter}. New URL: {new_url}\")\n",
    "\n",
    "# Get the file name from the URL\n",
    "file_name = new_url.split(\"/\")[-1]\n",
    "\n",
    "# Form the complete destination path\n",
    "destination_path = os.path.join(raw_pdf, file_name)\n",
    "\n",
    "# Download the PDF\n",
    "response = requests.get(new_url, stream=True)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    # Save the PDF content to the local file\n",
    "    with open(destination_path, 'wb') as pdf_file:\n",
    "        for chunk in response.iter_content(chunk_size=128):\n",
    "            pdf_file.write(chunk)\n",
    "\n",
    "    print(f\"PDF downloaded successfully at: {destination_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error downloading the PDF. Response code: {response.status_code}\")\n",
    "\n",
    "# Close the new window or tab\n",
    "driver.close()\n",
    "\n",
    "# Switch back to the main window\n",
    "driver.switch_to.window(windows[0])\n",
    "\n",
    "# Batch download quantity\n",
    "downloads_per_batch = 5\n",
    "# Total number of downloads\n",
    "total_download_count = 25\n",
    "\n",
    "try:\n",
    "    # Open the BCRP NS publications page\n",
    "    driver.get(bcrp_url)\n",
    "    print(\"Site opened successfully\")\n",
    "\n",
    "    # Wait for the container area to be present\n",
    "    wait = WebDriverWait(driver, 60)\n",
    "    container_area = wait.until(EC.presence_of_element_located((By.XPATH, '//*[@id=\"rightside\"]')))\n",
    "\n",
    "    # Get all links within the container area\n",
    "    pdf_links = container_area.find_elements(By.XPATH, './/a')\n",
    "\n",
    "    # Reverse the order of links\n",
    "    pdf_links = list(reversed(pdf_links))\n",
    "\n",
    "    # Initialize download counter\n",
    "    download_counter = 0\n",
    "\n",
    "    # Iterate over reversed links and download PDFs in batches\n",
    "    for pdf_link in pdf_links:\n",
    "        download_counter += 1\n",
    "\n",
    "        # Get the file name from the URL\n",
    "        new_url = pdf_link.get_attribute(\"href\")\n",
    "        file_name = new_url.split(\"/\")[-1]\n",
    "\n",
    "        # Check if the file has already been downloaded\n",
    "        if file_name in downloaded_files:\n",
    "            print(f\"{download_counter}. The file {file_name} has already been downloaded previously. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Attempt to download the file\n",
    "        try:\n",
    "            download_pdf(pdf_link)\n",
    "\n",
    "            # Update the list of downloaded files\n",
    "            downloaded_files.append(file_name)\n",
    "\n",
    "            # Save the file name in the log\n",
    "            with open(os.path.join(download_record, \"downloaded_files.txt\"), \"a\") as f:\n",
    "                f.write(file_name + \"\\n\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error downloading the file {file_name}: {str(e)}\")\n",
    "\n",
    "        # If download count reaches a multiple of batch size, notify\n",
    "        if download_counter % downloads_per_batch == 0:\n",
    "            print(f\"Batch {download_counter // downloads_per_batch} of {downloads_per_batch} completed\")\n",
    "\n",
    "        # Wait randomly before the next iteration\n",
    "        random_wait(5, 10)\n",
    "\n",
    "        # If total download count is reached, break the loop\n",
    "        if download_counter == total_download_count:\n",
    "            print(f\"All downloads completed ({total_download_count} in total)\")\n",
    "            break\n",
    "\n",
    "except StaleElementReferenceException:\n",
    "    print(\"A StaleElementReferenceException occurred. Retrying...\")\n",
    "\n",
    "finally:\n",
    "    # Close the browser upon completion\n",
    "    driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df42180",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88943561",
   "metadata": {},
   "source": [
    "<div id=\"2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415a6ff1",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.</span> <span style = \"color: dark; font-family: charter;\">Extracting Tables (and data cleaning)</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71ac57",
   "metadata": {},
   "source": [
    "<div id=\"2-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2715780f",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.1.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        pdfplumber\n",
    "    </span> \n",
    "    demo\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73de62f1",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Import\n",
    "    <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        pdfplumber\n",
    "    </span>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1d31d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "print(f'This library version is: {pdfplumber.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2ec125",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Load the PDF\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcf02fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pdfplumber.open(\"{raw_pdf}\\\\ns-10-2013.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b5f60",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Get the page 82\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba906154",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_82 = pdf.pages[81]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d3dabb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the page to a higher resolution image (e.g., 300 DPI).\n",
    "image = p_82.to_image(resolution=300)\n",
    "image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa06b54",
   "metadata": {},
   "source": [
    "<div id=\"2-1-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fab2ee",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.1.1.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    What data would we get if we used the default settings?\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3dfc6a",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    We can check by using <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        PageImage.debug_tablefinder()\n",
    "    </span>:\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f727f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.reset().debug_tablefinder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3d23c8",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    The default settings correctly identify the table's vertical demarcations, but don't capture the horizontal demarcations between each group of five states/territories. So:\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb0afff",
   "metadata": {},
   "source": [
    "<div id=\"2-1-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9246dce1",
   "metadata": {},
   "source": [
    "<h3><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.1.2.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Using custom <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        <b>.extract_table\n",
    "            </b>\n",
    "    </span>'s settings\n",
    "    </span>\n",
    "    </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0128ebb1",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    <ul>\n",
    "        <li>Because the columns are separated by lines, we use <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        vertical_strategy=\"lines\"\n",
    "    </span>.\n",
    "            </li>\n",
    "        <li>Because the rows are, primarily, separated by gutters between the text, we use <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        horizontal_strategy=\"text\"\n",
    "    </span>.\n",
    "            <li>To snap together a handful of the gutters at the top which aren't fully flush with one another, we use <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        snap_y_tolerance\n",
    "    </span>which snaps horizontal lines within a certain distance to the same vertical alignment.\n",
    "                </li>\n",
    "        <li>And because the left and right-hand extremities of the text aren't quite flush with the vertical lines, we use <span style=\"background-color: #f2f2f2; font-family: Courier New;\">\n",
    "        \"intersection_tolerance\": 15\n",
    "    </span>.\n",
    "            </li>\n",
    "        </ul>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1184cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_settings = {\n",
    "    \"vertical_strategy\": \"lines\", \n",
    "    \"horizontal_strategy\": \"lines\",\n",
    "    \"explicit_vertical_lines\": [],\n",
    "    \"explicit_horizontal_lines\": [],\n",
    "    \"snap_tolerance\": 3,\n",
    "    \"snap_x_tolerance\": 3,\n",
    "    \"snap_y_tolerance\": 3,\n",
    "    \"join_tolerance\": 3,\n",
    "    \"join_x_tolerance\": 3,\n",
    "    \"join_y_tolerance\": 3,\n",
    "    \"edge_min_length\": 3,\n",
    "    \"min_words_vertical\": 3,\n",
    "    \"min_words_horizontal\": 1,\n",
    "    \"text_keep_blank_chars\": False,\n",
    "    \"text_tolerance\": 3,\n",
    "    \"text_x_tolerance\": 3,\n",
    "    \"text_y_tolerance\": 3,\n",
    "    \"intersection_tolerance\": 3,\n",
    "    \"intersection_x_tolerance\": 3,\n",
    "    \"intersection_y_tolerance\": 3,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a70c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "image.reset().debug_tablefinder(table_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ba113c",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e38fed",
   "metadata": {},
   "source": [
    "<div id=\"2-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e3c3a1",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">2.2.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Extracting tables and generating dataframes (includes data cleanup)\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8202ae",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    We would like to get specific tables: information on GDP growth rates with annual, quarterly and monthly frequency. We don't need other tables also related to GDP that don't meet these requirements. Extraction will be easier if we use keywords.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc0a2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keywords to search in the page text\n",
    "keywords = [\"PRODUCTO BRUTO INTERNO\", \"SECTORES ECONÓMICOS\", \"PBI\", \"GDP\", \"Variaciones\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f193ac56",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    The code iterates through each PDF and extracts the two required tables from each. The extracted information is then transformed into dataframes and the columns and values are cleaned up to conform to Python conventions (pythonic).\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63188a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the locale to Spanish\n",
    "locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "\n",
    "# Function to process a PDF file and generate corresponding DataFrames\n",
    "def process_pdf(pdf_path):\n",
    "    # Dictionary to store tables that meet the criteria\n",
    "    tables_dict = {}\n",
    "\n",
    "    # Counter to assign names to tables\n",
    "    table_counter = 1\n",
    "\n",
    "    # Get id_ns and year from the PDF filename\n",
    "    filename = os.path.basename(pdf_path)\n",
    "    id_ns_year_matches = re.findall(r'ns-(\\d+)-(\\d{4})', filename)\n",
    "    if id_ns_year_matches:\n",
    "        id_ns, year = id_ns_year_matches[0]\n",
    "    else:\n",
    "        print(\"No matches found for id_ns and year in filename:\", filename)\n",
    "        return None, None, None, None\n",
    "\n",
    "    # Replace hyphens with underscores in the filename\n",
    "    new_filename = filename.replace('-', '_')\n",
    "\n",
    "    # Date extracted from the first text of the first page\n",
    "    date = None\n",
    "\n",
    "    # Open the PDF file\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        # Iterate through the pages of the PDF\n",
    "        for i, page in enumerate(pdf.pages, 1):\n",
    "            # Extract text from the page\n",
    "            text = page.extract_text()\n",
    "            if i == 1:\n",
    "                # Get the date from the first text of the first page\n",
    "                match = re.search(r'(\\d{1,2}\\s+de\\s+\\w+\\s+de\\s+\\d{4})', text)\n",
    "                if match:\n",
    "                    # Convert the date string to a datetime object with the desired format\n",
    "                    date = datetime.strptime(match.group(0), '%d de %B de %Y')\n",
    "\n",
    "            # Check if all keywords are present in the page text\n",
    "            if all(keyword in text for keyword in keywords):\n",
    "                # Extract all tables from the page and add them to the tables dictionary\n",
    "                for j, table in enumerate(page.extract_tables(), start=1):\n",
    "                    tables_dict[f\"table_{table_counter}\"] = table\n",
    "                    table_counter += 1\n",
    "\n",
    "    # Process each table in the dictionary\n",
    "    all_dataframes = {}\n",
    "    for table_name, table in tables_dict.items():\n",
    "        # Process the sublists to create DataFrames\n",
    "        for i, sublist in enumerate(table):\n",
    "            # Check if it's the first or second sublist\n",
    "            if i < 2:\n",
    "                # Apply space replacement around the hyphen only for the first and second sublist\n",
    "                for j, item in enumerate(sublist):\n",
    "                    if isinstance(item, str):\n",
    "                        table[i][j] = re.sub(r'\\s*-\\s*', '-', item)\n",
    "\n",
    "        # Process the first sublist to define the DataFrame columns\n",
    "        columns = table[0]\n",
    "\n",
    "        # List to store DataFrames of each sublist\n",
    "        dfs_temp = []\n",
    "\n",
    "        # Process the remaining sublists to create DataFrames\n",
    "        for sublist in table[1:]:\n",
    "            # Check if the sublist element is None\n",
    "            if sublist is not None:\n",
    "                # Iterate over sublist elements and split them by \"\\n\"\n",
    "                elements = [elem.split('\\n') if elem is not None else [''] for elem in sublist]\n",
    "                # Transpose the list to group elements of the same position into sublists\n",
    "                rows = zip(*elements)\n",
    "                # Convert rows to a Pandas DataFrame\n",
    "                df = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "                # Split observations into multiple columns, excluding 'SECTORES ECONÓMICOS' and 'ECONOMIC SECTORS' columns\n",
    "                columns_to_split = [col for col in df.columns if col not in ['SECTORES ECONÓMICOS', 'ECONOMIC SECTORS']]\n",
    "                for col in columns_to_split:\n",
    "                    df_temp = df[col].str.split(expand=True)\n",
    "                    for i in range(len(df_temp.columns)):\n",
    "                        df[f\"{col}_{i+1}\"] = df_temp[i]\n",
    "\n",
    "                # Remove the original columns that were split\n",
    "                df = df.drop(columns=columns_to_split)\n",
    "\n",
    "                # Add the DataFrame to the temporary DataFrame list\n",
    "                dfs_temp.append(df)\n",
    "\n",
    "        # Concatenate temporary DataFrames into one\n",
    "        df_final_temp = pd.concat(dfs_temp, ignore_index=True)\n",
    "\n",
    "        # Rename columns containing '_'\n",
    "        new_names = {col: col.split('_')[0] for col in df_final_temp.columns if '_' in col}\n",
    "        df_final_temp.rename(columns=new_names, inplace=True)\n",
    "\n",
    "        # Iterate over columns and remove leading underscores if necessary\n",
    "        df_final_temp.columns = [col[1:] if col.startswith('_') else col for col in df_final_temp.columns]\n",
    "\n",
    "        # Remove spaces before and after hyphens in column names\n",
    "        df_final_temp.columns = [col.strip().replace(' - ', '-') for col in df_final_temp.columns]\n",
    "\n",
    "        # Replace empty columns\n",
    "        columns = list(df_final_temp.columns)\n",
    "        for i, column in enumerate(columns):\n",
    "            if column.strip() == '':\n",
    "                # Find the left column name containing a year\n",
    "                left_name = next((col for col in reversed(columns[:i]) if col.isdigit()), None)\n",
    "\n",
    "                # Find the right column name containing a year\n",
    "                right_name = next((col for col in columns[i + 1:] if col.isdigit()), None)\n",
    "\n",
    "                if left_name and not right_name:\n",
    "                    # If there's a 4-digit number to the left and no more columns to the right\n",
    "                    df_final_temp.rename(columns={column: left_name}, inplace=True)\n",
    "                elif not left_name and right_name:\n",
    "                    # If there's a 4-digit number to the right and no more columns to the left\n",
    "                    right_year = int(right_name)\n",
    "                    df_final_temp.rename(columns={column: str(right_year - 1)}, inplace=True)\n",
    "                elif left_name and right_name:\n",
    "                    # If there are column names to the left and right containing 4-digit numbers\n",
    "                    left_year = int(left_name)\n",
    "                    df_final_temp.rename(columns={column: str(left_year)}, inplace=True)\n",
    "\n",
    "        # Replace column names with prefixes from the first row\n",
    "        new_names = df_final_temp.iloc[0].apply(lambda x: x.strip() if isinstance(x, str) else x).astype(str) + '_' + df_final_temp.columns\n",
    "        df_final_temp.columns = new_names\n",
    "\n",
    "        # Remove the first row of the DataFrame, as its values were used as prefixes for columns\n",
    "        df_final_temp = df_final_temp.drop(0)\n",
    "\n",
    "        # Convert all columns to lowercase\n",
    "        df_final_temp.columns = map(str.lower, df_final_temp.columns)\n",
    "\n",
    "        # Remove periods from column names\n",
    "        df_final_temp.columns = df_final_temp.columns.str.replace('.', '')\n",
    "\n",
    "        # Remove special characters and accents from column names\n",
    "        df_final_temp.columns = [unicodedata.normalize('NFKD', col).encode('ASCII', 'ignore').decode('utf-8') for col in df_final_temp.columns]\n",
    "\n",
    "        # Replace 'ano' with 'year' in all columns\n",
    "        df_final_temp.columns = [col.replace('ano', 'year') for col in df_final_temp.columns]\n",
    "\n",
    "        # Replace empty spaces between words with '_'\n",
    "        df_final_temp.columns = [col.replace(' ', '_') for col in df_final_temp.columns]\n",
    "\n",
    "        # Replace hyphens with underscores\n",
    "        df_final_temp.columns = [col.replace('-', '_') for col in df_final_temp.columns]\n",
    "\n",
    "        # Implementation of line that renames columns\n",
    "        df_final_temp.columns = [col[1:] if col.startswith('_') else col for col in df_final_temp.columns]\n",
    "\n",
    "        # Replace commas with periods in values of all columns except 'sectores_economicos' and 'economic_sectors'\n",
    "        for col in df_final_temp.columns:\n",
    "            if col not in ['sectores_economicos', 'economic_sectors']:\n",
    "                df_final_temp[col] = df_final_temp[col].apply(lambda x: str(x).replace(',', '.') if isinstance(x, (int, float, str)) else x)\n",
    "\n",
    "        # Convert columns to float type\n",
    "        for col in df_final_temp.columns:\n",
    "            if col not in ['sectores_economicos', 'economic_sectors']:\n",
    "                if isinstance(df_final_temp[col], pd.Series):\n",
    "                    df_final_temp[col] = pd.to_numeric(df_final_temp[col], errors='coerce')\n",
    "\n",
    "        # Get object (text string) type columns\n",
    "        text_columns = df_final_temp.select_dtypes(include='object').columns\n",
    "\n",
    "        # Iterate over text columns and remove accents\n",
    "        for col in text_columns:\n",
    "            df_final_temp[col] = df_final_temp[col].apply(lambda x: unicodedata.normalize('NFKD', x).encode('ASCII', 'ignore').decode('utf-8') if isinstance(x, str) else x)\n",
    "\n",
    "        # Convert all text strings to lowercase\n",
    "        for col in text_columns:\n",
    "            df_final_temp[col] = df_final_temp[col].str.lower()\n",
    "\n",
    "        # Define function to remove numbers and special characters\n",
    "        def remove_special_characters(text):\n",
    "            return re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "\n",
    "        # Apply function to 'sectores_economicos' and 'economic_sectors' columns\n",
    "        df_final_temp['sectores_economicos'] = df_final_temp['sectores_economicos'].apply(\n",
    "            remove_special_characters)\n",
    "        df_final_temp['economic_sectors'] = df_final_temp['economic_sectors'].apply(\n",
    "            remove_special_characters)\n",
    "\n",
    "        # Add new columns id_ns, year, and date to DataFrames\n",
    "        df_final_temp['year'] = year\n",
    "        df_final_temp['id_ns'] = id_ns\n",
    "        df_final_temp['date'] = date\n",
    "\n",
    "        # Reorganize columns to place year, id_ns, and date at the beginning\n",
    "        column_order = ['year', 'id_ns', 'date'] + [col for col in df_final_temp.columns if col not in ['id_ns', 'year', 'date']]\n",
    "        df_final_temp = df_final_temp[column_order]\n",
    "\n",
    "        # Convert id_ns and year columns to integer type\n",
    "        df_final_temp['year'] = df_final_temp['year'].astype(int)\n",
    "        df_final_temp['id_ns'] = df_final_temp['id_ns'].astype(int)\n",
    "\n",
    "        # Save the final DataFrame with a unique name in the dictionary\n",
    "        df_name = f\"{os.path.splitext(new_filename)[0]}_{table_name.split('_')[1]}\"\n",
    "        all_dataframes[df_name] = df_final_temp\n",
    "\n",
    "    # Return the results\n",
    "    return all_dataframes, year, id_ns, date\n",
    "\n",
    "# Iterate over the PDF files in the folder\n",
    "\n",
    "# Initialize a counter\n",
    "file_counter = 0\n",
    "\n",
    "# Dictionary to store all generated dataframes\n",
    "all_dataframes = {}\n",
    "\n",
    "# Iterate over the PDF files in the folder\n",
    "for filename in os.listdir(raw_pdf):\n",
    "    if filename.endswith(\".pdf\"):\n",
    "        file_counter += 1\n",
    "        pdf_file = os.path.join(raw_pdf, filename)\n",
    "        print(f\"Processing file {file_counter}: {pdf_file}\")\n",
    "        generated_dataframes, year, id_ns, date = process_pdf(pdf_file)\n",
    "        print(\"Generated DataFrames:\")\n",
    "        for df_name in generated_dataframes.keys():\n",
    "            print(df_name)\n",
    "        # Add the generated dataframes to the general dictionary\n",
    "        all_dataframes.update(generated_dataframes)\n",
    "\n",
    "# Use the all_dataframes dictionary as needed\n",
    "\n",
    "        #print(\"year:\", year)\n",
    "        #print(\"id_ns:\", id_ns)\n",
    "        #print(\"date:\", date)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072b0a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataframes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6b328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataframes['ns_10_2013_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eeb2791",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a8df84",
   "metadata": {},
   "source": [
    "<div id=\"3\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11413df9",
   "metadata": {},
   "source": [
    "<h1><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.</span> <span style = \"color: dark; font-family: charter;\">SQL Tables</span></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33c1561",
   "metadata": {},
   "source": [
    "<div style=\"font-family: charter; text-align: left; color:dark\">\n",
    "    Finally, after obtaining and cleaning all the necessary data, we can create the three most important datasets to store realeses, vintages, and revisions. These datasets will be stored as tables in SQL and can be loaded into any software or programming language.\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761bf2a4",
   "metadata": {},
   "source": [
    "<div id=\"3-1\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd7137b",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.1.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Annual Concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af728eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store the names of dataframes that meet the criterion of ending in '_2'\n",
    "dataframes_ending_with_2 = []\n",
    "\n",
    "# List to store the names of dataframes to be concatenated\n",
    "dataframes_to_concatenate = []\n",
    "\n",
    "# Iterate over the dataframe names in the all_dataframes dictionary\n",
    "for df_name in all_dataframes.keys():\n",
    "    # Check if the dataframe name ends with '_2' and add it to the corresponding list\n",
    "    if df_name.endswith('_2'):\n",
    "        dataframes_ending_with_2.append(df_name)\n",
    "        dataframes_to_concatenate.append(all_dataframes[df_name])\n",
    "\n",
    "# Print the names of dataframes that meet the criterion of ending in '_2'\n",
    "print(\"DataFrames ending with '_2' that will be concatenated:\")\n",
    "for df_name in dataframes_ending_with_2:\n",
    "    print(df_name)\n",
    "\n",
    "# Concatenate all dataframes in the 'dataframes_to_concatenate' list\n",
    "if dataframes_to_concatenate:\n",
    "    # Concatenate only rows that meet the specified conditions\n",
    "    gdp_annual_growth_rates = pd.concat([df[(df['sectores_economicos'] == 'pbi') | (df['economic_sectors'] == 'gdp')] \n",
    "                                for df in dataframes_to_concatenate \n",
    "                                if 'sectores_economicos' in df.columns and 'economic_sectors' in df.columns], \n",
    "                                ignore_index=True)\n",
    "\n",
    "    # Keep only columns that start with 'year' and the 'id_ns', 'year', and 'date' columns\n",
    "    columns_to_keep = ['id_ns', 'year', 'date'] + [col for col in gdp_annual_growth_rates.columns if col.startswith('year')]\n",
    "\n",
    "    # Drop unwanted columns\n",
    "    gdp_annual_growth_rates = gdp_annual_growth_rates[columns_to_keep]\n",
    "    \n",
    "    # Remove duplicate columns if any\n",
    "    gdp_annual_growth_rates = gdp_annual_growth_rates.loc[:,~gdp_annual_growth_rates.columns.duplicated()]\n",
    "\n",
    "    # Print the number of rows in the concatenated dataframe\n",
    "    print(\"Number of rows in the concatenated dataframe:\", len(gdp_annual_growth_rates))\n",
    "else:\n",
    "    print(\"No dataframes were found to concatenate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cab0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_annual_growth_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb4df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a351ddec",
   "metadata": {},
   "source": [
    "<div id=\"3-2\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a38011",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.2.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Quarterly Concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List to store the names of dataframes that meet the criterion of ending in '_2'\n",
    "dataframes_ending_with_2 = []\n",
    "\n",
    "# List to store the names of dataframes to be concatenated\n",
    "dataframes_to_concatenate = []\n",
    "\n",
    "# Iterate over the dataframe names in the all_dataframes dictionary\n",
    "for df_name in all_dataframes.keys():\n",
    "    # Check if the dataframe name ends with '_2' and add it to the corresponding list\n",
    "    if df_name.endswith('_2'):\n",
    "        dataframes_ending_with_2.append(df_name)\n",
    "        dataframes_to_concatenate.append(all_dataframes[df_name])\n",
    "\n",
    "# Print the names of dataframes that meet the criterion of ending in '_2'\n",
    "print(\"DataFrames ending with '_2' that will be concatenated:\")\n",
    "for df_name in dataframes_ending_with_2:\n",
    "    print(df_name)\n",
    "\n",
    "# Concatenate all dataframes in the 'dataframes_to_concatenate' list\n",
    "if dataframes_to_concatenate:\n",
    "    # Concatenate only rows that meet the specified conditions\n",
    "    gdp_quarterly_growth_rates = pd.concat([df[(df['sectores_economicos'] == 'pbi') | (df['economic_sectors'] == 'gdp')] \n",
    "                                for df in dataframes_to_concatenate \n",
    "                                if 'sectores_economicos' in df.columns and 'economic_sectors' in df.columns], \n",
    "                                ignore_index=True)\n",
    "\n",
    "    # Keep all columns except those starting with 'year_', in addition to the 'id_ns', 'year', and 'date' columns\n",
    "    columns_to_keep = ['year', 'id_ns', 'date'] + [col for col in gdp_quarterly_growth_rates.columns if not col.startswith('year_')]\n",
    "\n",
    "    # Select unwanted columns\n",
    "    gdp_quarterly_growth_rates = gdp_quarterly_growth_rates[columns_to_keep]\n",
    "\n",
    "    # Drop the 'sectores_economicos' and 'economic_sectors' columns\n",
    "    gdp_quarterly_growth_rates.drop(columns=['sectores_economicos', 'economic_sectors'], inplace=True)\n",
    "\n",
    "    # Remove duplicate columns if any\n",
    "    gdp_quarterly_growth_rates = gdp_quarterly_growth_rates.loc[:,~gdp_quarterly_growth_rates.columns.duplicated()]\n",
    "\n",
    "    # Print the number of rows in the concatenated dataframe\n",
    "    print(\"Number of rows in the concatenated dataframe:\", len(gdp_quarterly_growth_rates))\n",
    "else:\n",
    "    print(\"No dataframes were found to concatenate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c24df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_quarterly_growth_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e86a55e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d7b9235",
   "metadata": {},
   "source": [
    "<div id=\"3-3\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bbe2d7",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.3.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Monthly Concatenation\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8448d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List to store the names of dataframes that meet the criterion of ending in '_1'\n",
    "dataframes_ending_with_1 = []\n",
    "\n",
    "# List to store the names of dataframes to be concatenated\n",
    "dataframes_to_concatenate = []\n",
    "\n",
    "# Iterate over the dataframe names in the all_dataframes dictionary\n",
    "for df_name in all_dataframes.keys():\n",
    "    # Check if the dataframe name ends with '_1' and add it to the corresponding list\n",
    "    if df_name.endswith('_1'):\n",
    "        dataframes_ending_with_1.append(df_name)\n",
    "        dataframes_to_concatenate.append(all_dataframes[df_name])\n",
    "\n",
    "# Print the names of dataframes that meet the criterion of ending with '_1'\n",
    "print(\"DataFrames ending with '_1' that will be concatenated:\")\n",
    "for df_name in dataframes_ending_with_1:\n",
    "    print(df_name)\n",
    "\n",
    "# Concatenate all dataframes in the 'dataframes_to_concatenate' list\n",
    "if dataframes_to_concatenate:\n",
    "    # Concatenate only rows that meet the specified conditions\n",
    "    gdp_monthly_growth_rates = pd.concat([df[(df['sectores_economicos'] == 'pbi') | (df['economic_sectors'] == 'gdp')] \n",
    "                                for df in dataframes_to_concatenate \n",
    "                                if 'sectores_economicos' in df.columns and 'economic_sectors' in df.columns], \n",
    "                                ignore_index=True)\n",
    "\n",
    "    # Keep all columns except those starting with 'year_', in addition to the 'id_ns', 'year', and 'date' columns\n",
    "    columns_to_keep = ['year', 'id_ns', 'date'] + [col for col in gdp_monthly_growth_rates.columns if not col.startswith('year_')]\n",
    "\n",
    "    # Select unwanted columns\n",
    "    gdp_monthly_growth_rates = gdp_monthly_growth_rates[columns_to_keep]\n",
    "\n",
    "    # Drop the 'sectores_economicos' and 'economic_sectors' columns\n",
    "    gdp_monthly_growth_rates.drop(columns=['sectores_economicos', 'economic_sectors'], inplace=True)\n",
    "\n",
    "    # Remove duplicate columns if any\n",
    "    gdp_monthly_growth_rates = gdp_monthly_growth_rates.loc[:,~gdp_monthly_growth_rates.columns.duplicated()]\n",
    "    \n",
    "    # Drop columns with at least two underscores in their names\n",
    "    columns_to_drop = [col for col in gdp_monthly_growth_rates.columns if col.count('_') >= 2]\n",
    "    gdp_monthly_growth_rates.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "    # Print the number of rows in the concatenated dataframe\n",
    "    print(\"Number of rows in the concatenated dataframe:\", len(gdp_monthly_growth_rates))\n",
    "else:\n",
    "    print(\"No dataframes were found to concatenate.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63690ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_monthly_growth_rates['date'].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f1ecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6100946c",
   "metadata": {},
   "source": [
    "<div id=\"3-4\">\n",
    "   <!-- Contenido de la celda de destino -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0770fa97",
   "metadata": {},
   "source": [
    "<h2><span style = \"color: rgb(0, 65, 75); font-family: charter;\">3.4.</span>\n",
    "    <span style = \"color: dark; font-family: charter;\">\n",
    "    Loading SQL\n",
    "    </span>\n",
    "    </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42d480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Get environment variables\n",
    "user = os.environ.get('CIUP_SQL_USER')\n",
    "password = os.environ.get('CIUP_SQL_PASS')\n",
    "host = os.environ.get('CIUP_SQL_HOST')\n",
    "port = 5432\n",
    "database = 'gdp_revisions_datasets'\n",
    "\n",
    "# Check if all environment variables are defined\n",
    "if not all([host, user, password]):\n",
    "    raise ValueError(\"Some environment variables are missing (CIUP_SQL_HOST, CIUP_SQL_USER, CIUP_SQL_PASS)\")\n",
    "\n",
    "# Create connection string\n",
    "connection_string = f\"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(connection_string)\n",
    "\n",
    "# gdp_monthly_growth_rates is the DataFrame you want to save to the database\n",
    "gdp_annual_growth_rates.to_sql('gdp_annual_growth_rates', engine, index=False, if_exists='replace')\n",
    "gdp_quarterly_growth_rates.to_sql('gdp_quarterly_growth_rates', engine, index=False, if_exists='replace')\n",
    "gdp_monthly_growth_rates.to_sql('gdp_monthly_growth_rates', engine, index=False, if_exists='replace')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61f9b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03e4baa8",
   "metadata": {},
   "source": [
    "<div style=\"color: rgb(61, 48, 162); font-size: 12px;\">\n",
    "    Back to the\n",
    "    <a href=\"#outilne\" style=\"color: #687EFF;\">\n",
    "    outline.\n",
    "    </a>\n",
    "    <div/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c603aa4",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa180a79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074195e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdp_revisions",
   "language": "python",
   "name": "gdp_revisions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
